{"mean 100 episode reward": -200.0, "episodes": 2, "reward": -200.0, "steps": 199}
{"mean 100 episode reward": -200.0, "episodes": 3, "reward": -200.0, "steps": 399}
{"mean 100 episode reward": -200.0, "episodes": 4, "reward": -200.0, "steps": 599}
{"mean 100 episode reward": -200.0, "episodes": 5, "reward": -200.0, "steps": 799}
{"mean 100 episode reward": -200.0, "episodes": 6, "reward": -200.0, "steps": 999}
{"mean 100 episode reward": -200.0, "episodes": 7, "reward": -200.0, "steps": 1199}
{"mean 100 episode reward": -200.0, "episodes": 8, "reward": -200.0, "steps": 1399}
{"mean 100 episode reward": -200.0, "episodes": 9, "reward": -200.0, "steps": 1599}
{"mean 100 episode reward": -200.0, "episodes": 10, "reward": -200.0, "steps": 1799}
{"mean 100 episode reward": -200.0, "episodes": 11, "reward": -200.0, "steps": 1999}
{"mean 100 episode reward": -200.0, "episodes": 12, "reward": -200.0, "steps": 2199}
{"mean 100 episode reward": -200.0, "episodes": 13, "reward": -200.0, "steps": 2399}
{"mean 100 episode reward": -200.0, "episodes": 14, "reward": -200.0, "steps": 2599}
{"mean 100 episode reward": -200.0, "episodes": 15, "reward": -200.0, "steps": 2799}
{"mean 100 episode reward": -200.0, "episodes": 16, "reward": -200.0, "steps": 2999}
{"mean 100 episode reward": -200.0, "episodes": 17, "reward": -200.0, "steps": 3199}
{"mean 100 episode reward": -200.0, "episodes": 18, "reward": -200.0, "steps": 3399}
{"mean 100 episode reward": -200.0, "episodes": 19, "reward": -200.0, "steps": 3599}
{"mean 100 episode reward": -200.0, "episodes": 20, "reward": -200.0, "steps": 3799}
{"mean 100 episode reward": -200.0, "episodes": 21, "reward": -200.0, "steps": 3999}
{"mean 100 episode reward": -200.0, "episodes": 22, "reward": -200.0, "steps": 4199}
{"mean 100 episode reward": -200.0, "episodes": 23, "reward": -200.0, "steps": 4399}
{"mean 100 episode reward": -200.0, "episodes": 24, "reward": -200.0, "steps": 4599}
{"mean 100 episode reward": -200.0, "episodes": 25, "reward": -200.0, "steps": 4799}
{"mean 100 episode reward": -200.0, "episodes": 26, "reward": -200.0, "steps": 4999}
{"mean 100 episode reward": -200.0, "episodes": 27, "reward": -200.0, "steps": 5199}
{"mean 100 episode reward": -200.0, "episodes": 28, "reward": -200.0, "steps": 5399}
{"mean 100 episode reward": -200.0, "episodes": 29, "reward": -200.0, "steps": 5599}
{"mean 100 episode reward": -200.0, "episodes": 30, "reward": -200.0, "steps": 5799}
{"mean 100 episode reward": -200.0, "episodes": 31, "reward": -200.0, "steps": 5999}
{"mean 100 episode reward": -200.0, "episodes": 32, "reward": -200.0, "steps": 6199}
{"mean 100 episode reward": -200.0, "episodes": 33, "reward": -200.0, "steps": 6399}
{"mean 100 episode reward": -200.0, "episodes": 34, "reward": -200.0, "steps": 6599}
{"mean 100 episode reward": -200.0, "episodes": 35, "reward": -200.0, "steps": 6799}
{"mean 100 episode reward": -200.0, "episodes": 36, "reward": -200.0, "steps": 6999}
{"mean 100 episode reward": -200.0, "episodes": 37, "reward": -200.0, "steps": 7199}
{"mean 100 episode reward": -200.0, "episodes": 38, "reward": -200.0, "steps": 7399}
{"mean 100 episode reward": -200.0, "episodes": 39, "reward": -200.0, "steps": 7599}
{"mean 100 episode reward": -200.0, "episodes": 40, "reward": -200.0, "steps": 7799}
{"mean 100 episode reward": -200.0, "episodes": 41, "reward": -200.0, "steps": 7999}
{"mean 100 episode reward": -200.0, "episodes": 42, "reward": -200.0, "steps": 8199}
{"mean 100 episode reward": -200.0, "episodes": 43, "reward": -200.0, "steps": 8399}
{"mean 100 episode reward": -200.0, "episodes": 44, "reward": -200.0, "steps": 8599}
{"mean 100 episode reward": -200.0, "episodes": 45, "reward": -200.0, "steps": 8799}
{"mean 100 episode reward": -200.0, "episodes": 46, "reward": -200.0, "steps": 8999}
{"mean 100 episode reward": -200.0, "episodes": 47, "reward": -200.0, "steps": 9199}
{"mean 100 episode reward": -200.0, "episodes": 48, "reward": -200.0, "steps": 9399}
{"mean 100 episode reward": -200.0, "episodes": 49, "reward": -200.0, "steps": 9599}
{"mean 100 episode reward": -200.0, "episodes": 50, "reward": -200.0, "steps": 9799}
{"mean 100 episode reward": -200.0, "episodes": 51, "reward": -200.0, "steps": 9999}
{"mean 100 episode reward": -200.0, "episodes": 52, "reward": -200.0, "steps": 10199}
{"mean 100 episode reward": -200.0, "episodes": 53, "reward": -200.0, "steps": 10399}
{"mean 100 episode reward": -200.0, "episodes": 54, "reward": -200.0, "steps": 10599}
{"mean 100 episode reward": -200.0, "episodes": 55, "reward": -200.0, "steps": 10799}
{"mean 100 episode reward": -200.0, "episodes": 56, "reward": -200.0, "steps": 10999}
{"mean 100 episode reward": -200.0, "episodes": 57, "reward": -200.0, "steps": 11199}
{"mean 100 episode reward": -200.0, "episodes": 58, "reward": -200.0, "steps": 11399}
{"mean 100 episode reward": -200.0, "episodes": 59, "reward": -200.0, "steps": 11599}
{"mean 100 episode reward": -200.0, "episodes": 60, "reward": -200.0, "steps": 11799}
{"mean 100 episode reward": -200.0, "episodes": 61, "reward": -200.0, "steps": 11999}
{"mean 100 episode reward": -200.0, "episodes": 62, "reward": -200.0, "steps": 12199}
{"mean 100 episode reward": -200.0, "episodes": 63, "reward": -200.0, "steps": 12399}
{"mean 100 episode reward": -200.0, "episodes": 64, "reward": -200.0, "steps": 12599}
{"mean 100 episode reward": -200.0, "episodes": 65, "reward": -200.0, "steps": 12799}
{"mean 100 episode reward": -200.0, "episodes": 66, "reward": -200.0, "steps": 12999}
{"mean 100 episode reward": -200.0, "episodes": 67, "reward": -200.0, "steps": 13199}
{"mean 100 episode reward": -200.0, "episodes": 68, "reward": -200.0, "steps": 13399}
{"mean 100 episode reward": -200.0, "episodes": 69, "reward": -200.0, "steps": 13599}
{"mean 100 episode reward": -200.0, "episodes": 70, "reward": -200.0, "steps": 13799}
{"mean 100 episode reward": -200.0, "episodes": 71, "reward": -200.0, "steps": 13999}
{"mean 100 episode reward": -200.0, "episodes": 72, "reward": -200.0, "steps": 14199}
{"mean 100 episode reward": -200.0, "episodes": 73, "reward": -200.0, "steps": 14399}
{"mean 100 episode reward": -200.0, "episodes": 74, "reward": -200.0, "steps": 14599}
{"mean 100 episode reward": -200.0, "episodes": 75, "reward": -200.0, "steps": 14799}
{"mean 100 episode reward": -200.0, "episodes": 76, "reward": -200.0, "steps": 14999}
{"mean 100 episode reward": -200.0, "episodes": 77, "reward": -200.0, "steps": 15199}
{"mean 100 episode reward": -200.0, "episodes": 78, "reward": -200.0, "steps": 15399}
{"mean 100 episode reward": -200.0, "episodes": 79, "reward": -200.0, "steps": 15599}
{"mean 100 episode reward": -200.0, "episodes": 80, "reward": -200.0, "steps": 15799}
{"mean 100 episode reward": -200.0, "episodes": 81, "reward": -200.0, "steps": 15999}
{"mean 100 episode reward": -200.0, "episodes": 82, "reward": -200.0, "steps": 16199}
{"mean 100 episode reward": -200.0, "episodes": 83, "reward": -200.0, "steps": 16399}
{"mean 100 episode reward": -200.0, "episodes": 84, "reward": -200.0, "steps": 16599}
{"mean 100 episode reward": -200.0, "episodes": 85, "reward": -200.0, "steps": 16799}
{"mean 100 episode reward": -200.0, "episodes": 86, "reward": -200.0, "steps": 16999}
{"mean 100 episode reward": -200.0, "episodes": 87, "reward": -200.0, "steps": 17199}
{"mean 100 episode reward": -200.0, "episodes": 88, "reward": -200.0, "steps": 17399}
{"mean 100 episode reward": -200.0, "episodes": 89, "reward": -200.0, "steps": 17599}
{"mean 100 episode reward": -200.0, "episodes": 90, "reward": -200.0, "steps": 17799}
{"mean 100 episode reward": -200.0, "episodes": 91, "reward": -200.0, "steps": 17999}
{"mean 100 episode reward": -200.0, "episodes": 92, "reward": -200.0, "steps": 18199}
{"mean 100 episode reward": -200.0, "episodes": 93, "reward": -200.0, "steps": 18399}
{"mean 100 episode reward": -200.0, "episodes": 94, "reward": -200.0, "steps": 18599}
{"mean 100 episode reward": -200.0, "episodes": 95, "reward": -200.0, "steps": 18799}
{"mean 100 episode reward": -200.0, "episodes": 96, "reward": -200.0, "steps": 18999}
{"mean 100 episode reward": -200.0, "episodes": 97, "reward": -200.0, "steps": 19199}
{"mean 100 episode reward": -200.0, "episodes": 98, "reward": -200.0, "steps": 19399}
{"mean 100 episode reward": -200.0, "episodes": 99, "reward": -200.0, "steps": 19599}
{"mean 100 episode reward": -200.0, "episodes": 100, "reward": -200.0, "steps": 19799}
{"mean 100 episode reward": -200.0, "episodes": 101, "reward": -200.0, "steps": 19999}
{"mean 100 episode reward": -200.0, "episodes": 102, "reward": -200.0, "steps": 20199}
{"mean 100 episode reward": -200.0, "episodes": 103, "reward": -200.0, "steps": 20399}
{"mean 100 episode reward": -200.0, "episodes": 104, "reward": -200.0, "steps": 20599}
{"mean 100 episode reward": -200.0, "episodes": 105, "reward": -200.0, "steps": 20799}
{"mean 100 episode reward": -200.0, "episodes": 106, "reward": -200.0, "steps": 20999}
{"mean 100 episode reward": -200.0, "episodes": 107, "reward": -200.0, "steps": 21199}
{"mean 100 episode reward": -200.0, "episodes": 108, "reward": -200.0, "steps": 21399}
{"mean 100 episode reward": -200.0, "episodes": 109, "reward": -200.0, "steps": 21599}
{"mean 100 episode reward": -200.0, "episodes": 110, "reward": -200.0, "steps": 21799}
{"mean 100 episode reward": -200.0, "episodes": 111, "reward": -200.0, "steps": 21999}
{"mean 100 episode reward": -200.0, "episodes": 112, "reward": -200.0, "steps": 22199}
{"mean 100 episode reward": -200.0, "episodes": 113, "reward": -200.0, "steps": 22399}
{"mean 100 episode reward": -200.0, "episodes": 114, "reward": -200.0, "steps": 22599}
{"mean 100 episode reward": -200.0, "episodes": 115, "reward": -200.0, "steps": 22799}
{"mean 100 episode reward": -200.0, "episodes": 116, "reward": -200.0, "steps": 22999}
{"mean 100 episode reward": -200.0, "episodes": 117, "reward": -200.0, "steps": 23199}
{"mean 100 episode reward": -200.0, "episodes": 118, "reward": -200.0, "steps": 23399}
{"mean 100 episode reward": -200.0, "episodes": 119, "reward": -200.0, "steps": 23599}
{"mean 100 episode reward": -200.0, "episodes": 120, "reward": -200.0, "steps": 23799}
{"mean 100 episode reward": -200.0, "episodes": 121, "reward": -200.0, "steps": 23999}
{"mean 100 episode reward": -200.0, "episodes": 122, "reward": -200.0, "steps": 24199}
{"mean 100 episode reward": -200.0, "episodes": 123, "reward": -200.0, "steps": 24399}
{"mean 100 episode reward": -200.0, "episodes": 124, "reward": -200.0, "steps": 24599}
{"mean 100 episode reward": -200.0, "episodes": 125, "reward": -200.0, "steps": 24799}
{"mean 100 episode reward": -200.0, "episodes": 126, "reward": -200.0, "steps": 24999}
{"mean 100 episode reward": -200.0, "episodes": 127, "reward": -200.0, "steps": 25199}
{"mean 100 episode reward": -200.0, "episodes": 128, "reward": -200.0, "steps": 25399}
{"mean 100 episode reward": -200.0, "episodes": 129, "reward": -200.0, "steps": 25599}
{"mean 100 episode reward": -200.0, "episodes": 130, "reward": -200.0, "steps": 25799}
{"mean 100 episode reward": -200.0, "episodes": 131, "reward": -200.0, "steps": 25999}
{"mean 100 episode reward": -200.0, "episodes": 132, "reward": -200.0, "steps": 26199}
{"mean 100 episode reward": -200.0, "episodes": 133, "reward": -200.0, "steps": 26399}
{"mean 100 episode reward": -200.0, "episodes": 134, "reward": -200.0, "steps": 26599}
{"mean 100 episode reward": -200.0, "episodes": 135, "reward": -200.0, "steps": 26799}
{"mean 100 episode reward": -200.0, "episodes": 136, "reward": -200.0, "steps": 26999}
{"mean 100 episode reward": -200.0, "episodes": 137, "reward": -200.0, "steps": 27199}
{"mean 100 episode reward": -200.0, "episodes": 138, "reward": -200.0, "steps": 27399}
{"mean 100 episode reward": -200.0, "episodes": 139, "reward": -200.0, "steps": 27599}
{"mean 100 episode reward": -200.0, "episodes": 140, "reward": -200.0, "steps": 27799}
{"mean 100 episode reward": -200.0, "episodes": 141, "reward": -200.0, "steps": 27999}
{"mean 100 episode reward": -200.0, "episodes": 142, "reward": -200.0, "steps": 28199}
{"mean 100 episode reward": -200.0, "episodes": 143, "reward": -200.0, "steps": 28399}
{"mean 100 episode reward": -200.0, "episodes": 144, "reward": -200.0, "steps": 28599}
{"mean 100 episode reward": -200.0, "episodes": 145, "reward": -200.0, "steps": 28799}
{"mean 100 episode reward": -200.0, "episodes": 146, "reward": -200.0, "steps": 28999}
{"mean 100 episode reward": -200.0, "episodes": 147, "reward": -200.0, "steps": 29199}
{"mean 100 episode reward": -200.0, "episodes": 148, "reward": -200.0, "steps": 29399}
{"mean 100 episode reward": -200.0, "episodes": 149, "reward": -200.0, "steps": 29599}
{"mean 100 episode reward": -200.0, "episodes": 150, "reward": -200.0, "steps": 29799}
{"mean 100 episode reward": -200.0, "episodes": 151, "reward": -200.0, "steps": 29999}
{"mean 100 episode reward": -200.0, "episodes": 152, "reward": -200.0, "steps": 30199}
{"mean 100 episode reward": -200.0, "episodes": 153, "reward": -200.0, "steps": 30399}
{"mean 100 episode reward": -200.0, "episodes": 154, "reward": -200.0, "steps": 30599}
{"mean 100 episode reward": -200.0, "episodes": 155, "reward": -200.0, "steps": 30799}
{"mean 100 episode reward": -200.0, "episodes": 156, "reward": -200.0, "steps": 30999}
{"mean 100 episode reward": -200.0, "episodes": 157, "reward": -200.0, "steps": 31199}
{"mean 100 episode reward": -200.0, "episodes": 158, "reward": -200.0, "steps": 31399}
{"mean 100 episode reward": -200.0, "episodes": 159, "reward": -200.0, "steps": 31599}
{"mean 100 episode reward": -200.0, "episodes": 160, "reward": -200.0, "steps": 31799}
{"mean 100 episode reward": -200.0, "episodes": 161, "reward": -200.0, "steps": 31999}
{"mean 100 episode reward": -200.0, "episodes": 162, "reward": -200.0, "steps": 32199}
{"mean 100 episode reward": -200.0, "episodes": 163, "reward": -200.0, "steps": 32399}
{"mean 100 episode reward": -200.0, "episodes": 164, "reward": -200.0, "steps": 32599}
{"mean 100 episode reward": -200.0, "episodes": 165, "reward": -200.0, "steps": 32799}
{"mean 100 episode reward": -200.0, "episodes": 166, "reward": -200.0, "steps": 32999}
{"mean 100 episode reward": -200.0, "episodes": 167, "reward": -200.0, "steps": 33199}
{"mean 100 episode reward": -200.0, "episodes": 168, "reward": -200.0, "steps": 33399}
{"mean 100 episode reward": -200.0, "episodes": 169, "reward": -200.0, "steps": 33599}
{"mean 100 episode reward": -200.0, "episodes": 170, "reward": -200.0, "steps": 33799}
{"mean 100 episode reward": -200.0, "episodes": 171, "reward": -200.0, "steps": 33999}
{"mean 100 episode reward": -200.0, "episodes": 172, "reward": -200.0, "steps": 34199}
{"mean 100 episode reward": -200.0, "episodes": 173, "reward": -200.0, "steps": 34399}
{"mean 100 episode reward": -200.0, "episodes": 174, "reward": -200.0, "steps": 34599}
{"mean 100 episode reward": -200.0, "episodes": 175, "reward": -200.0, "steps": 34799}
{"mean 100 episode reward": -200.0, "episodes": 176, "reward": -200.0, "steps": 34999}
{"mean 100 episode reward": -200.0, "episodes": 177, "reward": -200.0, "steps": 35199}
{"mean 100 episode reward": -200.0, "episodes": 178, "reward": -200.0, "steps": 35399}
{"mean 100 episode reward": -200.0, "episodes": 179, "reward": -200.0, "steps": 35599}
{"mean 100 episode reward": -200.0, "episodes": 180, "reward": -200.0, "steps": 35799}
{"mean 100 episode reward": -200.0, "episodes": 181, "reward": -200.0, "steps": 35999}
{"mean 100 episode reward": -200.0, "episodes": 182, "reward": -200.0, "steps": 36199}
{"mean 100 episode reward": -200.0, "episodes": 183, "reward": -200.0, "steps": 36399}
{"mean 100 episode reward": -200.0, "episodes": 184, "reward": -200.0, "steps": 36599}
{"mean 100 episode reward": -200.0, "episodes": 185, "reward": -200.0, "steps": 36799}
{"mean 100 episode reward": -200.0, "episodes": 186, "reward": -200.0, "steps": 36999}
{"mean 100 episode reward": -200.0, "episodes": 187, "reward": -200.0, "steps": 37199}
{"mean 100 episode reward": -200.0, "episodes": 188, "reward": -200.0, "steps": 37399}
{"mean 100 episode reward": -200.0, "episodes": 189, "reward": -200.0, "steps": 37599}
{"mean 100 episode reward": -200.0, "episodes": 190, "reward": -200.0, "steps": 37799}
{"mean 100 episode reward": -200.0, "episodes": 191, "reward": -200.0, "steps": 37999}
{"mean 100 episode reward": -200.0, "episodes": 192, "reward": -200.0, "steps": 38199}
{"mean 100 episode reward": -200.0, "episodes": 193, "reward": -200.0, "steps": 38399}
{"mean 100 episode reward": -200.0, "episodes": 194, "reward": -200.0, "steps": 38599}
{"mean 100 episode reward": -200.0, "episodes": 195, "reward": -200.0, "steps": 38799}
{"mean 100 episode reward": -200.0, "episodes": 196, "reward": -200.0, "steps": 38999}
{"mean 100 episode reward": -200.0, "episodes": 197, "reward": -200.0, "steps": 39199}
{"mean 100 episode reward": -200.0, "episodes": 198, "reward": -200.0, "steps": 39399}
{"mean 100 episode reward": -200.0, "episodes": 199, "reward": -200.0, "steps": 39599}
{"mean 100 episode reward": -200.0, "episodes": 200, "reward": -200.0, "steps": 39799}
{"mean 100 episode reward": -200.0, "episodes": 201, "reward": -200.0, "steps": 39999}
{"mean 100 episode reward": -200.0, "episodes": 202, "reward": -200.0, "steps": 40199}
{"mean 100 episode reward": -200.0, "episodes": 203, "reward": -200.0, "steps": 40399}
{"mean 100 episode reward": -200.0, "episodes": 204, "reward": -200.0, "steps": 40599}
{"mean 100 episode reward": -200.0, "episodes": 205, "reward": -200.0, "steps": 40799}
{"mean 100 episode reward": -200.0, "episodes": 206, "reward": -200.0, "steps": 40999}
{"mean 100 episode reward": -200.0, "episodes": 207, "reward": -200.0, "steps": 41199}
{"mean 100 episode reward": -200.0, "episodes": 208, "reward": -200.0, "steps": 41399}
{"mean 100 episode reward": -200.0, "episodes": 209, "reward": -200.0, "steps": 41599}
{"mean 100 episode reward": -200.0, "episodes": 210, "reward": -200.0, "steps": 41799}
{"mean 100 episode reward": -200.0, "episodes": 211, "reward": -200.0, "steps": 41999}
{"mean 100 episode reward": -200.0, "episodes": 212, "reward": -200.0, "steps": 42199}
{"mean 100 episode reward": -200.0, "episodes": 213, "reward": -200.0, "steps": 42399}
{"mean 100 episode reward": -200.0, "episodes": 214, "reward": -200.0, "steps": 42599}
{"mean 100 episode reward": -200.0, "episodes": 215, "reward": -200.0, "steps": 42799}
{"mean 100 episode reward": -200.0, "episodes": 216, "reward": -200.0, "steps": 42999}
{"mean 100 episode reward": -200.0, "episodes": 217, "reward": -200.0, "steps": 43199}
{"mean 100 episode reward": -200.0, "episodes": 218, "reward": -200.0, "steps": 43399}
{"mean 100 episode reward": -200.0, "episodes": 219, "reward": -200.0, "steps": 43599}
{"mean 100 episode reward": -200.0, "episodes": 220, "reward": -200.0, "steps": 43799}
{"mean 100 episode reward": -200.0, "episodes": 221, "reward": -200.0, "steps": 43999}
{"mean 100 episode reward": -200.0, "episodes": 222, "reward": -200.0, "steps": 44199}
{"mean 100 episode reward": -200.0, "episodes": 223, "reward": -200.0, "steps": 44399}
{"mean 100 episode reward": -200.0, "episodes": 224, "reward": -200.0, "steps": 44599}
{"mean 100 episode reward": -200.0, "episodes": 225, "reward": -200.0, "steps": 44799}
{"mean 100 episode reward": -200.0, "episodes": 226, "reward": -200.0, "steps": 44999}
{"mean 100 episode reward": -200.0, "episodes": 227, "reward": -200.0, "steps": 45199}
{"mean 100 episode reward": -200.0, "episodes": 228, "reward": -200.0, "steps": 45399}
{"mean 100 episode reward": -200.0, "episodes": 229, "reward": -200.0, "steps": 45599}
{"mean 100 episode reward": -200.0, "episodes": 230, "reward": -200.0, "steps": 45799}
{"mean 100 episode reward": -200.0, "episodes": 231, "reward": -200.0, "steps": 45999}
{"mean 100 episode reward": -200.0, "episodes": 232, "reward": -200.0, "steps": 46199}
{"mean 100 episode reward": -200.0, "episodes": 233, "reward": -200.0, "steps": 46399}
{"mean 100 episode reward": -200.0, "episodes": 234, "reward": -200.0, "steps": 46599}
{"mean 100 episode reward": -200.0, "episodes": 235, "reward": -200.0, "steps": 46799}
{"mean 100 episode reward": -200.0, "episodes": 236, "reward": -200.0, "steps": 46999}
{"mean 100 episode reward": -200.0, "episodes": 237, "reward": -200.0, "steps": 47199}
{"mean 100 episode reward": -200.0, "episodes": 238, "reward": -200.0, "steps": 47399}
{"mean 100 episode reward": -200.0, "episodes": 239, "reward": -200.0, "steps": 47599}
{"mean 100 episode reward": -200.0, "episodes": 240, "reward": -200.0, "steps": 47799}
{"mean 100 episode reward": -200.0, "episodes": 241, "reward": -200.0, "steps": 47999}
{"mean 100 episode reward": -200.0, "episodes": 242, "reward": -200.0, "steps": 48199}
{"mean 100 episode reward": -200.0, "episodes": 243, "reward": -200.0, "steps": 48399}
{"mean 100 episode reward": -200.0, "episodes": 244, "reward": -200.0, "steps": 48599}
{"mean 100 episode reward": -200.0, "episodes": 245, "reward": -200.0, "steps": 48799}
{"mean 100 episode reward": -200.0, "episodes": 246, "reward": -200.0, "steps": 48999}
{"mean 100 episode reward": -200.0, "episodes": 247, "reward": -200.0, "steps": 49199}
{"mean 100 episode reward": -200.0, "episodes": 248, "reward": -200.0, "steps": 49399}
{"mean 100 episode reward": -200.0, "episodes": 249, "reward": -200.0, "steps": 49599}
{"mean 100 episode reward": -200.0, "episodes": 250, "reward": -200.0, "steps": 49799}
{"mean 100 episode reward": -200.0, "episodes": 251, "reward": -200.0, "steps": 49999}
{"mean 100 episode reward": -200.0, "episodes": 252, "reward": -200.0, "steps": 50199}
{"mean 100 episode reward": -200.0, "episodes": 253, "reward": -200.0, "steps": 50399}
{"mean 100 episode reward": -200.0, "episodes": 254, "reward": -200.0, "steps": 50599}
{"mean 100 episode reward": -200.0, "episodes": 255, "reward": -200.0, "steps": 50799}
{"mean 100 episode reward": -200.0, "episodes": 256, "reward": -200.0, "steps": 50999}
{"mean 100 episode reward": -200.0, "episodes": 257, "reward": -200.0, "steps": 51199}
{"mean 100 episode reward": -200.0, "episodes": 258, "reward": -200.0, "steps": 51399}
{"mean 100 episode reward": -200.0, "episodes": 259, "reward": -200.0, "steps": 51599}
{"mean 100 episode reward": -200.0, "episodes": 260, "reward": -200.0, "steps": 51799}
{"mean 100 episode reward": -200.0, "episodes": 261, "reward": -200.0, "steps": 51999}
{"mean 100 episode reward": -200.0, "episodes": 262, "reward": -200.0, "steps": 52199}
{"mean 100 episode reward": -200.0, "episodes": 263, "reward": -200.0, "steps": 52399}
{"mean 100 episode reward": -200.0, "episodes": 264, "reward": -200.0, "steps": 52599}
{"mean 100 episode reward": -200.0, "episodes": 265, "reward": -200.0, "steps": 52799}
{"mean 100 episode reward": -200.0, "episodes": 266, "reward": -200.0, "steps": 52999}
{"mean 100 episode reward": -200.0, "episodes": 267, "reward": -200.0, "steps": 53199}
{"mean 100 episode reward": -200.0, "episodes": 268, "reward": -200.0, "steps": 53399}
{"mean 100 episode reward": -200.0, "episodes": 269, "reward": -200.0, "steps": 53599}
{"mean 100 episode reward": -200.0, "episodes": 270, "reward": -200.0, "steps": 53799}
{"mean 100 episode reward": -200.0, "episodes": 271, "reward": -200.0, "steps": 53999}
{"mean 100 episode reward": -200.0, "episodes": 272, "reward": -200.0, "steps": 54199}
{"mean 100 episode reward": -200.0, "episodes": 273, "reward": -200.0, "steps": 54399}
{"mean 100 episode reward": -200.0, "episodes": 274, "reward": -200.0, "steps": 54599}
{"mean 100 episode reward": -200.0, "episodes": 275, "reward": -200.0, "steps": 54799}
{"mean 100 episode reward": -200.0, "episodes": 276, "reward": -200.0, "steps": 54999}
{"mean 100 episode reward": -200.0, "episodes": 277, "reward": -200.0, "steps": 55199}
{"mean 100 episode reward": -200.0, "episodes": 278, "reward": -200.0, "steps": 55399}
{"mean 100 episode reward": -200.0, "episodes": 279, "reward": -200.0, "steps": 55599}
{"mean 100 episode reward": -200.0, "episodes": 280, "reward": -200.0, "steps": 55799}
{"mean 100 episode reward": -200.0, "episodes": 281, "reward": -200.0, "steps": 55999}
{"mean 100 episode reward": -200.0, "episodes": 282, "reward": -200.0, "steps": 56199}
{"mean 100 episode reward": -200.0, "episodes": 283, "reward": -200.0, "steps": 56399}
{"mean 100 episode reward": -200.0, "episodes": 284, "reward": -200.0, "steps": 56599}
{"mean 100 episode reward": -200.0, "episodes": 285, "reward": -200.0, "steps": 56799}
{"mean 100 episode reward": -200.0, "episodes": 286, "reward": -200.0, "steps": 56999}
{"mean 100 episode reward": -200.0, "episodes": 287, "reward": -200.0, "steps": 57199}
{"mean 100 episode reward": -200.0, "episodes": 288, "reward": -200.0, "steps": 57399}
{"mean 100 episode reward": -200.0, "episodes": 289, "reward": -200.0, "steps": 57599}
{"mean 100 episode reward": -200.0, "episodes": 290, "reward": -200.0, "steps": 57799}
{"mean 100 episode reward": -200.0, "episodes": 291, "reward": -200.0, "steps": 57999}
{"mean 100 episode reward": -200.0, "episodes": 292, "reward": -200.0, "steps": 58199}
{"mean 100 episode reward": -200.0, "episodes": 293, "reward": -200.0, "steps": 58399}
{"mean 100 episode reward": -200.0, "episodes": 294, "reward": -200.0, "steps": 58599}
{"mean 100 episode reward": -200.0, "episodes": 295, "reward": -200.0, "steps": 58799}
{"mean 100 episode reward": -200.0, "episodes": 296, "reward": -200.0, "steps": 58999}
{"mean 100 episode reward": -200.0, "episodes": 297, "reward": -200.0, "steps": 59199}
{"mean 100 episode reward": -200.0, "episodes": 298, "reward": -200.0, "steps": 59399}
{"mean 100 episode reward": -200.0, "episodes": 299, "reward": -200.0, "steps": 59599}
{"mean 100 episode reward": -200.0, "episodes": 300, "reward": -200.0, "steps": 59799}
{"mean 100 episode reward": -200.0, "episodes": 301, "reward": -200.0, "steps": 59999}
{"mean 100 episode reward": -200.0, "episodes": 302, "reward": -200.0, "steps": 60199}
{"mean 100 episode reward": -200.0, "episodes": 303, "reward": -200.0, "steps": 60399}
{"mean 100 episode reward": -200.0, "episodes": 304, "reward": -200.0, "steps": 60599}
{"mean 100 episode reward": -200.0, "episodes": 305, "reward": -200.0, "steps": 60799}
{"mean 100 episode reward": -200.0, "episodes": 306, "reward": -200.0, "steps": 60999}
{"mean 100 episode reward": -200.0, "episodes": 307, "reward": -200.0, "steps": 61199}
{"mean 100 episode reward": -200.0, "episodes": 308, "reward": -200.0, "steps": 61399}
{"mean 100 episode reward": -200.0, "episodes": 309, "reward": -200.0, "steps": 61599}
{"mean 100 episode reward": -200.0, "episodes": 310, "reward": -200.0, "steps": 61799}
{"mean 100 episode reward": -200.0, "episodes": 311, "reward": -200.0, "steps": 61999}
{"mean 100 episode reward": -200.0, "episodes": 312, "reward": -200.0, "steps": 62199}
{"mean 100 episode reward": -200.0, "episodes": 313, "reward": -200.0, "steps": 62399}
{"mean 100 episode reward": -200.0, "episodes": 314, "reward": -200.0, "steps": 62599}
{"mean 100 episode reward": -200.0, "episodes": 315, "reward": -200.0, "steps": 62799}
{"mean 100 episode reward": -200.0, "episodes": 316, "reward": -200.0, "steps": 62999}
{"mean 100 episode reward": -200.0, "episodes": 317, "reward": -200.0, "steps": 63199}
{"mean 100 episode reward": -200.0, "episodes": 318, "reward": -200.0, "steps": 63399}
{"mean 100 episode reward": -200.0, "episodes": 319, "reward": -200.0, "steps": 63599}
{"mean 100 episode reward": -200.0, "episodes": 320, "reward": -200.0, "steps": 63799}
{"mean 100 episode reward": -200.0, "episodes": 321, "reward": -200.0, "steps": 63999}
{"mean 100 episode reward": -200.0, "episodes": 322, "reward": -200.0, "steps": 64199}
{"mean 100 episode reward": -200.0, "episodes": 323, "reward": -200.0, "steps": 64399}
{"mean 100 episode reward": -200.0, "episodes": 324, "reward": -200.0, "steps": 64599}
{"mean 100 episode reward": -200.0, "episodes": 325, "reward": -200.0, "steps": 64799}
{"mean 100 episode reward": -200.0, "episodes": 326, "reward": -200.0, "steps": 64999}
{"mean 100 episode reward": -200.0, "episodes": 327, "reward": -200.0, "steps": 65199}
{"mean 100 episode reward": -200.0, "episodes": 328, "reward": -200.0, "steps": 65399}
{"mean 100 episode reward": -200.0, "episodes": 329, "reward": -200.0, "steps": 65599}
{"mean 100 episode reward": -200.0, "episodes": 330, "reward": -200.0, "steps": 65799}
{"mean 100 episode reward": -200.0, "episodes": 331, "reward": -200.0, "steps": 65999}
{"mean 100 episode reward": -200.0, "episodes": 332, "reward": -200.0, "steps": 66199}
{"mean 100 episode reward": -200.0, "episodes": 333, "reward": -200.0, "steps": 66399}
{"mean 100 episode reward": -200.0, "episodes": 334, "reward": -200.0, "steps": 66599}
{"mean 100 episode reward": -200.0, "episodes": 335, "reward": -200.0, "steps": 66799}
{"mean 100 episode reward": -200.0, "episodes": 336, "reward": -200.0, "steps": 66999}
{"mean 100 episode reward": -200.0, "episodes": 337, "reward": -200.0, "steps": 67199}
{"mean 100 episode reward": -200.0, "episodes": 338, "reward": -200.0, "steps": 67399}
{"mean 100 episode reward": -200.0, "episodes": 339, "reward": -200.0, "steps": 67599}
{"mean 100 episode reward": -200.0, "episodes": 340, "reward": -200.0, "steps": 67799}
{"mean 100 episode reward": -200.0, "episodes": 341, "reward": -200.0, "steps": 67999}
{"mean 100 episode reward": -200.0, "episodes": 342, "reward": -200.0, "steps": 68199}
{"mean 100 episode reward": -200.0, "episodes": 343, "reward": -200.0, "steps": 68399}
{"mean 100 episode reward": -200.0, "episodes": 344, "reward": -200.0, "steps": 68599}
{"mean 100 episode reward": -200.0, "episodes": 345, "reward": -200.0, "steps": 68799}
{"mean 100 episode reward": -200.0, "episodes": 346, "reward": -200.0, "steps": 68999}
{"mean 100 episode reward": -200.0, "episodes": 347, "reward": -200.0, "steps": 69199}
{"mean 100 episode reward": -200.0, "episodes": 348, "reward": -200.0, "steps": 69399}
{"mean 100 episode reward": -200.0, "episodes": 349, "reward": -200.0, "steps": 69599}
