{"reward": -200.0, "head": 6, "% time spent exploring": 98, "mean 100 episode reward": -200.0, "episodes": 2, "steps": 199}
{"reward": -200.0, "head": 1, "% time spent exploring": 96, "mean 100 episode reward": -200.0, "episodes": 3, "steps": 399}
{"reward": -200.0, "head": 2, "% time spent exploring": 94, "mean 100 episode reward": -200.0, "episodes": 4, "steps": 599}
{"reward": -200.0, "head": 3, "% time spent exploring": 92, "mean 100 episode reward": -200.0, "episodes": 5, "steps": 799}
{"reward": -200.0, "head": 3, "% time spent exploring": 91, "mean 100 episode reward": -200.0, "episodes": 6, "steps": 999}
{"reward": -200.0, "head": 0, "% time spent exploring": 89, "mean 100 episode reward": -200.0, "episodes": 7, "steps": 1199}
{"reward": -200.0, "head": 6, "% time spent exploring": 87, "mean 100 episode reward": -200.0, "episodes": 8, "steps": 1399}
{"reward": -200.0, "head": 1, "% time spent exploring": 85, "mean 100 episode reward": -200.0, "episodes": 9, "steps": 1599}
{"reward": -200.0, "head": 4, "% time spent exploring": 83, "mean 100 episode reward": -200.0, "episodes": 10, "steps": 1799}
{"reward": -200.0, "head": 5, "% time spent exploring": 82, "mean 100 episode reward": -200.0, "episodes": 11, "steps": 1999}
{"reward": -200.0, "head": 9, "% time spent exploring": 80, "mean 100 episode reward": -200.0, "episodes": 12, "steps": 2199}
{"reward": -200.0, "head": 2, "% time spent exploring": 78, "mean 100 episode reward": -200.0, "episodes": 13, "steps": 2399}
{"reward": -200.0, "head": 6, "% time spent exploring": 76, "mean 100 episode reward": -200.0, "episodes": 14, "steps": 2599}
{"reward": -200.0, "head": 0, "% time spent exploring": 74, "mean 100 episode reward": -200.0, "episodes": 15, "steps": 2799}
{"reward": -200.0, "head": 5, "% time spent exploring": 73, "mean 100 episode reward": -200.0, "episodes": 16, "steps": 2999}
{"reward": -200.0, "head": 8, "% time spent exploring": 71, "mean 100 episode reward": -200.0, "episodes": 17, "steps": 3199}
{"reward": -200.0, "head": 2, "% time spent exploring": 69, "mean 100 episode reward": -200.0, "episodes": 18, "steps": 3399}
{"reward": -200.0, "head": 9, "% time spent exploring": 67, "mean 100 episode reward": -200.0, "episodes": 19, "steps": 3599}
{"reward": -200.0, "head": 3, "% time spent exploring": 65, "mean 100 episode reward": -200.0, "episodes": 20, "steps": 3799}
{"reward": -200.0, "head": 4, "% time spent exploring": 64, "mean 100 episode reward": -200.0, "episodes": 21, "steps": 3999}
{"reward": -200.0, "head": 3, "% time spent exploring": 62, "mean 100 episode reward": -200.0, "episodes": 22, "steps": 4199}
{"reward": -200.0, "head": 1, "% time spent exploring": 60, "mean 100 episode reward": -200.0, "episodes": 23, "steps": 4399}
{"reward": -200.0, "head": 7, "% time spent exploring": 58, "mean 100 episode reward": -200.0, "episodes": 24, "steps": 4599}
{"reward": -200.0, "head": 0, "% time spent exploring": 56, "mean 100 episode reward": -200.0, "episodes": 25, "steps": 4799}
{"reward": -200.0, "head": 2, "% time spent exploring": 55, "mean 100 episode reward": -200.0, "episodes": 26, "steps": 4999}
{"reward": -200.0, "head": 6, "% time spent exploring": 53, "mean 100 episode reward": -200.0, "episodes": 27, "steps": 5199}
{"reward": -200.0, "head": 2, "% time spent exploring": 51, "mean 100 episode reward": -200.0, "episodes": 28, "steps": 5399}
{"reward": -200.0, "head": 0, "% time spent exploring": 49, "mean 100 episode reward": -200.0, "episodes": 29, "steps": 5599}
{"reward": -200.0, "head": 4, "% time spent exploring": 47, "mean 100 episode reward": -200.0, "episodes": 30, "steps": 5799}
{"reward": -200.0, "head": 6, "% time spent exploring": 46, "mean 100 episode reward": -200.0, "episodes": 31, "steps": 5999}
{"reward": -200.0, "head": 9, "% time spent exploring": 44, "mean 100 episode reward": -200.0, "episodes": 32, "steps": 6199}
{"reward": -200.0, "head": 0, "% time spent exploring": 42, "mean 100 episode reward": -200.0, "episodes": 33, "steps": 6399}
{"reward": -200.0, "head": 0, "% time spent exploring": 40, "mean 100 episode reward": -200.0, "episodes": 34, "steps": 6599}
{"reward": -200.0, "head": 9, "% time spent exploring": 38, "mean 100 episode reward": -200.0, "episodes": 35, "steps": 6799}
{"reward": -200.0, "head": 8, "% time spent exploring": 37, "mean 100 episode reward": -200.0, "episodes": 36, "steps": 6999}
{"reward": -200.0, "head": 9, "% time spent exploring": 35, "mean 100 episode reward": -200.0, "episodes": 37, "steps": 7199}
{"reward": -200.0, "head": 6, "% time spent exploring": 33, "mean 100 episode reward": -200.0, "episodes": 38, "steps": 7399}
{"reward": -200.0, "head": 1, "% time spent exploring": 31, "mean 100 episode reward": -200.0, "episodes": 39, "steps": 7599}
{"reward": -200.0, "head": 8, "% time spent exploring": 29, "mean 100 episode reward": -200.0, "episodes": 40, "steps": 7799}
{"reward": -200.0, "head": 4, "% time spent exploring": 28, "mean 100 episode reward": -200.0, "episodes": 41, "steps": 7999}
{"reward": -200.0, "head": 0, "% time spent exploring": 26, "mean 100 episode reward": -200.0, "episodes": 42, "steps": 8199}
{"reward": -200.0, "head": 4, "% time spent exploring": 24, "mean 100 episode reward": -200.0, "episodes": 43, "steps": 8399}
{"reward": -200.0, "head": 1, "% time spent exploring": 22, "mean 100 episode reward": -200.0, "episodes": 44, "steps": 8599}
{"reward": -200.0, "head": 5, "% time spent exploring": 20, "mean 100 episode reward": -200.0, "episodes": 45, "steps": 8799}
{"reward": -200.0, "head": 5, "% time spent exploring": 19, "mean 100 episode reward": -200.0, "episodes": 46, "steps": 8999}
{"reward": -200.0, "head": 3, "% time spent exploring": 17, "mean 100 episode reward": -200.0, "episodes": 47, "steps": 9199}
{"reward": -200.0, "head": 4, "% time spent exploring": 15, "mean 100 episode reward": -200.0, "episodes": 48, "steps": 9399}
{"reward": -200.0, "head": 5, "% time spent exploring": 13, "mean 100 episode reward": -200.0, "episodes": 49, "steps": 9599}
{"reward": -200.0, "head": 5, "% time spent exploring": 11, "mean 100 episode reward": -200.0, "episodes": 50, "steps": 9799}
{"reward": -200.0, "head": 0, "% time spent exploring": 10, "mean 100 episode reward": -200.0, "episodes": 51, "steps": 9999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 52, "steps": 10199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 53, "steps": 10399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 54, "steps": 10599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 55, "steps": 10799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 56, "steps": 10999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 57, "steps": 11199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 58, "steps": 11399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 59, "steps": 11599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 60, "steps": 11799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 61, "steps": 11999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 62, "steps": 12199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 63, "steps": 12399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 64, "steps": 12599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 65, "steps": 12799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 66, "steps": 12999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 67, "steps": 13199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 68, "steps": 13399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 69, "steps": 13599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 70, "steps": 13799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 71, "steps": 13999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 72, "steps": 14199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 73, "steps": 14399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 74, "steps": 14599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 75, "steps": 14799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 76, "steps": 14999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 77, "steps": 15199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 78, "steps": 15399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 79, "steps": 15599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 80, "steps": 15799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 81, "steps": 15999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 82, "steps": 16199}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 83, "steps": 16399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 84, "steps": 16599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 85, "steps": 16799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 86, "steps": 16999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 87, "steps": 17199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 88, "steps": 17399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 89, "steps": 17599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 90, "steps": 17799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 91, "steps": 17999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 92, "steps": 18199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 93, "steps": 18399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 94, "steps": 18599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 95, "steps": 18799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 96, "steps": 18999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 97, "steps": 19199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 98, "steps": 19399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 99, "steps": 19599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 100, "steps": 19799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 101, "steps": 19999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 102, "steps": 20199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 103, "steps": 20399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 104, "steps": 20599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 105, "steps": 20799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 106, "steps": 20999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 107, "steps": 21199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 108, "steps": 21399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 109, "steps": 21599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 110, "steps": 21799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 111, "steps": 21999}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 112, "steps": 22199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 113, "steps": 22399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 114, "steps": 22599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 115, "steps": 22799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 116, "steps": 22999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 117, "steps": 23199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 118, "steps": 23399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 119, "steps": 23599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 120, "steps": 23799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 121, "steps": 23999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 122, "steps": 24199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 123, "steps": 24399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 124, "steps": 24599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 125, "steps": 24799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 126, "steps": 24999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 127, "steps": 25199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 128, "steps": 25399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 129, "steps": 25599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 130, "steps": 25799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 131, "steps": 25999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 132, "steps": 26199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 133, "steps": 26399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 134, "steps": 26599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 135, "steps": 26799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 136, "steps": 26999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 137, "steps": 27199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 138, "steps": 27399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 139, "steps": 27599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 140, "steps": 27799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 141, "steps": 27999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 142, "steps": 28199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 143, "steps": 28399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 144, "steps": 28599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 145, "steps": 28799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 146, "steps": 28999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 147, "steps": 29199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 148, "steps": 29399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 149, "steps": 29599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 150, "steps": 29799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 151, "steps": 29999}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 152, "steps": 30199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 153, "steps": 30399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 154, "steps": 30599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 155, "steps": 30799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 156, "steps": 30999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 157, "steps": 31199}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 158, "steps": 31399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 159, "steps": 31599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 160, "steps": 31799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 161, "steps": 31999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 162, "steps": 32199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 163, "steps": 32399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 164, "steps": 32599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 165, "steps": 32799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 166, "steps": 32999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 167, "steps": 33199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 168, "steps": 33399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 169, "steps": 33599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 170, "steps": 33799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 171, "steps": 33999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 172, "steps": 34199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 173, "steps": 34399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 174, "steps": 34599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 175, "steps": 34799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 176, "steps": 34999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 177, "steps": 35199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 178, "steps": 35399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 179, "steps": 35599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 180, "steps": 35799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 181, "steps": 35999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 182, "steps": 36199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 183, "steps": 36399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 184, "steps": 36599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 185, "steps": 36799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 186, "steps": 36999}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 187, "steps": 37199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 188, "steps": 37399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 189, "steps": 37599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 190, "steps": 37799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 191, "steps": 37999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 192, "steps": 38199}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 193, "steps": 38399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 194, "steps": 38599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 195, "steps": 38799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 196, "steps": 38999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 197, "steps": 39199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 198, "steps": 39399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 199, "steps": 39599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 200, "steps": 39799}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 201, "steps": 39999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 202, "steps": 40199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 203, "steps": 40399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 204, "steps": 40599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 205, "steps": 40799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 206, "steps": 40999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 207, "steps": 41199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 208, "steps": 41399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 209, "steps": 41599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 210, "steps": 41799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 211, "steps": 41999}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 212, "steps": 42199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 213, "steps": 42399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 214, "steps": 42599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 215, "steps": 42799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 216, "steps": 42999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 217, "steps": 43199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 218, "steps": 43399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 219, "steps": 43599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 220, "steps": 43799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 221, "steps": 43999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 222, "steps": 44199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 223, "steps": 44399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 224, "steps": 44599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 225, "steps": 44799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 226, "steps": 44999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 227, "steps": 45199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 228, "steps": 45399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 229, "steps": 45599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 230, "steps": 45799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 231, "steps": 45999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 232, "steps": 46199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 233, "steps": 46399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 234, "steps": 46599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 235, "steps": 46799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 236, "steps": 46999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 237, "steps": 47199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 238, "steps": 47399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 239, "steps": 47599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 240, "steps": 47799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 241, "steps": 47999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 242, "steps": 48199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 243, "steps": 48399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 244, "steps": 48599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 245, "steps": 48799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 246, "steps": 48999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 247, "steps": 49199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 248, "steps": 49399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 249, "steps": 49599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 250, "steps": 49799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 251, "steps": 49999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 252, "steps": 50199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 253, "steps": 50399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 254, "steps": 50599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 255, "steps": 50799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 256, "steps": 50999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 257, "steps": 51199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 258, "steps": 51399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 259, "steps": 51599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 260, "steps": 51799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 261, "steps": 51999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 262, "steps": 52199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 263, "steps": 52399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 264, "steps": 52599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 265, "steps": 52799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 266, "steps": 52999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 267, "steps": 53199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 268, "steps": 53399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 269, "steps": 53599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 270, "steps": 53799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 271, "steps": 53999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 272, "steps": 54199}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 273, "steps": 54399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 274, "steps": 54599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 275, "steps": 54799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 276, "steps": 54999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 277, "steps": 55199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 278, "steps": 55399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 279, "steps": 55599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 280, "steps": 55799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 281, "steps": 55999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 282, "steps": 56199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 283, "steps": 56399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 284, "steps": 56599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 285, "steps": 56799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 286, "steps": 56999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 287, "steps": 57199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 288, "steps": 57399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 289, "steps": 57599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 290, "steps": 57799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 291, "steps": 57999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 292, "steps": 58199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 293, "steps": 58399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 294, "steps": 58599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 295, "steps": 58799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 296, "steps": 58999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 297, "steps": 59199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 298, "steps": 59399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 299, "steps": 59599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 300, "steps": 59799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 301, "steps": 59999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 302, "steps": 60199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 303, "steps": 60399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 304, "steps": 60599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 305, "steps": 60799}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 306, "steps": 60999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 307, "steps": 61199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 308, "steps": 61399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 309, "steps": 61599}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 310, "steps": 61799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 311, "steps": 61999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 312, "steps": 62199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 313, "steps": 62399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 314, "steps": 62599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 315, "steps": 62799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 316, "steps": 62999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 317, "steps": 63199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 318, "steps": 63399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 319, "steps": 63599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 320, "steps": 63799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 321, "steps": 63999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 322, "steps": 64199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 323, "steps": 64399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 324, "steps": 64599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 325, "steps": 64799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 326, "steps": 64999}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 327, "steps": 65199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 328, "steps": 65399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 329, "steps": 65599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 330, "steps": 65799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 331, "steps": 65999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 332, "steps": 66199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 333, "steps": 66399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 334, "steps": 66599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 335, "steps": 66799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 336, "steps": 66999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 337, "steps": 67199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 338, "steps": 67399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 339, "steps": 67599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 340, "steps": 67799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 341, "steps": 67999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 342, "steps": 68199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 343, "steps": 68399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 344, "steps": 68599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 345, "steps": 68799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 346, "steps": 68999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 347, "steps": 69199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 348, "steps": 69399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 349, "steps": 69599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 350, "steps": 69799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 351, "steps": 69999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 352, "steps": 70199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 353, "steps": 70399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 354, "steps": 70599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 355, "steps": 70799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 356, "steps": 70999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 357, "steps": 71199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 358, "steps": 71399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 359, "steps": 71599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 360, "steps": 71799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 361, "steps": 71999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 362, "steps": 72199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 363, "steps": 72399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 364, "steps": 72599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 365, "steps": 72799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 366, "steps": 72999}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 367, "steps": 73199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 368, "steps": 73399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 369, "steps": 73599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 370, "steps": 73799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 371, "steps": 73999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 372, "steps": 74199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 373, "steps": 74399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 374, "steps": 74599}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 375, "steps": 74799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 376, "steps": 74999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 377, "steps": 75199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 378, "steps": 75399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 379, "steps": 75599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 380, "steps": 75799}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 381, "steps": 75999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 382, "steps": 76199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 383, "steps": 76399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 384, "steps": 76599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 385, "steps": 76799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 386, "steps": 76999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 387, "steps": 77199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 388, "steps": 77399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 389, "steps": 77599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 390, "steps": 77799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 391, "steps": 77999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 392, "steps": 78199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 393, "steps": 78399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 394, "steps": 78599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 395, "steps": 78799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 396, "steps": 78999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 397, "steps": 79199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 398, "steps": 79399}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 399, "steps": 79599}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 400, "steps": 79799}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 401, "steps": 79999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 402, "steps": 80199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 403, "steps": 80399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 404, "steps": 80599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 405, "steps": 80799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 406, "steps": 80999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 407, "steps": 81199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 408, "steps": 81399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 409, "steps": 81599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 410, "steps": 81799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 411, "steps": 81999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 412, "steps": 82199}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 413, "steps": 82399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 414, "steps": 82599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 415, "steps": 82799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 416, "steps": 82999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 417, "steps": 83199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 418, "steps": 83399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 419, "steps": 83599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 420, "steps": 83799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 421, "steps": 83999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 422, "steps": 84199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 423, "steps": 84399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 424, "steps": 84599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 425, "steps": 84799}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 426, "steps": 84999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 427, "steps": 85199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 428, "steps": 85399}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 429, "steps": 85599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 430, "steps": 85799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 431, "steps": 85999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 432, "steps": 86199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 433, "steps": 86399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 434, "steps": 86599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 435, "steps": 86799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 436, "steps": 86999}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 437, "steps": 87199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 438, "steps": 87399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 439, "steps": 87599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 440, "steps": 87799}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 441, "steps": 87999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 442, "steps": 88199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 443, "steps": 88399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 444, "steps": 88599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 445, "steps": 88799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 446, "steps": 88999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 447, "steps": 89199}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 448, "steps": 89399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 449, "steps": 89599}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 450, "steps": 89799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 451, "steps": 89999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 452, "steps": 90199}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 453, "steps": 90399}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 454, "steps": 90599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 455, "steps": 90799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 456, "steps": 90999}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 457, "steps": 91199}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 458, "steps": 91399}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 459, "steps": 91599}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 460, "steps": 91799}
{"reward": -200.0, "head": 5, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 461, "steps": 91999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 462, "steps": 92199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 463, "steps": 92399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 464, "steps": 92599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 465, "steps": 92799}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 466, "steps": 92999}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 467, "steps": 93199}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 468, "steps": 93399}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 469, "steps": 93599}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 470, "steps": 93799}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 471, "steps": 93999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 472, "steps": 94199}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 473, "steps": 94399}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 474, "steps": 94599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 475, "steps": 94799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 476, "steps": 94999}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 477, "steps": 95199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 478, "steps": 95399}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 479, "steps": 95599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 480, "steps": 95799}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 481, "steps": 95999}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 482, "steps": 96199}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 483, "steps": 96399}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 484, "steps": 96599}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 485, "steps": 96799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 486, "steps": 96999}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 487, "steps": 97199}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 488, "steps": 97399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 489, "steps": 97599}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 490, "steps": 97799}
{"reward": -200.0, "head": 6, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 491, "steps": 97999}
{"reward": -200.0, "head": 4, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 492, "steps": 98199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 493, "steps": 98399}
{"reward": -200.0, "head": 2, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 494, "steps": 98599}
{"reward": -200.0, "head": 8, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 495, "steps": 98799}
{"reward": -200.0, "head": 0, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 496, "steps": 98999}
{"reward": -200.0, "head": 1, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 497, "steps": 99199}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 498, "steps": 99399}
{"reward": -200.0, "head": 9, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 499, "steps": 99599}
{"reward": -200.0, "head": 7, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 500, "steps": 99799}
{"reward": -200.0, "head": 3, "% time spent exploring": 9, "mean 100 episode reward": -200.0, "episodes": 501, "steps": 99999}
