{"steps": 18, "mean 100 episode reward": 0.0, "% time spent exploring": 91, "episodes": 2, "reward": 0.004}
{"steps": 37, "mean 100 episode reward": 0.0, "% time spent exploring": 82, "episodes": 3, "reward": 0.005}
{"steps": 56, "mean 100 episode reward": 0.0, "% time spent exploring": 73, "episodes": 4, "reward": 0.001}
{"steps": 75, "mean 100 episode reward": 0.0, "% time spent exploring": 64, "episodes": 5, "reward": 0.007}
{"steps": 94, "mean 100 episode reward": 0.8, "% time spent exploring": 55, "episodes": 6, "reward": 4.0}
{"steps": 113, "mean 100 episode reward": 1.3, "% time spent exploring": 46, "episodes": 7, "reward": 4.0}
{"steps": 132, "mean 100 episode reward": 2.1, "% time spent exploring": 37, "episodes": 8, "reward": 7.0009999999999994}
{"steps": 151, "mean 100 episode reward": 2.9, "% time spent exploring": 28, "episodes": 9, "reward": 8.001}
{"steps": 170, "mean 100 episode reward": 3.4, "% time spent exploring": 19, "episodes": 10, "reward": 8.0}
{"steps": 189, "mean 100 episode reward": 4.3, "% time spent exploring": 10, "episodes": 11, "reward": 12.0}
{"steps": 208, "mean 100 episode reward": 4.8, "% time spent exploring": 9, "episodes": 12, "reward": 10.001}
{"steps": 227, "mean 100 episode reward": 5.3, "% time spent exploring": 9, "episodes": 13, "reward": 10.0}
{"steps": 246, "mean 100 episode reward": 5.2, "% time spent exploring": 9, "episodes": 14, "reward": 5.0}
{"steps": 265, "mean 100 episode reward": 5.6, "% time spent exploring": 9, "episodes": 15, "reward": 11.0}
{"steps": 284, "mean 100 episode reward": 6.0, "% time spent exploring": 9, "episodes": 16, "reward": 11.0}
{"steps": 303, "mean 100 episode reward": 6.3, "% time spent exploring": 9, "episodes": 17, "reward": 11.0}
{"steps": 322, "mean 100 episode reward": 6.6, "% time spent exploring": 9, "episodes": 18, "reward": 11.0}
{"steps": 341, "mean 100 episode reward": 6.9, "% time spent exploring": 9, "episodes": 19, "reward": 12.0}
{"steps": 360, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 20, "reward": 12.0}
{"steps": 379, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 21, "reward": 8.0}
{"steps": 398, "mean 100 episode reward": 7.4, "% time spent exploring": 9, "episodes": 22, "reward": 12.0}
{"steps": 417, "mean 100 episode reward": 7.5, "% time spent exploring": 9, "episodes": 23, "reward": 9.0}
{"steps": 436, "mean 100 episode reward": 7.5, "% time spent exploring": 9, "episodes": 24, "reward": 7.0}
{"steps": 455, "mean 100 episode reward": 7.7, "% time spent exploring": 9, "episodes": 25, "reward": 12.0}
{"steps": 474, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 26, "reward": 12.0}
{"steps": 493, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 27, "reward": 12.0}
{"steps": 512, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 28, "reward": 8.001}
{"steps": 531, "mean 100 episode reward": 8.1, "% time spent exploring": 9, "episodes": 29, "reward": 12.0}
{"steps": 550, "mean 100 episode reward": 8.2, "% time spent exploring": 9, "episodes": 30, "reward": 11.0}
{"steps": 569, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 31, "reward": 2.001}
{"steps": 588, "mean 100 episode reward": 8.1, "% time spent exploring": 9, "episodes": 32, "reward": 10.0}
{"steps": 607, "mean 100 episode reward": 8.2, "% time spent exploring": 9, "episodes": 33, "reward": 10.001}
{"steps": 626, "mean 100 episode reward": 8.3, "% time spent exploring": 9, "episodes": 34, "reward": 12.0}
{"steps": 645, "mean 100 episode reward": 8.4, "% time spent exploring": 9, "episodes": 35, "reward": 11.0}
{"steps": 664, "mean 100 episode reward": 8.4, "% time spent exploring": 9, "episodes": 36, "reward": 10.0}
{"steps": 683, "mean 100 episode reward": 8.3, "% time spent exploring": 9, "episodes": 37, "reward": 4.002}
{"steps": 702, "mean 100 episode reward": 8.4, "% time spent exploring": 9, "episodes": 38, "reward": 12.0}
{"steps": 721, "mean 100 episode reward": 8.4, "% time spent exploring": 9, "episodes": 39, "reward": 8.0}
{"steps": 740, "mean 100 episode reward": 8.5, "% time spent exploring": 9, "episodes": 40, "reward": 12.0}
{"steps": 759, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 41, "reward": 12.0}
{"steps": 778, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 42, "reward": 11.0}
{"steps": 797, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 43, "reward": 10.0}
{"steps": 816, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 44, "reward": 8.0}
{"steps": 835, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 45, "reward": 6.0}
{"steps": 854, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 46, "reward": 12.0}
{"steps": 873, "mean 100 episode reward": 8.7, "% time spent exploring": 9, "episodes": 47, "reward": 11.0}
{"steps": 892, "mean 100 episode reward": 8.7, "% time spent exploring": 9, "episodes": 48, "reward": 10.001}
{"steps": 911, "mean 100 episode reward": 8.8, "% time spent exploring": 9, "episodes": 49, "reward": 11.0}
{"steps": 930, "mean 100 episode reward": 8.8, "% time spent exploring": 9, "episodes": 50, "reward": 9.0}
{"steps": 949, "mean 100 episode reward": 8.8, "% time spent exploring": 9, "episodes": 51, "reward": 11.0}
{"steps": 968, "mean 100 episode reward": 8.8, "% time spent exploring": 9, "episodes": 52, "reward": 8.0}
{"steps": 987, "mean 100 episode reward": 8.9, "% time spent exploring": 9, "episodes": 53, "reward": 12.0}
{"steps": 1006, "mean 100 episode reward": 8.9, "% time spent exploring": 9, "episodes": 54, "reward": 10.0}
{"steps": 1025, "mean 100 episode reward": 8.9, "% time spent exploring": 9, "episodes": 55, "reward": 8.0}
{"steps": 1044, "mean 100 episode reward": 8.7, "% time spent exploring": 9, "episodes": 56, "reward": 0.001}
{"steps": 1063, "mean 100 episode reward": 8.6, "% time spent exploring": 9, "episodes": 57, "reward": 0.013000000000000005}
{"steps": 1082, "mean 100 episode reward": 8.4, "% time spent exploring": 9, "episodes": 58, "reward": 0.012000000000000004}
{"steps": 1101, "mean 100 episode reward": 8.3, "% time spent exploring": 9, "episodes": 59, "reward": 0.008}
{"steps": 1120, "mean 100 episode reward": 8.1, "% time spent exploring": 9, "episodes": 60, "reward": 0.001}
{"steps": 1139, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 61, "reward": 0.001}
{"steps": 1158, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 62, "reward": 10.0}
{"steps": 1177, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 63, "reward": 0.0}
{"steps": 1196, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 64, "reward": 0.0}
{"steps": 1215, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 65, "reward": 12.0}
{"steps": 1234, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 66, "reward": 9.0}
{"steps": 1253, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 67, "reward": 8.001}
{"steps": 1272, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 68, "reward": 9.001999999999999}
{"steps": 1291, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 69, "reward": 11.0}
{"steps": 1310, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 70, "reward": 9.0}
{"steps": 1329, "mean 100 episode reward": 8.0, "% time spent exploring": 9, "episodes": 71, "reward": 11.0}
{"steps": 1348, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 72, "reward": 0.006}
{"steps": 1367, "mean 100 episode reward": 7.9, "% time spent exploring": 9, "episodes": 73, "reward": 12.0}
{"steps": 1386, "mean 100 episode reward": 7.8, "% time spent exploring": 9, "episodes": 74, "reward": 0.0}
{"steps": 1405, "mean 100 episode reward": 7.7, "% time spent exploring": 9, "episodes": 75, "reward": 0.001}
{"steps": 1424, "mean 100 episode reward": 7.6, "% time spent exploring": 9, "episodes": 76, "reward": 0.010000000000000002}
{"steps": 1443, "mean 100 episode reward": 7.5, "% time spent exploring": 9, "episodes": 77, "reward": 0.001}
{"steps": 1462, "mean 100 episode reward": 7.4, "% time spent exploring": 9, "episodes": 78, "reward": 0.0}
{"steps": 1481, "mean 100 episode reward": 7.3, "% time spent exploring": 9, "episodes": 79, "reward": 0.0}
{"steps": 1500, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 80, "reward": 0.004}
{"steps": 1519, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 81, "reward": 6.0}
{"steps": 1538, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 82, "reward": 0.014000000000000005}
{"steps": 1557, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 83, "reward": 4.006}
{"steps": 1576, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 84, "reward": 12.0}
{"steps": 1595, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 85, "reward": 6.0}
{"steps": 1614, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 86, "reward": 10.0}
{"steps": 1633, "mean 100 episode reward": 7.2, "% time spent exploring": 9, "episodes": 87, "reward": 12.0}
{"steps": 1652, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 88, "reward": 0.0}
{"steps": 1671, "mean 100 episode reward": 7.0, "% time spent exploring": 9, "episodes": 89, "reward": 0.0}
{"steps": 1690, "mean 100 episode reward": 7.1, "% time spent exploring": 9, "episodes": 90, "reward": 10.0}
{"steps": 1709, "mean 100 episode reward": 7.0, "% time spent exploring": 9, "episodes": 91, "reward": 0.0}
{"steps": 1728, "mean 100 episode reward": 6.9, "% time spent exploring": 9, "episodes": 92, "reward": 0.001}
{"steps": 1747, "mean 100 episode reward": 6.8, "% time spent exploring": 9, "episodes": 93, "reward": 0.003}
{"steps": 1766, "mean 100 episode reward": 6.9, "% time spent exploring": 9, "episodes": 94, "reward": 8.0}
{"steps": 1785, "mean 100 episode reward": 6.8, "% time spent exploring": 9, "episodes": 95, "reward": 0.001}
{"steps": 1804, "mean 100 episode reward": 6.8, "% time spent exploring": 9, "episodes": 96, "reward": 11.0}
{"steps": 1823, "mean 100 episode reward": 6.8, "% time spent exploring": 9, "episodes": 97, "reward": 0.005}
{"steps": 1842, "mean 100 episode reward": 6.7, "% time spent exploring": 9, "episodes": 98, "reward": 0.006}
{"steps": 1861, "mean 100 episode reward": 6.7, "% time spent exploring": 9, "episodes": 99, "reward": 8.0}
{"steps": 1880, "mean 100 episode reward": 6.6, "% time spent exploring": 9, "episodes": 100, "reward": 0.007}
{"steps": 1899, "mean 100 episode reward": 6.7, "% time spent exploring": 9, "episodes": 101, "reward": 10.0}
