{"reward": 0.004, "mean 100 episode reward": 0.0, "steps": 18, "episodes": 2, "% time spent exploring": 95}
{"reward": 0.005, "mean 100 episode reward": 0.0, "steps": 37, "episodes": 3, "% time spent exploring": 91}
{"reward": 0.003, "mean 100 episode reward": 0.0, "steps": 56, "episodes": 4, "% time spent exploring": 86}
{"reward": 0.007, "mean 100 episode reward": 0.0, "steps": 75, "episodes": 5, "% time spent exploring": 82}
{"reward": 2.0, "mean 100 episode reward": 0.4, "steps": 94, "episodes": 6, "% time spent exploring": 77}
{"reward": 0.0, "mean 100 episode reward": 0.3, "steps": 113, "episodes": 7, "% time spent exploring": 73}
{"reward": 6.0009999999999994, "mean 100 episode reward": 1.1, "steps": 132, "episodes": 8, "% time spent exploring": 68}
{"reward": 7.0009999999999994, "mean 100 episode reward": 1.9, "steps": 151, "episodes": 9, "% time spent exploring": 64}
{"reward": 3.0, "mean 100 episode reward": 2.0, "steps": 170, "episodes": 10, "% time spent exploring": 59}
{"reward": 3.0, "mean 100 episode reward": 2.1, "steps": 189, "episodes": 11, "% time spent exploring": 55}
{"reward": 6.0009999999999994, "mean 100 episode reward": 2.5, "steps": 208, "episodes": 12, "% time spent exploring": 50}
{"reward": 0.002, "mean 100 episode reward": 2.3, "steps": 227, "episodes": 13, "% time spent exploring": 45}
{"reward": 0.0, "mean 100 episode reward": 2.1, "steps": 246, "episodes": 14, "% time spent exploring": 41}
{"reward": 10.0, "mean 100 episode reward": 2.6, "steps": 265, "episodes": 15, "% time spent exploring": 36}
{"reward": 4.0, "mean 100 episode reward": 2.7, "steps": 284, "episodes": 16, "% time spent exploring": 32}
{"reward": 6.0, "mean 100 episode reward": 2.9, "steps": 303, "episodes": 17, "% time spent exploring": 27}
{"reward": 7.0, "mean 100 episode reward": 3.2, "steps": 322, "episodes": 18, "% time spent exploring": 23}
{"reward": 12.0, "mean 100 episode reward": 3.7, "steps": 341, "episodes": 19, "% time spent exploring": 18}
{"reward": 12.0, "mean 100 episode reward": 4.1, "steps": 360, "episodes": 20, "% time spent exploring": 14}
{"reward": 8.0, "mean 100 episode reward": 4.3, "steps": 379, "episodes": 21, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 4.7, "steps": 398, "episodes": 22, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 4.9, "steps": 417, "episodes": 23, "% time spent exploring": 9}
{"reward": 7.0, "mean 100 episode reward": 5.0, "steps": 436, "episodes": 24, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 5.3, "steps": 455, "episodes": 25, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 5.5, "steps": 474, "episodes": 26, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 5.8, "steps": 493, "episodes": 27, "% time spent exploring": 9}
{"reward": 8.001, "mean 100 episode reward": 5.9, "steps": 512, "episodes": 28, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 6.1, "steps": 531, "episodes": 29, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 6.2, "steps": 550, "episodes": 30, "% time spent exploring": 9}
{"reward": 2.001, "mean 100 episode reward": 6.1, "steps": 569, "episodes": 31, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 6.2, "steps": 588, "episodes": 32, "% time spent exploring": 9}
{"reward": 10.001, "mean 100 episode reward": 6.3, "steps": 607, "episodes": 33, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 6.5, "steps": 626, "episodes": 34, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 6.6, "steps": 645, "episodes": 35, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 6.7, "steps": 664, "episodes": 36, "% time spent exploring": 9}
{"reward": 4.002, "mean 100 episode reward": 6.7, "steps": 683, "episodes": 37, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 6.8, "steps": 702, "episodes": 38, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 6.8, "steps": 721, "episodes": 39, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.0, "steps": 740, "episodes": 40, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.1, "steps": 759, "episodes": 41, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.2, "steps": 778, "episodes": 42, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.3, "steps": 797, "episodes": 43, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.3, "steps": 816, "episodes": 44, "% time spent exploring": 9}
{"reward": 6.0, "mean 100 episode reward": 7.3, "steps": 835, "episodes": 45, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.4, "steps": 854, "episodes": 46, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.4, "steps": 873, "episodes": 47, "% time spent exploring": 9}
{"reward": 10.001, "mean 100 episode reward": 7.5, "steps": 892, "episodes": 48, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.6, "steps": 911, "episodes": 49, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 7.6, "steps": 930, "episodes": 50, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.7, "steps": 949, "episodes": 51, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.7, "steps": 968, "episodes": 52, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.8, "steps": 987, "episodes": 53, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.8, "steps": 1006, "episodes": 54, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.8, "steps": 1025, "episodes": 55, "% time spent exploring": 9}
{"reward": 0.001, "mean 100 episode reward": 7.7, "steps": 1044, "episodes": 56, "% time spent exploring": 9}
{"reward": 0.0, "mean 100 episode reward": 7.5, "steps": 1063, "episodes": 57, "% time spent exploring": 9}
{"reward": 0.001, "mean 100 episode reward": 7.4, "steps": 1082, "episodes": 58, "% time spent exploring": 9}
{"reward": 0.006, "mean 100 episode reward": 7.3, "steps": 1101, "episodes": 59, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 7.3, "steps": 1120, "episodes": 60, "% time spent exploring": 9}
{"reward": 10.001, "mean 100 episode reward": 7.3, "steps": 1139, "episodes": 61, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.4, "steps": 1158, "episodes": 62, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.5, "steps": 1177, "episodes": 63, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.6, "steps": 1196, "episodes": 64, "% time spent exploring": 9}
{"reward": 6.0, "mean 100 episode reward": 7.5, "steps": 1215, "episodes": 65, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 7.6, "steps": 1234, "episodes": 66, "% time spent exploring": 9}
{"reward": 0.001, "mean 100 episode reward": 7.4, "steps": 1253, "episodes": 67, "% time spent exploring": 9}
{"reward": 7.002, "mean 100 episode reward": 7.4, "steps": 1272, "episodes": 68, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.5, "steps": 1291, "episodes": 69, "% time spent exploring": 9}
{"reward": 0.011000000000000003, "mean 100 episode reward": 7.4, "steps": 1310, "episodes": 70, "% time spent exploring": 9}
{"reward": 4.003, "mean 100 episode reward": 7.3, "steps": 1329, "episodes": 71, "% time spent exploring": 9}
{"reward": 0.0, "mean 100 episode reward": 7.2, "steps": 1348, "episodes": 72, "% time spent exploring": 9}
{"reward": 0.004, "mean 100 episode reward": 7.1, "steps": 1367, "episodes": 73, "% time spent exploring": 9}
{"reward": 0.012000000000000004, "mean 100 episode reward": 7.0, "steps": 1386, "episodes": 74, "% time spent exploring": 9}
{"reward": 10.001, "mean 100 episode reward": 7.1, "steps": 1405, "episodes": 75, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.1, "steps": 1424, "episodes": 76, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.2, "steps": 1443, "episodes": 77, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.2, "steps": 1462, "episodes": 78, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.3, "steps": 1481, "episodes": 79, "% time spent exploring": 9}
{"reward": 0.0, "mean 100 episode reward": 7.2, "steps": 1500, "episodes": 80, "% time spent exploring": 9}
{"reward": 6.0, "mean 100 episode reward": 7.2, "steps": 1519, "episodes": 81, "% time spent exploring": 9}
{"reward": 0.017000000000000008, "mean 100 episode reward": 7.1, "steps": 1538, "episodes": 82, "% time spent exploring": 9}
{"reward": 0.01900000000000001, "mean 100 episode reward": 7.0, "steps": 1557, "episodes": 83, "% time spent exploring": 9}
{"reward": 2.0, "mean 100 episode reward": 7.0, "steps": 1576, "episodes": 84, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.0, "steps": 1595, "episodes": 85, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.0, "steps": 1614, "episodes": 86, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.1, "steps": 1633, "episodes": 87, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.2, "steps": 1652, "episodes": 88, "% time spent exploring": 9}
{"reward": 5.0, "mean 100 episode reward": 7.1, "steps": 1671, "episodes": 89, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.2, "steps": 1690, "episodes": 90, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 7.2, "steps": 1709, "episodes": 91, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.2, "steps": 1728, "episodes": 92, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.2, "steps": 1747, "episodes": 93, "% time spent exploring": 9}
{"reward": 2.0, "mean 100 episode reward": 7.2, "steps": 1766, "episodes": 94, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.2, "steps": 1785, "episodes": 95, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.3, "steps": 1804, "episodes": 96, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.3, "steps": 1823, "episodes": 97, "% time spent exploring": 9}
{"reward": 9.001, "mean 100 episode reward": 7.3, "steps": 1842, "episodes": 98, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.3, "steps": 1861, "episodes": 99, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.4, "steps": 1880, "episodes": 100, "% time spent exploring": 9}
{"reward": 0.0, "mean 100 episode reward": 7.3, "steps": 1899, "episodes": 101, "% time spent exploring": 9}
{"reward": 7.0, "mean 100 episode reward": 7.4, "steps": 1918, "episodes": 102, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.5, "steps": 1937, "episodes": 103, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 7.6, "steps": 1956, "episodes": 104, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 7.7, "steps": 1975, "episodes": 105, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.8, "steps": 1994, "episodes": 106, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 7.9, "steps": 2013, "episodes": 107, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 7.9, "steps": 2032, "episodes": 108, "% time spent exploring": 9}
{"reward": 3.0069999999999997, "mean 100 episode reward": 7.9, "steps": 2051, "episodes": 109, "% time spent exploring": 9}
{"reward": 7.0009999999999994, "mean 100 episode reward": 7.9, "steps": 2070, "episodes": 110, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 8.0, "steps": 2089, "episodes": 111, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.0, "steps": 2108, "episodes": 112, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.1, "steps": 2127, "episodes": 113, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.2, "steps": 2146, "episodes": 114, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2165, "episodes": 115, "% time spent exploring": 9}
{"reward": 7.0009999999999994, "mean 100 episode reward": 8.3, "steps": 2184, "episodes": 116, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2203, "episodes": 117, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.4, "steps": 2222, "episodes": 118, "% time spent exploring": 9}
{"reward": 7.0009999999999994, "mean 100 episode reward": 8.3, "steps": 2241, "episodes": 119, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.3, "steps": 2260, "episodes": 120, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2279, "episodes": 121, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2298, "episodes": 122, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2317, "episodes": 123, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.4, "steps": 2336, "episodes": 124, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.4, "steps": 2355, "episodes": 125, "% time spent exploring": 9}
{"reward": 2.0, "mean 100 episode reward": 8.3, "steps": 2374, "episodes": 126, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2393, "episodes": 127, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2412, "episodes": 128, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2431, "episodes": 129, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2450, "episodes": 130, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 8.4, "steps": 2469, "episodes": 131, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.4, "steps": 2488, "episodes": 132, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2507, "episodes": 133, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 8.4, "steps": 2526, "episodes": 134, "% time spent exploring": 9}
{"reward": 5.006, "mean 100 episode reward": 8.3, "steps": 2545, "episodes": 135, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2564, "episodes": 136, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.4, "steps": 2583, "episodes": 137, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2602, "episodes": 138, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2621, "episodes": 139, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2640, "episodes": 140, "% time spent exploring": 9}
{"reward": 0.0, "mean 100 episode reward": 8.3, "steps": 2659, "episodes": 141, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2678, "episodes": 142, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.3, "steps": 2697, "episodes": 143, "% time spent exploring": 9}
{"reward": 6.0, "mean 100 episode reward": 8.3, "steps": 2716, "episodes": 144, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.4, "steps": 2735, "episodes": 145, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2754, "episodes": 146, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2773, "episodes": 147, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 8.3, "steps": 2792, "episodes": 148, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.3, "steps": 2811, "episodes": 149, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2830, "episodes": 150, "% time spent exploring": 9}
{"reward": 6.0, "mean 100 episode reward": 8.3, "steps": 2849, "episodes": 151, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2868, "episodes": 152, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.3, "steps": 2887, "episodes": 153, "% time spent exploring": 9}
{"reward": 0.001, "mean 100 episode reward": 8.2, "steps": 2906, "episodes": 154, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.3, "steps": 2925, "episodes": 155, "% time spent exploring": 9}
{"reward": 4.0009999999999994, "mean 100 episode reward": 8.3, "steps": 2944, "episodes": 156, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.4, "steps": 2963, "episodes": 157, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.5, "steps": 2982, "episodes": 158, "% time spent exploring": 9}
{"reward": 2.0, "mean 100 episode reward": 8.5, "steps": 3001, "episodes": 159, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.6, "steps": 3020, "episodes": 160, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.6, "steps": 3039, "episodes": 161, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.6, "steps": 3058, "episodes": 162, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.5, "steps": 3077, "episodes": 163, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.5, "steps": 3096, "episodes": 164, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 8.6, "steps": 3115, "episodes": 165, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.6, "steps": 3134, "episodes": 166, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.7, "steps": 3153, "episodes": 167, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 8.7, "steps": 3172, "episodes": 168, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.7, "steps": 3191, "episodes": 169, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 8.8, "steps": 3210, "episodes": 170, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 8.9, "steps": 3229, "episodes": 171, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.0, "steps": 3248, "episodes": 172, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.1, "steps": 3267, "episodes": 173, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.2, "steps": 3286, "episodes": 174, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 9.2, "steps": 3305, "episodes": 175, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.2, "steps": 3324, "episodes": 176, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.2, "steps": 3343, "episodes": 177, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.2, "steps": 3362, "episodes": 178, "% time spent exploring": 9}
{"reward": 5.0, "mean 100 episode reward": 9.1, "steps": 3381, "episodes": 179, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 9.2, "steps": 3400, "episodes": 180, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.2, "steps": 3419, "episodes": 181, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.3, "steps": 3438, "episodes": 182, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.5, "steps": 3457, "episodes": 183, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 9.6, "steps": 3476, "episodes": 184, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.6, "steps": 3495, "episodes": 185, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.6, "steps": 3514, "episodes": 186, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 9.5, "steps": 3533, "episodes": 187, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 9.5, "steps": 3552, "episodes": 188, "% time spent exploring": 9}
{"reward": 10.0, "mean 100 episode reward": 9.6, "steps": 3571, "episodes": 189, "% time spent exploring": 9}
{"reward": 8.0, "mean 100 episode reward": 9.5, "steps": 3590, "episodes": 190, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.6, "steps": 3609, "episodes": 191, "% time spent exploring": 9}
{"reward": 11.0, "mean 100 episode reward": 9.6, "steps": 3628, "episodes": 192, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.6, "steps": 3647, "episodes": 193, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.7, "steps": 3666, "episodes": 194, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.7, "steps": 3685, "episodes": 195, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.7, "steps": 3704, "episodes": 196, "% time spent exploring": 9}
{"reward": 9.0, "mean 100 episode reward": 9.7, "steps": 3723, "episodes": 197, "% time spent exploring": 9}
{"reward": 9.001, "mean 100 episode reward": 9.7, "steps": 3742, "episodes": 198, "% time spent exploring": 9}
{"reward": 12.0, "mean 100 episode reward": 9.8, "steps": 3761, "episodes": 199, "% time spent exploring": 9}
{"reward": 0.011000000000000003, "mean 100 episode reward": 9.6, "steps": 3780, "episodes": 200, "% time spent exploring": 9}
