{"reward": 0.001, "episodes": 2, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 99, "steps": 108}
{"reward": 0.0, "episodes": 3, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 99, "steps": 217}
{"reward": 0.002, "episodes": 4, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 98, "steps": 326}
{"reward": 0.02900000000000002, "episodes": 5, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 98, "steps": 435}
{"reward": 0.03300000000000002, "episodes": 6, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 97, "steps": 544}
{"reward": 0.004, "episodes": 7, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 97, "steps": 653}
{"reward": 0.026000000000000016, "episodes": 8, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 96, "steps": 762}
{"reward": 0.012000000000000004, "episodes": 9, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 96, "steps": 871}
{"reward": 0.03200000000000002, "episodes": 10, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 95, "steps": 980}
{"reward": 0.003, "episodes": 11, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 95, "steps": 1089}
{"reward": 0.02100000000000001, "episodes": 12, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 95, "steps": 1198}
{"reward": 0.001, "episodes": 13, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 94, "steps": 1307}
{"reward": 0.03300000000000002, "episodes": 14, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 94, "steps": 1416}
{"reward": 0.01800000000000001, "episodes": 15, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 93, "steps": 1525}
{"reward": 0.010000000000000002, "episodes": 16, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 93, "steps": 1634}
{"reward": 0.024000000000000014, "episodes": 17, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 92, "steps": 1743}
{"reward": 0.0, "episodes": 18, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 92, "steps": 1852}
{"reward": 0.025000000000000015, "episodes": 19, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 91, "steps": 1961}
{"reward": 0.005, "episodes": 20, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 91, "steps": 2070}
{"reward": 0.006, "episodes": 21, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 90, "steps": 2179}
{"reward": 0.0, "episodes": 22, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 90, "steps": 2288}
{"reward": 0.01800000000000001, "episodes": 23, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 90, "steps": 2397}
{"reward": 0.02900000000000002, "episodes": 24, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 89, "steps": 2506}
{"reward": 0.0, "episodes": 25, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 89, "steps": 2615}
{"reward": 0.009000000000000001, "episodes": 26, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 88, "steps": 2724}
{"reward": 0.002, "episodes": 27, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 88, "steps": 2833}
{"reward": 0.024000000000000014, "episodes": 28, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 87, "steps": 2942}
{"reward": 0.011000000000000003, "episodes": 29, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 87, "steps": 3051}
{"reward": 0.0, "episodes": 30, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 86, "steps": 3160}
{"reward": 0.0, "episodes": 31, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 86, "steps": 3269}
{"reward": 0.012000000000000004, "episodes": 32, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 86, "steps": 3378}
{"reward": 0.027000000000000017, "episodes": 33, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 85, "steps": 3487}
{"reward": 0.009000000000000001, "episodes": 34, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 85, "steps": 3596}
{"reward": 0.01800000000000001, "episodes": 35, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 84, "steps": 3705}
{"reward": 0.026000000000000016, "episodes": 36, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 84, "steps": 3814}
{"reward": 0.010000000000000002, "episodes": 37, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 83, "steps": 3923}
{"reward": 0.008, "episodes": 38, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 83, "steps": 4032}
{"reward": 0.008, "episodes": 39, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 82, "steps": 4141}
{"reward": 0.002, "episodes": 40, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 82, "steps": 4250}
{"reward": 0.006, "episodes": 41, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 81, "steps": 4359}
{"reward": 0.002, "episodes": 42, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 81, "steps": 4468}
{"reward": 0.0, "episodes": 43, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 81, "steps": 4577}
{"reward": 0.011000000000000003, "episodes": 44, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 80, "steps": 4686}
{"reward": 0.004, "episodes": 45, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 80, "steps": 4795}
{"reward": 0.012000000000000004, "episodes": 46, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 79, "steps": 4904}
{"reward": 0.023000000000000013, "episodes": 47, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 79, "steps": 5013}
{"reward": 0.012000000000000004, "episodes": 48, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 78, "steps": 5122}
{"reward": 0.0, "episodes": 49, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 78, "steps": 5231}
{"reward": 0.015000000000000006, "episodes": 50, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 77, "steps": 5340}
{"reward": 0.026000000000000016, "episodes": 51, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 77, "steps": 5449}
{"reward": 0.004, "episodes": 52, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 77, "steps": 5558}
{"reward": 0.03300000000000002, "episodes": 53, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 76, "steps": 5667}
{"reward": 0.002, "episodes": 54, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 76, "steps": 5776}
{"reward": 0.0, "episodes": 55, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 75, "steps": 5885}
{"reward": 0.03900000000000003, "episodes": 56, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 75, "steps": 5994}
{"reward": 0.035000000000000024, "episodes": 57, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 74, "steps": 6103}
{"reward": 0.03400000000000002, "episodes": 58, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 74, "steps": 6212}
{"reward": 0.03400000000000002, "episodes": 59, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 73, "steps": 6321}
{"reward": 0.02000000000000001, "episodes": 60, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 73, "steps": 6430}
{"reward": 0.0, "episodes": 61, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 72, "steps": 6539}
{"reward": 0.0, "episodes": 62, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 72, "steps": 6648}
{"reward": 0.04200000000000003, "episodes": 63, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 72, "steps": 6757}
{"reward": 0.03800000000000003, "episodes": 64, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 71, "steps": 6866}
{"reward": 0.002, "episodes": 65, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 71, "steps": 6975}
{"reward": 0.02000000000000001, "episodes": 66, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 70, "steps": 7084}
{"reward": 0.0, "episodes": 67, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 70, "steps": 7193}
{"reward": 0.001, "episodes": 68, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 69, "steps": 7302}
{"reward": 0.0, "episodes": 69, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 69, "steps": 7411}
{"reward": 0.007, "episodes": 70, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 68, "steps": 7520}
{"reward": 0.037000000000000026, "episodes": 71, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 68, "steps": 7629}
{"reward": 0.016000000000000007, "episodes": 72, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 68, "steps": 7738}
{"reward": 0.0, "episodes": 73, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 67, "steps": 7847}
{"reward": 0.0, "episodes": 74, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 67, "steps": 7956}
{"reward": 0.001, "episodes": 75, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 66, "steps": 8065}
{"reward": 0.011000000000000003, "episodes": 76, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 66, "steps": 8174}
{"reward": 0.0, "episodes": 77, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 65, "steps": 8283}
{"reward": 0.0, "episodes": 78, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 65, "steps": 8392}
{"reward": 0.004, "episodes": 79, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 64, "steps": 8501}
{"reward": 0.001, "episodes": 80, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 64, "steps": 8610}
{"reward": 0.002, "episodes": 81, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 63, "steps": 8719}
{"reward": 0.0, "episodes": 82, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 63, "steps": 8828}
{"reward": 0.004, "episodes": 83, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 63, "steps": 8937}
{"reward": 0.047000000000000035, "episodes": 84, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 62, "steps": 9046}
{"reward": 0.0, "episodes": 85, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 62, "steps": 9155}
{"reward": 0.002, "episodes": 86, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 61, "steps": 9264}
{"reward": 0.0, "episodes": 87, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 61, "steps": 9373}
{"reward": 0.0, "episodes": 88, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 60, "steps": 9482}
{"reward": 0.003, "episodes": 89, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 60, "steps": 9591}
{"reward": 0.04500000000000003, "episodes": 90, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 59, "steps": 9700}
{"reward": 0.023000000000000013, "episodes": 91, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 59, "steps": 9809}
{"reward": 0.0, "episodes": 92, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 59, "steps": 9918}
{"reward": 0.03200000000000002, "episodes": 93, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 58, "steps": 10027}
{"reward": 0.003, "episodes": 94, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 58, "steps": 10136}
{"reward": 0.05200000000000004, "episodes": 95, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 57, "steps": 10245}
{"reward": 0.0, "episodes": 96, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 57, "steps": 10354}
{"reward": 0.02900000000000002, "episodes": 97, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 56, "steps": 10463}
{"reward": 0.01900000000000001, "episodes": 98, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 56, "steps": 10572}
{"reward": 0.07200000000000005, "episodes": 99, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 55, "steps": 10681}
{"reward": 0.0, "episodes": 100, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 55, "steps": 10790}
{"reward": 0.02000000000000001, "episodes": 101, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 54, "steps": 10899}
{"reward": 0.057000000000000044, "episodes": 102, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 54, "steps": 11008}
{"reward": 0.003, "episodes": 103, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 54, "steps": 11117}
{"reward": 0.05300000000000004, "episodes": 104, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 53, "steps": 11226}
{"reward": 0.05000000000000004, "episodes": 105, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 53, "steps": 11335}
{"reward": 0.015000000000000006, "episodes": 106, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 52, "steps": 11444}
{"reward": 0.0, "episodes": 107, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 52, "steps": 11553}
{"reward": 0.002, "episodes": 108, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 51, "steps": 11662}
{"reward": 0.04300000000000003, "episodes": 109, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 51, "steps": 11771}
{"reward": 0.05600000000000004, "episodes": 110, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 50, "steps": 11880}
{"reward": 0.07000000000000005, "episodes": 111, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 50, "steps": 11989}
{"reward": 0.023000000000000013, "episodes": 112, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 50, "steps": 12098}
{"reward": 0.0, "episodes": 113, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 49, "steps": 12207}
{"reward": 0.03300000000000002, "episodes": 114, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 49, "steps": 12316}
{"reward": 0.027000000000000017, "episodes": 115, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 48, "steps": 12425}
{"reward": 0.03400000000000002, "episodes": 116, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 48, "steps": 12534}
{"reward": 0.02900000000000002, "episodes": 117, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 47, "steps": 12643}
{"reward": 0.04200000000000003, "episodes": 118, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 47, "steps": 12752}
{"reward": 0.001, "episodes": 119, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 46, "steps": 12861}
{"reward": 0.023000000000000013, "episodes": 120, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 46, "steps": 12970}
{"reward": 0.022000000000000013, "episodes": 121, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 45, "steps": 13079}
{"reward": 0.001, "episodes": 122, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 45, "steps": 13188}
{"reward": 0.013000000000000005, "episodes": 123, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 45, "steps": 13297}
{"reward": 0.0, "episodes": 124, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 44, "steps": 13406}
{"reward": 0.037000000000000026, "episodes": 125, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 44, "steps": 13515}
{"reward": 0.03900000000000003, "episodes": 126, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 43, "steps": 13624}
{"reward": 0.025000000000000015, "episodes": 127, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 43, "steps": 13733}
{"reward": 0.011000000000000003, "episodes": 128, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 42, "steps": 13842}
{"reward": 0.025000000000000015, "episodes": 129, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 42, "steps": 13951}
{"reward": 0.027000000000000017, "episodes": 130, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 41, "steps": 14060}
{"reward": 0.03900000000000003, "episodes": 131, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 41, "steps": 14169}
{"reward": 0.0, "episodes": 132, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 41, "steps": 14278}
{"reward": 0.02000000000000001, "episodes": 133, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 40, "steps": 14387}
{"reward": 0.04300000000000003, "episodes": 134, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 40, "steps": 14496}
{"reward": 0.037000000000000026, "episodes": 135, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 39, "steps": 14605}
{"reward": 0.02100000000000001, "episodes": 136, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 39, "steps": 14714}
{"reward": 0.03100000000000002, "episodes": 137, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 38, "steps": 14823}
{"reward": 0.060000000000000046, "episodes": 138, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 38, "steps": 14932}
{"reward": 0.023000000000000013, "episodes": 139, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 37, "steps": 15041}
{"reward": 0.03400000000000002, "episodes": 140, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 37, "steps": 15150}
{"reward": 0.05100000000000004, "episodes": 141, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 36, "steps": 15259}
{"reward": 0.05400000000000004, "episodes": 142, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 36, "steps": 15368}
{"reward": 0.04300000000000003, "episodes": 143, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 36, "steps": 15477}
{"reward": 0.024000000000000014, "episodes": 144, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 35, "steps": 15586}
{"reward": 0.04000000000000003, "episodes": 145, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 35, "steps": 15695}
{"reward": 0.003, "episodes": 146, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 34, "steps": 15804}
{"reward": 0.023000000000000013, "episodes": 147, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 34, "steps": 15913}
{"reward": 0.013000000000000005, "episodes": 148, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 33, "steps": 16022}
{"reward": 0.0, "episodes": 149, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 33, "steps": 16131}
{"reward": 0.060000000000000046, "episodes": 150, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 32, "steps": 16240}
{"reward": 0.02100000000000001, "episodes": 151, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 32, "steps": 16349}
{"reward": 0.0, "episodes": 152, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 32, "steps": 16458}
{"reward": 0.03400000000000002, "episodes": 153, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 31, "steps": 16567}
{"reward": 0.0, "episodes": 154, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 31, "steps": 16676}
{"reward": 0.002, "episodes": 155, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 30, "steps": 16785}
{"reward": 0.026000000000000016, "episodes": 156, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 30, "steps": 16894}
{"reward": 0.03900000000000003, "episodes": 157, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 29, "steps": 17003}
{"reward": 0.03200000000000002, "episodes": 158, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 29, "steps": 17112}
{"reward": 0.0, "episodes": 159, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 28, "steps": 17221}
{"reward": 0.006, "episodes": 160, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 28, "steps": 17330}
{"reward": 0.04400000000000003, "episodes": 161, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 27, "steps": 17439}
{"reward": 0.007, "episodes": 162, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 27, "steps": 17548}
{"reward": 0.013000000000000005, "episodes": 163, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 27, "steps": 17657}
{"reward": 0.007, "episodes": 164, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 26, "steps": 17766}
{"reward": 0.07200000000000005, "episodes": 165, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 26, "steps": 17875}
{"reward": 0.04200000000000003, "episodes": 166, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 25, "steps": 17984}
{"reward": 0.06400000000000004, "episodes": 167, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 25, "steps": 18093}
{"reward": 0.01800000000000001, "episodes": 168, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 24, "steps": 18202}
{"reward": 0.006, "episodes": 169, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 24, "steps": 18311}
{"reward": 0.005, "episodes": 170, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 23, "steps": 18420}
{"reward": 0.005, "episodes": 171, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 23, "steps": 18529}
{"reward": 0.005, "episodes": 172, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 23, "steps": 18638}
{"reward": 0.09100000000000007, "episodes": 173, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 22, "steps": 18747}
{"reward": 0.05400000000000004, "episodes": 174, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 22, "steps": 18856}
{"reward": 0.04000000000000003, "episodes": 175, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 21, "steps": 18965}
{"reward": 0.007, "episodes": 176, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 21, "steps": 19074}
{"reward": 0.012000000000000004, "episodes": 177, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 20, "steps": 19183}
{"reward": 0.009000000000000001, "episodes": 178, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 20, "steps": 19292}
{"reward": 0.04200000000000003, "episodes": 179, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 19, "steps": 19401}
{"reward": 0.009000000000000001, "episodes": 180, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 19, "steps": 19510}
{"reward": 0.023000000000000013, "episodes": 181, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 18, "steps": 19619}
{"reward": 0.007, "episodes": 182, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 18, "steps": 19728}
{"reward": 0.0, "episodes": 183, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 18, "steps": 19837}
{"reward": 0.027000000000000017, "episodes": 184, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 17, "steps": 19946}
{"reward": 0.027000000000000017, "episodes": 185, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 17, "steps": 20055}
{"reward": 0.026000000000000016, "episodes": 186, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 16, "steps": 20164}
{"reward": 0.05400000000000004, "episodes": 187, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 16, "steps": 20273}
{"reward": 0.05100000000000004, "episodes": 188, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 15, "steps": 20382}
{"reward": 0.08500000000000006, "episodes": 189, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 15, "steps": 20491}
{"reward": 0.058000000000000045, "episodes": 190, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 14, "steps": 20600}
{"reward": 0.07200000000000005, "episodes": 191, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 14, "steps": 20709}
{"reward": 0.0, "episodes": 192, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 14, "steps": 20818}
{"reward": 0.10400000000000008, "episodes": 193, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 13, "steps": 20927}
{"reward": 0.07600000000000005, "episodes": 194, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 13, "steps": 21036}
{"reward": 0.03200000000000002, "episodes": 195, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 12, "steps": 21145}
{"reward": 0.014000000000000005, "episodes": 196, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 12, "steps": 21254}
{"reward": 0.007, "episodes": 197, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 11, "steps": 21363}
{"reward": 0.06700000000000005, "episodes": 198, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 11, "steps": 21472}
{"reward": 0.03200000000000002, "episodes": 199, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 10, "steps": 21581}
{"reward": 0.037000000000000026, "episodes": 200, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 10, "steps": 21690}
{"reward": 0.01800000000000001, "episodes": 201, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 21799}
{"reward": 0.02100000000000001, "episodes": 202, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 21908}
{"reward": 0.08200000000000006, "episodes": 203, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 22017}
{"reward": 0.06700000000000005, "episodes": 204, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 22126}
{"reward": 0.035000000000000024, "episodes": 205, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 22235}
{"reward": 0.03300000000000002, "episodes": 206, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 22344}
{"reward": 0.005, "episodes": 207, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 22453}
{"reward": 0.05400000000000004, "episodes": 208, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 22562}
{"reward": 0.005, "episodes": 209, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 22671}
{"reward": 0.07500000000000005, "episodes": 210, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 22780}
{"reward": 0.007, "episodes": 211, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 22889}
{"reward": 0.0, "episodes": 212, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 22998}
{"reward": 0.0, "episodes": 213, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 23107}
{"reward": 0.08700000000000006, "episodes": 214, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 23216}
{"reward": 0.04400000000000003, "episodes": 215, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 23325}
{"reward": 0.06900000000000005, "episodes": 216, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 23434}
{"reward": 0.07100000000000005, "episodes": 217, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 23543}
{"reward": 0.03400000000000002, "episodes": 218, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 23652}
{"reward": 0.09100000000000007, "episodes": 219, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 23761}
{"reward": 0.08800000000000006, "episodes": 220, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 23870}
{"reward": 0.04200000000000003, "episodes": 221, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 23979}
{"reward": 0.058000000000000045, "episodes": 222, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 24088}
{"reward": 0.04400000000000003, "episodes": 223, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 24197}
{"reward": 0.06500000000000004, "episodes": 224, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 24306}
{"reward": 0.07000000000000005, "episodes": 225, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 24415}
{"reward": 0.06700000000000005, "episodes": 226, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 24524}
{"reward": 0.035000000000000024, "episodes": 227, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 24633}
{"reward": 0.04400000000000003, "episodes": 228, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 24742}
{"reward": 0.008, "episodes": 229, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 24851}
{"reward": 0.06600000000000004, "episodes": 230, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 24960}
{"reward": 0.05300000000000004, "episodes": 231, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 25069}
{"reward": 0.08000000000000006, "episodes": 232, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 25178}
{"reward": 0.03000000000000002, "episodes": 233, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 25287}
{"reward": 0.02100000000000001, "episodes": 234, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 25396}
{"reward": 0.058000000000000045, "episodes": 235, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 25505}
{"reward": 0.059000000000000045, "episodes": 236, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 25614}
{"reward": 0.03800000000000003, "episodes": 237, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 25723}
{"reward": 0.05300000000000004, "episodes": 238, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 25832}
{"reward": 0.07900000000000006, "episodes": 239, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 25941}
{"reward": 0.022000000000000013, "episodes": 240, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 26050}
{"reward": 0.027000000000000017, "episodes": 241, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 26159}
{"reward": 0.06400000000000004, "episodes": 242, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 26268}
{"reward": 0.025000000000000015, "episodes": 243, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 26377}
{"reward": 0.06700000000000005, "episodes": 244, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 26486}
{"reward": 0.05500000000000004, "episodes": 245, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 26595}
{"reward": 0.046000000000000034, "episodes": 246, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 26704}
{"reward": 0.06200000000000005, "episodes": 247, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 26813}
{"reward": 0.05300000000000004, "episodes": 248, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 26922}
{"reward": 0.05000000000000004, "episodes": 249, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 27031}
{"reward": 0.03400000000000002, "episodes": 250, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 27140}
{"reward": 0.046000000000000034, "episodes": 251, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 27249}
{"reward": 0.08300000000000006, "episodes": 252, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 27358}
{"reward": 0.05600000000000004, "episodes": 253, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 27467}
{"reward": 0.017000000000000008, "episodes": 254, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 27576}
{"reward": 0.03800000000000003, "episodes": 255, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 27685}
{"reward": 0.05200000000000004, "episodes": 256, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 27794}
{"reward": 0.016000000000000007, "episodes": 257, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 27903}
{"reward": 0.05100000000000004, "episodes": 258, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 28012}
{"reward": 0.04900000000000004, "episodes": 259, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 28121}
{"reward": 0.02900000000000002, "episodes": 260, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 28230}
{"reward": 0.06300000000000004, "episodes": 261, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 28339}
{"reward": 0.07800000000000006, "episodes": 262, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 28448}
{"reward": 0.03300000000000002, "episodes": 263, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 28557}
{"reward": 0.036000000000000025, "episodes": 264, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 28666}
{"reward": 0.060000000000000046, "episodes": 265, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 28775}
{"reward": 0.037000000000000026, "episodes": 266, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 28884}
{"reward": 0.06900000000000005, "episodes": 267, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 28993}
{"reward": 0.06100000000000005, "episodes": 268, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 29102}
{"reward": 0.059000000000000045, "episodes": 269, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 29211}
{"reward": 0.04100000000000003, "episodes": 270, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 29320}
{"reward": 0.03800000000000003, "episodes": 271, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 29429}
{"reward": 0.07500000000000005, "episodes": 272, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 29538}
{"reward": 0.03800000000000003, "episodes": 273, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 29647}
{"reward": 0.07200000000000005, "episodes": 274, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 29756}
{"reward": 0.025000000000000015, "episodes": 275, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 29865}
{"reward": 0.03900000000000003, "episodes": 276, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 29974}
{"reward": 0.03800000000000003, "episodes": 277, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 30083}
{"reward": 0.04400000000000003, "episodes": 278, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 30192}
{"reward": 0.047000000000000035, "episodes": 279, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 30301}
{"reward": 0.05200000000000004, "episodes": 280, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 30410}
{"reward": 0.07000000000000005, "episodes": 281, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 30519}
{"reward": 0.07500000000000005, "episodes": 282, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 30628}
{"reward": 0.002, "episodes": 283, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 30737}
{"reward": 0.025000000000000015, "episodes": 284, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 30846}
{"reward": 0.057000000000000044, "episodes": 285, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 30955}
{"reward": 0.017000000000000008, "episodes": 286, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 31064}
{"reward": 0.013000000000000005, "episodes": 287, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 31173}
{"reward": 0.012000000000000004, "episodes": 288, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 31282}
{"reward": 0.07200000000000005, "episodes": 289, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 31391}
{"reward": 0.03800000000000003, "episodes": 290, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 31500}
{"reward": 0.05600000000000004, "episodes": 291, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 31609}
{"reward": 0.037000000000000026, "episodes": 292, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 31718}
{"reward": 0.06800000000000005, "episodes": 293, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 31827}
{"reward": 0.04300000000000003, "episodes": 294, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 31936}
{"reward": 0.02000000000000001, "episodes": 295, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 32045}
{"reward": 0.010000000000000002, "episodes": 296, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 32154}
{"reward": 0.0, "episodes": 297, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 32263}
{"reward": 0.035000000000000024, "episodes": 298, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 32372}
{"reward": 0.046000000000000034, "episodes": 299, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 32481}
{"reward": 0.007, "episodes": 300, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 32590}
{"reward": 0.057000000000000044, "episodes": 301, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 32699}
{"reward": 0.05000000000000004, "episodes": 302, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 32808}
{"reward": 0.04400000000000003, "episodes": 303, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 32917}
{"reward": 0.024000000000000014, "episodes": 304, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 33026}
{"reward": 0.01900000000000001, "episodes": 305, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 33135}
{"reward": 0.017000000000000008, "episodes": 306, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 33244}
{"reward": 0.013000000000000005, "episodes": 307, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 33353}
{"reward": 0.03000000000000002, "episodes": 308, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 33462}
{"reward": 0.03900000000000003, "episodes": 309, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 33571}
{"reward": 0.023000000000000013, "episodes": 310, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 33680}
{"reward": 0.059000000000000045, "episodes": 311, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 33789}
{"reward": 0.04200000000000003, "episodes": 312, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 33898}
{"reward": 0.010000000000000002, "episodes": 313, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 34007}
{"reward": 0.046000000000000034, "episodes": 314, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 34116}
{"reward": 0.008, "episodes": 315, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 34225}
{"reward": 0.006, "episodes": 316, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 34334}
{"reward": 0.04500000000000003, "episodes": 317, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 34443}
{"reward": 0.06200000000000005, "episodes": 318, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 34552}
{"reward": 0.015000000000000006, "episodes": 319, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 34661}
{"reward": 0.04300000000000003, "episodes": 320, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 34770}
{"reward": 0.023000000000000013, "episodes": 321, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 34879}
{"reward": 0.037000000000000026, "episodes": 322, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 34988}
{"reward": 0.036000000000000025, "episodes": 323, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 35097}
{"reward": 0.10000000000000007, "episodes": 324, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 35206}
{"reward": 0.0, "episodes": 325, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 35315}
{"reward": 0.017000000000000008, "episodes": 326, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 35424}
{"reward": 0.0, "episodes": 327, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 35533}
{"reward": 0.037000000000000026, "episodes": 328, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 35642}
{"reward": 0.06400000000000004, "episodes": 329, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 35751}
{"reward": 0.060000000000000046, "episodes": 330, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 35860}
{"reward": 0.017000000000000008, "episodes": 331, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 35969}
{"reward": 0.060000000000000046, "episodes": 332, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 36078}
{"reward": 0.09700000000000007, "episodes": 333, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 36187}
{"reward": 0.0, "episodes": 334, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 36296}
{"reward": 0.05300000000000004, "episodes": 335, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 36405}
{"reward": 0.04000000000000003, "episodes": 336, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 36514}
{"reward": 0.07700000000000005, "episodes": 337, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 36623}
{"reward": 0.04400000000000003, "episodes": 338, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 36732}
{"reward": 0.036000000000000025, "episodes": 339, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 36841}
{"reward": 0.025000000000000015, "episodes": 340, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 36950}
{"reward": 0.04300000000000003, "episodes": 341, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 37059}
{"reward": 0.04000000000000003, "episodes": 342, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 37168}
{"reward": 0.03100000000000002, "episodes": 343, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 37277}
{"reward": 0.011000000000000003, "episodes": 344, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 37386}
{"reward": 0.06300000000000004, "episodes": 345, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 37495}
{"reward": 0.02100000000000001, "episodes": 346, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 37604}
{"reward": 0.04200000000000003, "episodes": 347, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 37713}
{"reward": 0.04100000000000003, "episodes": 348, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 37822}
{"reward": 0.03000000000000002, "episodes": 349, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 37931}
{"reward": 0.04400000000000003, "episodes": 350, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 38040}
{"reward": 0.026000000000000016, "episodes": 351, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 38149}
{"reward": 0.022000000000000013, "episodes": 352, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 38258}
{"reward": 0.026000000000000016, "episodes": 353, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 38367}
{"reward": 0.02000000000000001, "episodes": 354, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 38476}
{"reward": 0.07400000000000005, "episodes": 355, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 38585}
{"reward": 0.05200000000000004, "episodes": 356, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 38694}
{"reward": 0.010000000000000002, "episodes": 357, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 38803}
{"reward": 0.022000000000000013, "episodes": 358, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 38912}
{"reward": 0.05300000000000004, "episodes": 359, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 39021}
{"reward": 0.05400000000000004, "episodes": 360, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 39130}
{"reward": 0.03100000000000002, "episodes": 361, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 39239}
{"reward": 0.04100000000000003, "episodes": 362, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 39348}
{"reward": 0.024000000000000014, "episodes": 363, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 39457}
{"reward": 0.024000000000000014, "episodes": 364, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 39566}
{"reward": 0.08100000000000006, "episodes": 365, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 39675}
{"reward": 0.04300000000000003, "episodes": 366, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 39784}
{"reward": 0.046000000000000034, "episodes": 367, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 39893}
{"reward": 0.04300000000000003, "episodes": 368, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 40002}
{"reward": 0.03000000000000002, "episodes": 369, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 40111}
{"reward": 0.04000000000000003, "episodes": 370, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 40220}
{"reward": 0.06500000000000004, "episodes": 371, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 40329}
{"reward": 0.05000000000000004, "episodes": 372, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 40438}
{"reward": 0.0, "episodes": 373, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 40547}
{"reward": 0.059000000000000045, "episodes": 374, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 40656}
{"reward": 0.035000000000000024, "episodes": 375, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 40765}
{"reward": 0.05100000000000004, "episodes": 376, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 40874}
{"reward": 0.04300000000000003, "episodes": 377, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 40983}
{"reward": 0.04000000000000003, "episodes": 378, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 41092}
{"reward": 0.05200000000000004, "episodes": 379, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 41201}
{"reward": 0.0, "episodes": 380, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 41310}
{"reward": 0.023000000000000013, "episodes": 381, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 41419}
{"reward": 0.03900000000000003, "episodes": 382, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 41528}
{"reward": 0.07000000000000005, "episodes": 383, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 41637}
{"reward": 0.04000000000000003, "episodes": 384, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 41746}
{"reward": 0.05200000000000004, "episodes": 385, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 41855}
{"reward": 0.037000000000000026, "episodes": 386, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 41964}
{"reward": 0.013000000000000005, "episodes": 387, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 42073}
{"reward": 0.03300000000000002, "episodes": 388, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 42182}
{"reward": 0.07200000000000005, "episodes": 389, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 42291}
{"reward": 0.013000000000000005, "episodes": 390, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 42400}
{"reward": 0.057000000000000044, "episodes": 391, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 42509}
{"reward": 0.05500000000000004, "episodes": 392, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 42618}
{"reward": 0.047000000000000035, "episodes": 393, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 42727}
{"reward": 0.03200000000000002, "episodes": 394, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 42836}
{"reward": 0.010000000000000002, "episodes": 395, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 42945}
{"reward": 0.060000000000000046, "episodes": 396, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 43054}
{"reward": 0.002, "episodes": 397, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 43163}
{"reward": 0.03000000000000002, "episodes": 398, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 43272}
{"reward": 0.06200000000000005, "episodes": 399, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 43381}
{"reward": 0.04500000000000003, "episodes": 400, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 43490}
{"reward": 0.03200000000000002, "episodes": 401, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 43599}
{"reward": 0.04400000000000003, "episodes": 402, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 43708}
{"reward": 0.03900000000000003, "episodes": 403, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 43817}
{"reward": 0.013000000000000005, "episodes": 404, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 43926}
{"reward": 0.009000000000000001, "episodes": 405, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 44035}
{"reward": 0.05600000000000004, "episodes": 406, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 44144}
{"reward": 0.03000000000000002, "episodes": 407, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 44253}
{"reward": 0.015000000000000006, "episodes": 408, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 44362}
{"reward": 0.07500000000000005, "episodes": 409, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 44471}
{"reward": 0.01800000000000001, "episodes": 410, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 44580}
{"reward": 0.04000000000000003, "episodes": 411, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 44689}
{"reward": 0.04400000000000003, "episodes": 412, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 44798}
{"reward": 0.02900000000000002, "episodes": 413, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 44907}
{"reward": 0.02000000000000001, "episodes": 414, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 45016}
{"reward": 0.04200000000000003, "episodes": 415, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 45125}
{"reward": 0.048000000000000036, "episodes": 416, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 45234}
{"reward": 0.06600000000000004, "episodes": 417, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 45343}
{"reward": 0.035000000000000024, "episodes": 418, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 45452}
{"reward": 0.06300000000000004, "episodes": 419, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 45561}
{"reward": 0.025000000000000015, "episodes": 420, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 45670}
{"reward": 0.015000000000000006, "episodes": 421, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 45779}
{"reward": 0.012000000000000004, "episodes": 422, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 45888}
{"reward": 0.028000000000000018, "episodes": 423, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 45997}
{"reward": 0.03800000000000003, "episodes": 424, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 46106}
{"reward": 0.03100000000000002, "episodes": 425, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 46215}
{"reward": 0.04400000000000003, "episodes": 426, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 46324}
{"reward": 0.07900000000000006, "episodes": 427, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 46433}
{"reward": 0.03300000000000002, "episodes": 428, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 46542}
{"reward": 0.037000000000000026, "episodes": 429, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 46651}
{"reward": 0.03300000000000002, "episodes": 430, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 46760}
{"reward": 0.03800000000000003, "episodes": 431, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 46869}
{"reward": 0.06200000000000005, "episodes": 432, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 46978}
{"reward": 0.06100000000000005, "episodes": 433, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 47087}
{"reward": 0.002, "episodes": 434, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 47196}
{"reward": 0.07700000000000005, "episodes": 435, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 47305}
{"reward": 0.04100000000000003, "episodes": 436, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 47414}
{"reward": 0.013000000000000005, "episodes": 437, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 47523}
{"reward": 0.037000000000000026, "episodes": 438, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 47632}
{"reward": 0.047000000000000035, "episodes": 439, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 47741}
{"reward": 0.04200000000000003, "episodes": 440, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 47850}
{"reward": 0.05300000000000004, "episodes": 441, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 47959}
{"reward": 0.004, "episodes": 442, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 48068}
{"reward": 0.03900000000000003, "episodes": 443, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 48177}
{"reward": 0.014000000000000005, "episodes": 444, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 48286}
{"reward": 0.03200000000000002, "episodes": 445, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 48395}
{"reward": 0.06300000000000004, "episodes": 446, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 48504}
{"reward": 0.03900000000000003, "episodes": 447, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 48613}
{"reward": 0.016000000000000007, "episodes": 448, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 48722}
{"reward": 0.046000000000000034, "episodes": 449, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 48831}
{"reward": 0.037000000000000026, "episodes": 450, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 48940}
{"reward": 0.03800000000000003, "episodes": 451, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 49049}
{"reward": 0.04300000000000003, "episodes": 452, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 49158}
{"reward": 0.06900000000000005, "episodes": 453, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 49267}
{"reward": 0.059000000000000045, "episodes": 454, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 49376}
{"reward": 0.0, "episodes": 455, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 49485}
{"reward": 0.01900000000000001, "episodes": 456, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 49594}
{"reward": 0.01900000000000001, "episodes": 457, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 49703}
{"reward": 0.04200000000000003, "episodes": 458, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 49812}
{"reward": 0.03300000000000002, "episodes": 459, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 49921}
{"reward": 0.008, "episodes": 460, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 50030}
{"reward": 0.035000000000000024, "episodes": 461, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 50139}
{"reward": 0.02100000000000001, "episodes": 462, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 50248}
{"reward": 0.060000000000000046, "episodes": 463, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 50357}
{"reward": 0.022000000000000013, "episodes": 464, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 50466}
{"reward": 0.058000000000000045, "episodes": 465, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 50575}
{"reward": 0.03400000000000002, "episodes": 466, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 50684}
{"reward": 0.047000000000000035, "episodes": 467, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 50793}
{"reward": 0.058000000000000045, "episodes": 468, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 50902}
{"reward": 0.03300000000000002, "episodes": 469, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 51011}
{"reward": 0.06200000000000005, "episodes": 470, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 51120}
{"reward": 0.03800000000000003, "episodes": 471, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 51229}
{"reward": 0.060000000000000046, "episodes": 472, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 51338}
{"reward": 0.04100000000000003, "episodes": 473, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 51447}
{"reward": 0.035000000000000024, "episodes": 474, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 51556}
{"reward": 0.027000000000000017, "episodes": 475, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 51665}
{"reward": 0.04900000000000004, "episodes": 476, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 51774}
{"reward": 0.01900000000000001, "episodes": 477, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 51883}
{"reward": 0.025000000000000015, "episodes": 478, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 51992}
{"reward": 0.022000000000000013, "episodes": 479, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 52101}
{"reward": 0.04500000000000003, "episodes": 480, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 52210}
{"reward": 0.024000000000000014, "episodes": 481, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 52319}
{"reward": 0.05000000000000004, "episodes": 482, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 52428}
{"reward": 0.023000000000000013, "episodes": 483, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 52537}
{"reward": 0.04500000000000003, "episodes": 484, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 52646}
{"reward": 0.002, "episodes": 485, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 52755}
{"reward": 0.017000000000000008, "episodes": 486, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 52864}
{"reward": 0.028000000000000018, "episodes": 487, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 52973}
{"reward": 0.036000000000000025, "episodes": 488, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 53082}
{"reward": 0.01800000000000001, "episodes": 489, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 53191}
{"reward": 0.07000000000000005, "episodes": 490, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 53300}
{"reward": 0.024000000000000014, "episodes": 491, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 53409}
{"reward": 0.013000000000000005, "episodes": 492, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 53518}
{"reward": 0.06700000000000005, "episodes": 493, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 53627}
{"reward": 0.04900000000000004, "episodes": 494, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 53736}
{"reward": 0.02100000000000001, "episodes": 495, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 53845}
{"reward": 0.06500000000000004, "episodes": 496, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 53954}
{"reward": 0.01900000000000001, "episodes": 497, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 54063}
{"reward": 0.046000000000000034, "episodes": 498, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 54172}
{"reward": 0.05300000000000004, "episodes": 499, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 54281}
{"reward": 0.05500000000000004, "episodes": 500, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 54390}
{"reward": 0.0, "episodes": 501, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 54499}
{"reward": 0.003, "episodes": 502, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 54608}
{"reward": 0.06700000000000005, "episodes": 503, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 54717}
{"reward": 0.048000000000000036, "episodes": 504, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 54826}
{"reward": 0.03300000000000002, "episodes": 505, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 54935}
{"reward": 0.06600000000000004, "episodes": 506, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 55044}
{"reward": 0.03800000000000003, "episodes": 507, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 55153}
{"reward": 0.02100000000000001, "episodes": 508, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 55262}
{"reward": 0.057000000000000044, "episodes": 509, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 55371}
{"reward": 0.022000000000000013, "episodes": 510, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 55480}
{"reward": 0.027000000000000017, "episodes": 511, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 55589}
{"reward": 0.006, "episodes": 512, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 55698}
{"reward": 0.027000000000000017, "episodes": 513, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 55807}
{"reward": 0.024000000000000014, "episodes": 514, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 55916}
{"reward": 0.047000000000000035, "episodes": 515, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 56025}
{"reward": 0.05300000000000004, "episodes": 516, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 56134}
{"reward": 0.014000000000000005, "episodes": 517, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 56243}
{"reward": 0.012000000000000004, "episodes": 518, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 56352}
{"reward": 0.011000000000000003, "episodes": 519, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 56461}
{"reward": 0.07100000000000005, "episodes": 520, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 56570}
{"reward": 0.046000000000000034, "episodes": 521, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 56679}
{"reward": 0.04000000000000003, "episodes": 522, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 56788}
{"reward": 0.03400000000000002, "episodes": 523, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 56897}
{"reward": 0.036000000000000025, "episodes": 524, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 57006}
{"reward": 0.047000000000000035, "episodes": 525, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 57115}
{"reward": 0.06600000000000004, "episodes": 526, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 57224}
{"reward": 0.03300000000000002, "episodes": 527, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 57333}
{"reward": 0.06200000000000005, "episodes": 528, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 57442}
{"reward": 0.04400000000000003, "episodes": 529, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 57551}
{"reward": 0.003, "episodes": 530, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 57660}
{"reward": 0.004, "episodes": 531, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 57769}
{"reward": 0.060000000000000046, "episodes": 532, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 57878}
{"reward": 0.024000000000000014, "episodes": 533, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 57987}
{"reward": 0.024000000000000014, "episodes": 534, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 58096}
{"reward": 0.01800000000000001, "episodes": 535, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 58205}
{"reward": 0.02100000000000001, "episodes": 536, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 58314}
{"reward": 0.04900000000000004, "episodes": 537, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 58423}
{"reward": 0.05300000000000004, "episodes": 538, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 58532}
{"reward": 0.058000000000000045, "episodes": 539, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 58641}
{"reward": 0.009000000000000001, "episodes": 540, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 58750}
{"reward": 0.025000000000000015, "episodes": 541, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 58859}
{"reward": 0.05400000000000004, "episodes": 542, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 58968}
{"reward": 0.028000000000000018, "episodes": 543, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 59077}
{"reward": 0.04100000000000003, "episodes": 544, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 59186}
{"reward": 0.04900000000000004, "episodes": 545, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 59295}
{"reward": 0.017000000000000008, "episodes": 546, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 59404}
{"reward": 0.08000000000000006, "episodes": 547, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 59513}
{"reward": 0.08400000000000006, "episodes": 548, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 59622}
{"reward": 0.028000000000000018, "episodes": 549, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 59731}
{"reward": 0.007, "episodes": 550, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 59840}
{"reward": 0.008, "episodes": 551, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 59949}
{"reward": 0.04500000000000003, "episodes": 552, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 60058}
{"reward": 0.06800000000000005, "episodes": 553, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 60167}
{"reward": 0.03400000000000002, "episodes": 554, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 60276}
{"reward": 0.007, "episodes": 555, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 60385}
{"reward": 0.09200000000000007, "episodes": 556, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 60494}
{"reward": 0.05500000000000004, "episodes": 557, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 60603}
{"reward": 0.03800000000000003, "episodes": 558, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 60712}
{"reward": 0.06800000000000005, "episodes": 559, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 60821}
{"reward": 0.026000000000000016, "episodes": 560, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 60930}
{"reward": 0.048000000000000036, "episodes": 561, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 61039}
{"reward": 0.024000000000000014, "episodes": 562, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 61148}
{"reward": 0.04400000000000003, "episodes": 563, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 61257}
{"reward": 0.03300000000000002, "episodes": 564, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 61366}
{"reward": 0.05400000000000004, "episodes": 565, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 61475}
{"reward": 0.02000000000000001, "episodes": 566, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 61584}
{"reward": 0.024000000000000014, "episodes": 567, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 61693}
{"reward": 0.04200000000000003, "episodes": 568, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 61802}
{"reward": 0.06700000000000005, "episodes": 569, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 61911}
{"reward": 0.08200000000000006, "episodes": 570, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 62020}
{"reward": 0.014000000000000005, "episodes": 571, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 62129}
{"reward": 0.05100000000000004, "episodes": 572, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 62238}
{"reward": 0.06300000000000004, "episodes": 573, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 62347}
{"reward": 0.03100000000000002, "episodes": 574, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 62456}
{"reward": 0.09300000000000007, "episodes": 575, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 62565}
{"reward": 0.03100000000000002, "episodes": 576, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 62674}
{"reward": 0.0, "episodes": 577, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 62783}
{"reward": 0.037000000000000026, "episodes": 578, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 62892}
{"reward": 0.028000000000000018, "episodes": 579, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 63001}
{"reward": 0.027000000000000017, "episodes": 580, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 63110}
{"reward": 0.03000000000000002, "episodes": 581, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 63219}
{"reward": 0.03400000000000002, "episodes": 582, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 63328}
{"reward": 0.060000000000000046, "episodes": 583, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 63437}
{"reward": 0.05000000000000004, "episodes": 584, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 63546}
{"reward": 0.05500000000000004, "episodes": 585, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 63655}
{"reward": 0.03100000000000002, "episodes": 586, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 63764}
{"reward": 0.04500000000000003, "episodes": 587, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 63873}
{"reward": 0.025000000000000015, "episodes": 588, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 63982}
{"reward": 0.07700000000000005, "episodes": 589, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 64091}
{"reward": 0.010000000000000002, "episodes": 590, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 64200}
{"reward": 0.059000000000000045, "episodes": 591, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 64309}
{"reward": 0.022000000000000013, "episodes": 592, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 64418}
{"reward": 0.016000000000000007, "episodes": 593, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 64527}
{"reward": 0.026000000000000016, "episodes": 594, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 64636}
{"reward": 0.08100000000000006, "episodes": 595, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 64745}
{"reward": 0.036000000000000025, "episodes": 596, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 64854}
{"reward": 0.025000000000000015, "episodes": 597, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 64963}
{"reward": 0.035000000000000024, "episodes": 598, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 65072}
{"reward": 0.03900000000000003, "episodes": 599, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 65181}
{"reward": 0.08000000000000006, "episodes": 600, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 65290}
{"reward": 0.02100000000000001, "episodes": 601, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 65399}
{"reward": 0.035000000000000024, "episodes": 602, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 65508}
{"reward": 0.025000000000000015, "episodes": 603, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 65617}
{"reward": 0.04300000000000003, "episodes": 604, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 65726}
{"reward": 0.046000000000000034, "episodes": 605, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 65835}
{"reward": 0.04500000000000003, "episodes": 606, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 65944}
{"reward": 0.022000000000000013, "episodes": 607, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 66053}
{"reward": 0.058000000000000045, "episodes": 608, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 66162}
{"reward": 0.012000000000000004, "episodes": 609, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 66271}
{"reward": 0.09400000000000007, "episodes": 610, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 66380}
{"reward": 0.06300000000000004, "episodes": 611, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 66489}
{"reward": 0.07000000000000005, "episodes": 612, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 66598}
{"reward": 0.03800000000000003, "episodes": 613, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 66707}
{"reward": 0.03400000000000002, "episodes": 614, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 66816}
{"reward": 0.010000000000000002, "episodes": 615, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 66925}
{"reward": 0.048000000000000036, "episodes": 616, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 67034}
{"reward": 0.03100000000000002, "episodes": 617, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 67143}
{"reward": 0.025000000000000015, "episodes": 618, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 67252}
{"reward": 0.06300000000000004, "episodes": 619, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 67361}
{"reward": 0.010000000000000002, "episodes": 620, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 67470}
{"reward": 0.04900000000000004, "episodes": 621, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 67579}
{"reward": 0.023000000000000013, "episodes": 622, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 67688}
{"reward": 0.048000000000000036, "episodes": 623, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 67797}
{"reward": 0.05600000000000004, "episodes": 624, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 67906}
{"reward": 0.05000000000000004, "episodes": 625, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 68015}
{"reward": 0.02900000000000002, "episodes": 626, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 68124}
{"reward": 0.04000000000000003, "episodes": 627, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 68233}
{"reward": 0.047000000000000035, "episodes": 628, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 68342}
{"reward": 0.026000000000000016, "episodes": 629, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 68451}
{"reward": 0.028000000000000018, "episodes": 630, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 68560}
{"reward": 0.011000000000000003, "episodes": 631, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 68669}
{"reward": 0.013000000000000005, "episodes": 632, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 68778}
{"reward": 0.035000000000000024, "episodes": 633, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 68887}
{"reward": 0.04100000000000003, "episodes": 634, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 68996}
{"reward": 0.04100000000000003, "episodes": 635, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 69105}
{"reward": 0.03100000000000002, "episodes": 636, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 69214}
{"reward": 0.06200000000000005, "episodes": 637, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 69323}
{"reward": 0.046000000000000034, "episodes": 638, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 69432}
{"reward": 0.06200000000000005, "episodes": 639, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 69541}
{"reward": 0.04300000000000003, "episodes": 640, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 69650}
{"reward": 0.06700000000000005, "episodes": 641, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 69759}
{"reward": 0.035000000000000024, "episodes": 642, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 69868}
{"reward": 0.01800000000000001, "episodes": 643, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 69977}
{"reward": 0.027000000000000017, "episodes": 644, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 70086}
{"reward": 0.035000000000000024, "episodes": 645, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 70195}
{"reward": 0.05000000000000004, "episodes": 646, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 70304}
{"reward": 0.016000000000000007, "episodes": 647, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 70413}
{"reward": 0.046000000000000034, "episodes": 648, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 70522}
{"reward": 0.03800000000000003, "episodes": 649, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 70631}
{"reward": 0.07200000000000005, "episodes": 650, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 70740}
{"reward": 0.05600000000000004, "episodes": 651, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 70849}
{"reward": 0.03200000000000002, "episodes": 652, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 70958}
{"reward": 0.05100000000000004, "episodes": 653, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 71067}
{"reward": 0.02000000000000001, "episodes": 654, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 71176}
{"reward": 0.06100000000000005, "episodes": 655, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 71285}
{"reward": 0.016000000000000007, "episodes": 656, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 71394}
{"reward": 0.026000000000000016, "episodes": 657, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 71503}
{"reward": 0.04200000000000003, "episodes": 658, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 71612}
{"reward": 0.014000000000000005, "episodes": 659, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 71721}
{"reward": 0.007, "episodes": 660, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 71830}
{"reward": 0.05100000000000004, "episodes": 661, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 71939}
{"reward": 0.02000000000000001, "episodes": 662, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 72048}
{"reward": 0.06700000000000005, "episodes": 663, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 72157}
{"reward": 0.05600000000000004, "episodes": 664, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 72266}
{"reward": 0.028000000000000018, "episodes": 665, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 72375}
{"reward": 0.027000000000000017, "episodes": 666, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 72484}
{"reward": 0.08100000000000006, "episodes": 667, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 72593}
{"reward": 0.04900000000000004, "episodes": 668, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 72702}
{"reward": 0.03300000000000002, "episodes": 669, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 72811}
{"reward": 0.03000000000000002, "episodes": 670, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 72920}
{"reward": 0.05400000000000004, "episodes": 671, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 73029}
{"reward": 0.022000000000000013, "episodes": 672, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 73138}
{"reward": 0.015000000000000006, "episodes": 673, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 73247}
{"reward": 0.02900000000000002, "episodes": 674, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 73356}
{"reward": 0.06300000000000004, "episodes": 675, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 73465}
{"reward": 0.06800000000000005, "episodes": 676, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 73574}
{"reward": 0.01900000000000001, "episodes": 677, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 73683}
{"reward": 0.04500000000000003, "episodes": 678, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 73792}
{"reward": 0.07600000000000005, "episodes": 679, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 73901}
{"reward": 0.05200000000000004, "episodes": 680, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 74010}
{"reward": 0.05300000000000004, "episodes": 681, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 74119}
{"reward": 0.04900000000000004, "episodes": 682, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 74228}
{"reward": 0.008, "episodes": 683, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 74337}
{"reward": 0.10200000000000008, "episodes": 684, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 74446}
{"reward": 0.025000000000000015, "episodes": 685, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 74555}
{"reward": 0.026000000000000016, "episodes": 686, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 74664}
{"reward": 0.03300000000000002, "episodes": 687, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 74773}
{"reward": 0.04100000000000003, "episodes": 688, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 74882}
{"reward": 0.023000000000000013, "episodes": 689, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 74991}
{"reward": 0.03100000000000002, "episodes": 690, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 75100}
{"reward": 0.037000000000000026, "episodes": 691, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 75209}
{"reward": 0.013000000000000005, "episodes": 692, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 75318}
{"reward": 0.058000000000000045, "episodes": 693, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 75427}
{"reward": 0.037000000000000026, "episodes": 694, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 75536}
{"reward": 0.04100000000000003, "episodes": 695, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 75645}
{"reward": 0.03200000000000002, "episodes": 696, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 75754}
{"reward": 0.03900000000000003, "episodes": 697, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 75863}
{"reward": 0.017000000000000008, "episodes": 698, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 75972}
{"reward": 0.07000000000000005, "episodes": 699, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 76081}
{"reward": 0.037000000000000026, "episodes": 700, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 76190}
{"reward": 0.012000000000000004, "episodes": 701, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 76299}
{"reward": 0.04900000000000004, "episodes": 702, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 76408}
{"reward": 0.04500000000000003, "episodes": 703, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 76517}
{"reward": 0.04000000000000003, "episodes": 704, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 76626}
{"reward": 0.048000000000000036, "episodes": 705, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 76735}
{"reward": 0.05400000000000004, "episodes": 706, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 76844}
{"reward": 0.0, "episodes": 707, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 76953}
{"reward": 0.03900000000000003, "episodes": 708, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 77062}
{"reward": 0.05500000000000004, "episodes": 709, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 77171}
{"reward": 0.013000000000000005, "episodes": 710, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 77280}
{"reward": 0.010000000000000002, "episodes": 711, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 77389}
{"reward": 0.03800000000000003, "episodes": 712, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 77498}
{"reward": 0.04000000000000003, "episodes": 713, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 77607}
{"reward": 0.047000000000000035, "episodes": 714, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 77716}
{"reward": 0.05600000000000004, "episodes": 715, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 77825}
{"reward": 0.048000000000000036, "episodes": 716, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 77934}
{"reward": 0.02100000000000001, "episodes": 717, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 78043}
{"reward": 0.07400000000000005, "episodes": 718, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 78152}
{"reward": 0.006, "episodes": 719, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 78261}
{"reward": 0.036000000000000025, "episodes": 720, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 78370}
{"reward": 0.047000000000000035, "episodes": 721, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 78479}
{"reward": 0.014000000000000005, "episodes": 722, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 78588}
{"reward": 0.012000000000000004, "episodes": 723, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 78697}
{"reward": 0.06100000000000005, "episodes": 724, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 78806}
{"reward": 0.03900000000000003, "episodes": 725, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 78915}
{"reward": 0.08600000000000006, "episodes": 726, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 79024}
{"reward": 0.05400000000000004, "episodes": 727, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 79133}
{"reward": 0.05200000000000004, "episodes": 728, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 79242}
{"reward": 0.028000000000000018, "episodes": 729, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 79351}
{"reward": 0.02900000000000002, "episodes": 730, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 79460}
{"reward": 0.05000000000000004, "episodes": 731, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 79569}
{"reward": 0.036000000000000025, "episodes": 732, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 79678}
{"reward": 0.04500000000000003, "episodes": 733, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 79787}
{"reward": 0.03100000000000002, "episodes": 734, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 79896}
{"reward": 0.06900000000000005, "episodes": 735, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 80005}
{"reward": 0.046000000000000034, "episodes": 736, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 80114}
{"reward": 0.03800000000000003, "episodes": 737, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 80223}
{"reward": 0.059000000000000045, "episodes": 738, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 80332}
{"reward": 0.05500000000000004, "episodes": 739, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 80441}
{"reward": 0.05000000000000004, "episodes": 740, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 80550}
{"reward": 0.015000000000000006, "episodes": 741, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 80659}
{"reward": 0.014000000000000005, "episodes": 742, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 80768}
{"reward": 0.05500000000000004, "episodes": 743, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 80877}
{"reward": 0.017000000000000008, "episodes": 744, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 80986}
{"reward": 0.04900000000000004, "episodes": 745, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 81095}
{"reward": 0.03400000000000002, "episodes": 746, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 81204}
{"reward": 0.037000000000000026, "episodes": 747, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 81313}
{"reward": 0.017000000000000008, "episodes": 748, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 81422}
{"reward": 0.01800000000000001, "episodes": 749, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 81531}
{"reward": 0.03000000000000002, "episodes": 750, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 81640}
{"reward": 0.006, "episodes": 751, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 81749}
{"reward": 0.026000000000000016, "episodes": 752, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 81858}
{"reward": 0.025000000000000015, "episodes": 753, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 81967}
{"reward": 0.05000000000000004, "episodes": 754, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 82076}
{"reward": 0.046000000000000034, "episodes": 755, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 82185}
{"reward": 0.03000000000000002, "episodes": 756, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 82294}
{"reward": 0.06500000000000004, "episodes": 757, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 82403}
{"reward": 0.03000000000000002, "episodes": 758, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 82512}
{"reward": 0.017000000000000008, "episodes": 759, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 82621}
{"reward": 0.06700000000000005, "episodes": 760, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 82730}
{"reward": 0.06300000000000004, "episodes": 761, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 82839}
{"reward": 0.08300000000000006, "episodes": 762, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 82948}
{"reward": 0.008, "episodes": 763, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 83057}
{"reward": 0.022000000000000013, "episodes": 764, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 83166}
{"reward": 0.02000000000000001, "episodes": 765, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 83275}
{"reward": 0.047000000000000035, "episodes": 766, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 83384}
{"reward": 0.017000000000000008, "episodes": 767, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 83493}
{"reward": 0.05500000000000004, "episodes": 768, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 83602}
{"reward": 0.048000000000000036, "episodes": 769, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 83711}
{"reward": 0.05000000000000004, "episodes": 770, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 83820}
{"reward": 0.06700000000000005, "episodes": 771, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 83929}
{"reward": 0.036000000000000025, "episodes": 772, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 84038}
{"reward": 0.047000000000000035, "episodes": 773, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 84147}
{"reward": 0.04300000000000003, "episodes": 774, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 84256}
{"reward": 0.03000000000000002, "episodes": 775, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 84365}
{"reward": 0.04100000000000003, "episodes": 776, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 84474}
{"reward": 0.009000000000000001, "episodes": 777, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 84583}
{"reward": 0.016000000000000007, "episodes": 778, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 84692}
{"reward": 0.013000000000000005, "episodes": 779, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 84801}
{"reward": 0.04000000000000003, "episodes": 780, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 84910}
{"reward": 0.048000000000000036, "episodes": 781, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 85019}
{"reward": 0.05600000000000004, "episodes": 782, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 85128}
{"reward": 0.03800000000000003, "episodes": 783, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 85237}
{"reward": 0.02900000000000002, "episodes": 784, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 85346}
{"reward": 0.03100000000000002, "episodes": 785, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 85455}
{"reward": 0.08100000000000006, "episodes": 786, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 85564}
{"reward": 0.02900000000000002, "episodes": 787, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 85673}
{"reward": 0.058000000000000045, "episodes": 788, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 85782}
{"reward": 0.022000000000000013, "episodes": 789, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 85891}
{"reward": 0.014000000000000005, "episodes": 790, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 86000}
{"reward": 0.04300000000000003, "episodes": 791, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 86109}
{"reward": 0.010000000000000002, "episodes": 792, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 86218}
{"reward": 0.03800000000000003, "episodes": 793, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 86327}
{"reward": 0.022000000000000013, "episodes": 794, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 86436}
{"reward": 0.08300000000000006, "episodes": 795, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 86545}
{"reward": 0.005, "episodes": 796, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 86654}
{"reward": 0.03900000000000003, "episodes": 797, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 86763}
{"reward": 0.04500000000000003, "episodes": 798, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 86872}
{"reward": 0.04300000000000003, "episodes": 799, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 86981}
{"reward": 0.05300000000000004, "episodes": 800, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 87090}
{"reward": 0.060000000000000046, "episodes": 801, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 87199}
{"reward": 0.028000000000000018, "episodes": 802, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 87308}
{"reward": 0.04100000000000003, "episodes": 803, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 87417}
{"reward": 0.03100000000000002, "episodes": 804, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 87526}
{"reward": 0.010000000000000002, "episodes": 805, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 87635}
{"reward": 0.06600000000000004, "episodes": 806, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 87744}
{"reward": 0.07000000000000005, "episodes": 807, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 87853}
{"reward": 0.08000000000000006, "episodes": 808, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 87962}
{"reward": 0.07600000000000005, "episodes": 809, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 88071}
{"reward": 0.028000000000000018, "episodes": 810, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 88180}
{"reward": 0.03900000000000003, "episodes": 811, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 88289}
{"reward": 0.011000000000000003, "episodes": 812, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 88398}
{"reward": 0.03000000000000002, "episodes": 813, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 88507}
{"reward": 0.05300000000000004, "episodes": 814, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 88616}
{"reward": 0.03900000000000003, "episodes": 815, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 88725}
{"reward": 0.013000000000000005, "episodes": 816, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 88834}
{"reward": 0.025000000000000015, "episodes": 817, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 88943}
{"reward": 0.03400000000000002, "episodes": 818, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 89052}
{"reward": 0.08200000000000006, "episodes": 819, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 89161}
{"reward": 0.07300000000000005, "episodes": 820, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 89270}
{"reward": 0.06400000000000004, "episodes": 821, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 89379}
{"reward": 0.07400000000000005, "episodes": 822, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 89488}
{"reward": 0.037000000000000026, "episodes": 823, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 89597}
{"reward": 0.015000000000000006, "episodes": 824, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 89706}
{"reward": 0.02900000000000002, "episodes": 825, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 89815}
{"reward": 0.017000000000000008, "episodes": 826, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 89924}
{"reward": 0.025000000000000015, "episodes": 827, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 90033}
{"reward": 0.027000000000000017, "episodes": 828, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 90142}
{"reward": 0.048000000000000036, "episodes": 829, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 90251}
{"reward": 0.001, "episodes": 830, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 90360}
{"reward": 0.08000000000000006, "episodes": 831, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 90469}
{"reward": 0.058000000000000045, "episodes": 832, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 90578}
{"reward": 0.05300000000000004, "episodes": 833, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 90687}
{"reward": 0.03100000000000002, "episodes": 834, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 90796}
{"reward": 0.05400000000000004, "episodes": 835, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 90905}
{"reward": 0.07600000000000005, "episodes": 836, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 91014}
{"reward": 0.024000000000000014, "episodes": 837, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 91123}
{"reward": 0.025000000000000015, "episodes": 838, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 91232}
{"reward": 0.058000000000000045, "episodes": 839, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 91341}
{"reward": 0.03300000000000002, "episodes": 840, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 91450}
{"reward": 0.04500000000000003, "episodes": 841, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 91559}
{"reward": 0.02000000000000001, "episodes": 842, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 91668}
{"reward": 0.03200000000000002, "episodes": 843, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 91777}
{"reward": 0.03200000000000002, "episodes": 844, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 91886}
{"reward": 0.03000000000000002, "episodes": 845, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 91995}
{"reward": 0.016000000000000007, "episodes": 846, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 92104}
{"reward": 0.04300000000000003, "episodes": 847, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 92213}
{"reward": 0.008, "episodes": 848, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 92322}
{"reward": 0.036000000000000025, "episodes": 849, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 92431}
{"reward": 0.047000000000000035, "episodes": 850, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 92540}
{"reward": 0.04100000000000003, "episodes": 851, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 92649}
{"reward": 0.01900000000000001, "episodes": 852, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 92758}
{"reward": 0.02900000000000002, "episodes": 853, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 92867}
{"reward": 0.05100000000000004, "episodes": 854, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 92976}
{"reward": 0.036000000000000025, "episodes": 855, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 93085}
{"reward": 0.05400000000000004, "episodes": 856, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 93194}
{"reward": 0.04300000000000003, "episodes": 857, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 93303}
{"reward": 0.03000000000000002, "episodes": 858, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 93412}
{"reward": 0.08100000000000006, "episodes": 859, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 93521}
{"reward": 0.026000000000000016, "episodes": 860, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 93630}
{"reward": 0.016000000000000007, "episodes": 861, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 93739}
{"reward": 0.036000000000000025, "episodes": 862, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 93848}
{"reward": 0.05500000000000004, "episodes": 863, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 93957}
{"reward": 0.004, "episodes": 864, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 94066}
{"reward": 0.03100000000000002, "episodes": 865, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 94175}
{"reward": 0.03300000000000002, "episodes": 866, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 94284}
{"reward": 0.015000000000000006, "episodes": 867, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 94393}
{"reward": 0.06100000000000005, "episodes": 868, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 94502}
{"reward": 0.060000000000000046, "episodes": 869, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 94611}
{"reward": 0.014000000000000005, "episodes": 870, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 94720}
{"reward": 0.058000000000000045, "episodes": 871, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 94829}
{"reward": 0.03300000000000002, "episodes": 872, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 94938}
{"reward": 0.03800000000000003, "episodes": 873, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 95047}
{"reward": 0.04500000000000003, "episodes": 874, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 95156}
{"reward": 0.05500000000000004, "episodes": 875, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 95265}
{"reward": 0.048000000000000036, "episodes": 876, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 95374}
{"reward": 0.03900000000000003, "episodes": 877, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 95483}
{"reward": 0.06100000000000005, "episodes": 878, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 95592}
{"reward": 0.023000000000000013, "episodes": 879, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 95701}
{"reward": 0.048000000000000036, "episodes": 880, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 95810}
{"reward": 0.028000000000000018, "episodes": 881, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 95919}
{"reward": 0.058000000000000045, "episodes": 882, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 96028}
{"reward": 0.04400000000000003, "episodes": 883, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 96137}
{"reward": 0.06700000000000005, "episodes": 884, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 96246}
{"reward": 0.03300000000000002, "episodes": 885, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 96355}
{"reward": 0.03300000000000002, "episodes": 886, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 96464}
{"reward": 0.06400000000000004, "episodes": 887, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 96573}
{"reward": 0.05000000000000004, "episodes": 888, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 96682}
{"reward": 0.027000000000000017, "episodes": 889, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 96791}
{"reward": 0.07700000000000005, "episodes": 890, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 96900}
{"reward": 0.024000000000000014, "episodes": 891, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 97009}
{"reward": 0.07600000000000005, "episodes": 892, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 97118}
{"reward": 0.07500000000000005, "episodes": 893, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 97227}
{"reward": 0.05600000000000004, "episodes": 894, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 97336}
{"reward": 0.09100000000000007, "episodes": 895, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 97445}
{"reward": 0.05500000000000004, "episodes": 896, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 97554}
{"reward": 0.06500000000000004, "episodes": 897, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 97663}
{"reward": 0.010000000000000002, "episodes": 898, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 97772}
{"reward": 0.08400000000000006, "episodes": 899, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 97881}
{"reward": 0.06600000000000004, "episodes": 900, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 97990}
{"reward": 0.07100000000000005, "episodes": 901, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 98099}
{"reward": 0.03400000000000002, "episodes": 902, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 98208}
{"reward": 0.04100000000000003, "episodes": 903, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 98317}
{"reward": 0.026000000000000016, "episodes": 904, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 98426}
{"reward": 0.05100000000000004, "episodes": 905, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 98535}
{"reward": 0.024000000000000014, "episodes": 906, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 98644}
{"reward": 0.04500000000000003, "episodes": 907, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 98753}
{"reward": 0.03100000000000002, "episodes": 908, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 98862}
{"reward": 0.060000000000000046, "episodes": 909, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 98971}
{"reward": 0.03100000000000002, "episodes": 910, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 99080}
{"reward": 0.016000000000000007, "episodes": 911, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 99189}
{"reward": 0.026000000000000016, "episodes": 912, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 99298}
{"reward": 0.046000000000000034, "episodes": 913, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 99407}
{"reward": 0.011000000000000003, "episodes": 914, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 99516}
{"reward": 0.03400000000000002, "episodes": 915, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 99625}
{"reward": 0.048000000000000036, "episodes": 916, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 99734}
{"reward": 0.007, "episodes": 917, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 99843}
{"reward": 0.024000000000000014, "episodes": 918, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 99952}
{"reward": 0.09100000000000007, "episodes": 919, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 100061}
{"reward": 0.02100000000000001, "episodes": 920, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 100170}
{"reward": 0.023000000000000013, "episodes": 921, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 100279}
{"reward": 0.04500000000000003, "episodes": 922, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 100388}
{"reward": 0.03200000000000002, "episodes": 923, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 100497}
{"reward": 0.03800000000000003, "episodes": 924, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 100606}
{"reward": 0.05500000000000004, "episodes": 925, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 100715}
{"reward": 0.060000000000000046, "episodes": 926, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 100824}
{"reward": 0.04100000000000003, "episodes": 927, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 100933}
{"reward": 0.017000000000000008, "episodes": 928, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 101042}
{"reward": 0.07700000000000005, "episodes": 929, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 101151}
{"reward": 0.014000000000000005, "episodes": 930, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 101260}
{"reward": 0.048000000000000036, "episodes": 931, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 101369}
{"reward": 0.04200000000000003, "episodes": 932, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 101478}
{"reward": 0.03300000000000002, "episodes": 933, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 101587}
{"reward": 0.04100000000000003, "episodes": 934, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 101696}
{"reward": 0.04500000000000003, "episodes": 935, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 101805}
{"reward": 0.03900000000000003, "episodes": 936, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 101914}
{"reward": 0.046000000000000034, "episodes": 937, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 102023}
{"reward": 0.012000000000000004, "episodes": 938, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 102132}
{"reward": 0.047000000000000035, "episodes": 939, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 102241}
{"reward": 0.02900000000000002, "episodes": 940, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 102350}
{"reward": 0.009000000000000001, "episodes": 941, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 102459}
{"reward": 0.06500000000000004, "episodes": 942, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 102568}
{"reward": 0.059000000000000045, "episodes": 943, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 102677}
{"reward": 0.06700000000000005, "episodes": 944, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 102786}
{"reward": 0.008, "episodes": 945, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 102895}
{"reward": 0.04200000000000003, "episodes": 946, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 103004}
{"reward": 0.037000000000000026, "episodes": 947, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 103113}
{"reward": 0.037000000000000026, "episodes": 948, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 103222}
{"reward": 0.047000000000000035, "episodes": 949, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 103331}
{"reward": 0.02000000000000001, "episodes": 950, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 103440}
{"reward": 0.04000000000000003, "episodes": 951, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 103549}
{"reward": 0.04100000000000003, "episodes": 952, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 103658}
{"reward": 0.027000000000000017, "episodes": 953, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 103767}
{"reward": 0.01800000000000001, "episodes": 954, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 103876}
{"reward": 0.05600000000000004, "episodes": 955, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 103985}
{"reward": 0.03300000000000002, "episodes": 956, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 104094}
{"reward": 0.05400000000000004, "episodes": 957, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 104203}
{"reward": 0.058000000000000045, "episodes": 958, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 104312}
{"reward": 0.037000000000000026, "episodes": 959, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 104421}
{"reward": 0.03800000000000003, "episodes": 960, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 104530}
{"reward": 0.03000000000000002, "episodes": 961, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 104639}
{"reward": 0.048000000000000036, "episodes": 962, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 104748}
{"reward": 0.027000000000000017, "episodes": 963, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 104857}
{"reward": 0.047000000000000035, "episodes": 964, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 104966}
{"reward": 0.036000000000000025, "episodes": 965, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 105075}
{"reward": 0.046000000000000034, "episodes": 966, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 105184}
{"reward": 0.05000000000000004, "episodes": 967, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 105293}
{"reward": 0.03800000000000003, "episodes": 968, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 105402}
{"reward": 0.047000000000000035, "episodes": 969, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 105511}
{"reward": 0.05400000000000004, "episodes": 970, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 105620}
{"reward": 0.06600000000000004, "episodes": 971, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 105729}
{"reward": 0.06100000000000005, "episodes": 972, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 105838}
{"reward": 0.0, "episodes": 973, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 105947}
{"reward": 0.004, "episodes": 974, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 106056}
{"reward": 0.006, "episodes": 975, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 106165}
{"reward": 0.02900000000000002, "episodes": 976, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 106274}
{"reward": 0.03800000000000003, "episodes": 977, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 106383}
{"reward": 0.07200000000000005, "episodes": 978, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 106492}
{"reward": 0.025000000000000015, "episodes": 979, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 106601}
{"reward": 0.036000000000000025, "episodes": 980, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 106710}
{"reward": 0.025000000000000015, "episodes": 981, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 106819}
{"reward": 0.05000000000000004, "episodes": 982, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 106928}
{"reward": 0.035000000000000024, "episodes": 983, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 107037}
{"reward": 0.057000000000000044, "episodes": 984, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 107146}
{"reward": 0.04900000000000004, "episodes": 985, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 107255}
{"reward": 0.04900000000000004, "episodes": 986, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 107364}
{"reward": 0.024000000000000014, "episodes": 987, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 107473}
{"reward": 0.06300000000000004, "episodes": 988, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 107582}
{"reward": 0.05100000000000004, "episodes": 989, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 107691}
{"reward": 0.05300000000000004, "episodes": 990, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 107800}
{"reward": 0.02900000000000002, "episodes": 991, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 107909}
{"reward": 0.08200000000000006, "episodes": 992, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 108018}
{"reward": 0.03800000000000003, "episodes": 993, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 108127}
{"reward": 0.06900000000000005, "episodes": 994, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 108236}
{"reward": 0.07200000000000005, "episodes": 995, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 108345}
{"reward": 0.06300000000000004, "episodes": 996, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 108454}
{"reward": 0.025000000000000015, "episodes": 997, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 108563}
{"reward": 0.04400000000000003, "episodes": 998, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 108672}
{"reward": 0.059000000000000045, "episodes": 999, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 108781}
{"reward": 0.04300000000000003, "episodes": 1000, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 108890}
{"reward": 0.060000000000000046, "episodes": 1001, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 108999}
{"reward": 0.04900000000000004, "episodes": 1002, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 109108}
{"reward": 0.036000000000000025, "episodes": 1003, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 109217}
{"reward": 0.06400000000000004, "episodes": 1004, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 109326}
{"reward": 0.014000000000000005, "episodes": 1005, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 109435}
{"reward": 0.02000000000000001, "episodes": 1006, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 109544}
{"reward": 0.06500000000000004, "episodes": 1007, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 109653}
{"reward": 0.05100000000000004, "episodes": 1008, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 109762}
{"reward": 0.060000000000000046, "episodes": 1009, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 109871}
{"reward": 0.04500000000000003, "episodes": 1010, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 109980}
{"reward": 0.013000000000000005, "episodes": 1011, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 110089}
{"reward": 0.05300000000000004, "episodes": 1012, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 110198}
{"reward": 0.05000000000000004, "episodes": 1013, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 110307}
{"reward": 0.05200000000000004, "episodes": 1014, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 110416}
{"reward": 0.04000000000000003, "episodes": 1015, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 110525}
{"reward": 0.028000000000000018, "episodes": 1016, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 110634}
{"reward": 0.01900000000000001, "episodes": 1017, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 110743}
{"reward": 0.009000000000000001, "episodes": 1018, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 110852}
{"reward": 0.02900000000000002, "episodes": 1019, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 110961}
{"reward": 0.07800000000000006, "episodes": 1020, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 111070}
{"reward": 0.04400000000000003, "episodes": 1021, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 111179}
{"reward": 0.060000000000000046, "episodes": 1022, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 111288}
{"reward": 0.08400000000000006, "episodes": 1023, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 111397}
{"reward": 0.03200000000000002, "episodes": 1024, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 111506}
{"reward": 0.08300000000000006, "episodes": 1025, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 111615}
{"reward": 0.03900000000000003, "episodes": 1026, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 111724}
{"reward": 0.02900000000000002, "episodes": 1027, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 111833}
{"reward": 0.05000000000000004, "episodes": 1028, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 111942}
{"reward": 0.02100000000000001, "episodes": 1029, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 112051}
{"reward": 0.04900000000000004, "episodes": 1030, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 112160}
{"reward": 0.05300000000000004, "episodes": 1031, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 112269}
{"reward": 0.05200000000000004, "episodes": 1032, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 112378}
{"reward": 0.058000000000000045, "episodes": 1033, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 112487}
{"reward": 0.047000000000000035, "episodes": 1034, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 112596}
{"reward": 0.04300000000000003, "episodes": 1035, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 112705}
{"reward": 0.05000000000000004, "episodes": 1036, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 112814}
{"reward": 0.05300000000000004, "episodes": 1037, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 112923}
{"reward": 0.07400000000000005, "episodes": 1038, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 113032}
{"reward": 0.06900000000000005, "episodes": 1039, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 113141}
{"reward": 0.058000000000000045, "episodes": 1040, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 113250}
{"reward": 0.03300000000000002, "episodes": 1041, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 113359}
{"reward": 0.04200000000000003, "episodes": 1042, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 113468}
{"reward": 0.023000000000000013, "episodes": 1043, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 113577}
{"reward": 0.025000000000000015, "episodes": 1044, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 113686}
{"reward": 0.05000000000000004, "episodes": 1045, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 113795}
{"reward": 0.05300000000000004, "episodes": 1046, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 113904}
{"reward": 0.059000000000000045, "episodes": 1047, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 114013}
{"reward": 0.04900000000000004, "episodes": 1048, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 114122}
{"reward": 0.08700000000000006, "episodes": 1049, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 114231}
{"reward": 0.059000000000000045, "episodes": 1050, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 114340}
{"reward": 0.058000000000000045, "episodes": 1051, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 114449}
{"reward": 0.05300000000000004, "episodes": 1052, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 114558}
{"reward": 0.028000000000000018, "episodes": 1053, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 114667}
{"reward": 0.01800000000000001, "episodes": 1054, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 114776}
{"reward": 0.05400000000000004, "episodes": 1055, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 114885}
{"reward": 0.07100000000000005, "episodes": 1056, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 114994}
{"reward": 0.059000000000000045, "episodes": 1057, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 115103}
{"reward": 0.037000000000000026, "episodes": 1058, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 115212}
{"reward": 0.047000000000000035, "episodes": 1059, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 115321}
{"reward": 0.036000000000000025, "episodes": 1060, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 115430}
{"reward": 0.06900000000000005, "episodes": 1061, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 115539}
{"reward": 0.046000000000000034, "episodes": 1062, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 115648}
{"reward": 0.03000000000000002, "episodes": 1063, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 115757}
{"reward": 0.016000000000000007, "episodes": 1064, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 115866}
{"reward": 0.03100000000000002, "episodes": 1065, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 115975}
{"reward": 0.01900000000000001, "episodes": 1066, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 116084}
{"reward": 0.026000000000000016, "episodes": 1067, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 116193}
{"reward": 0.04200000000000003, "episodes": 1068, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 116302}
{"reward": 0.04900000000000004, "episodes": 1069, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 116411}
{"reward": 0.03300000000000002, "episodes": 1070, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 116520}
{"reward": 0.05200000000000004, "episodes": 1071, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 116629}
{"reward": 0.03400000000000002, "episodes": 1072, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 116738}
{"reward": 0.06400000000000004, "episodes": 1073, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 116847}
{"reward": 0.06100000000000005, "episodes": 1074, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 116956}
{"reward": 0.035000000000000024, "episodes": 1075, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 117065}
{"reward": 0.057000000000000044, "episodes": 1076, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 117174}
{"reward": 0.016000000000000007, "episodes": 1077, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 117283}
{"reward": 0.04400000000000003, "episodes": 1078, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 117392}
{"reward": 0.028000000000000018, "episodes": 1079, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 117501}
{"reward": 0.05500000000000004, "episodes": 1080, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 117610}
{"reward": 0.04100000000000003, "episodes": 1081, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 117719}
{"reward": 0.058000000000000045, "episodes": 1082, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 117828}
{"reward": 0.037000000000000026, "episodes": 1083, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 117937}
{"reward": 0.06800000000000005, "episodes": 1084, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 118046}
{"reward": 0.04400000000000003, "episodes": 1085, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 118155}
{"reward": 0.027000000000000017, "episodes": 1086, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 118264}
{"reward": 0.037000000000000026, "episodes": 1087, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 118373}
{"reward": 0.06200000000000005, "episodes": 1088, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 118482}
{"reward": 0.07800000000000006, "episodes": 1089, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 118591}
{"reward": 0.036000000000000025, "episodes": 1090, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 118700}
{"reward": 0.02100000000000001, "episodes": 1091, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 118809}
{"reward": 0.016000000000000007, "episodes": 1092, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 118918}
{"reward": 0.024000000000000014, "episodes": 1093, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 119027}
{"reward": 0.07500000000000005, "episodes": 1094, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 119136}
{"reward": 0.058000000000000045, "episodes": 1095, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 119245}
{"reward": 0.036000000000000025, "episodes": 1096, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 119354}
{"reward": 0.016000000000000007, "episodes": 1097, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 119463}
{"reward": 0.07600000000000005, "episodes": 1098, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 119572}
{"reward": 0.03200000000000002, "episodes": 1099, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 119681}
{"reward": 0.036000000000000025, "episodes": 1100, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 119790}
{"reward": 0.022000000000000013, "episodes": 1101, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 119899}
{"reward": 0.04200000000000003, "episodes": 1102, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 120008}
{"reward": 0.04200000000000003, "episodes": 1103, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 120117}
{"reward": 0.04300000000000003, "episodes": 1104, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 120226}
{"reward": 0.009000000000000001, "episodes": 1105, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 120335}
{"reward": 0.04500000000000003, "episodes": 1106, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 120444}
{"reward": 0.10300000000000008, "episodes": 1107, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 120553}
{"reward": 0.015000000000000006, "episodes": 1108, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 120662}
{"reward": 0.03200000000000002, "episodes": 1109, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 120771}
{"reward": 0.03800000000000003, "episodes": 1110, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 120880}
{"reward": 0.011000000000000003, "episodes": 1111, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 120989}
{"reward": 0.03300000000000002, "episodes": 1112, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 121098}
{"reward": 0.08000000000000006, "episodes": 1113, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 121207}
{"reward": 0.026000000000000016, "episodes": 1114, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 121316}
{"reward": 0.05100000000000004, "episodes": 1115, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 121425}
{"reward": 0.07800000000000006, "episodes": 1116, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 121534}
{"reward": 0.02900000000000002, "episodes": 1117, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 121643}
{"reward": 0.05600000000000004, "episodes": 1118, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 121752}
{"reward": 0.06200000000000005, "episodes": 1119, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 121861}
{"reward": 0.05200000000000004, "episodes": 1120, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 121970}
{"reward": 0.05000000000000004, "episodes": 1121, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 122079}
{"reward": 0.03100000000000002, "episodes": 1122, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 122188}
{"reward": 0.04100000000000003, "episodes": 1123, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 122297}
{"reward": 0.04100000000000003, "episodes": 1124, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 122406}
{"reward": 0.08400000000000006, "episodes": 1125, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 122515}
{"reward": 0.08200000000000006, "episodes": 1126, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 122624}
{"reward": 0.02100000000000001, "episodes": 1127, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 122733}
{"reward": 0.047000000000000035, "episodes": 1128, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 122842}
{"reward": 0.04000000000000003, "episodes": 1129, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 122951}
{"reward": 0.05600000000000004, "episodes": 1130, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 123060}
{"reward": 0.03000000000000002, "episodes": 1131, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 123169}
{"reward": 0.03800000000000003, "episodes": 1132, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 123278}
{"reward": 0.04300000000000003, "episodes": 1133, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 123387}
{"reward": 0.059000000000000045, "episodes": 1134, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 123496}
{"reward": 0.037000000000000026, "episodes": 1135, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 123605}
{"reward": 0.011000000000000003, "episodes": 1136, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 123714}
{"reward": 0.02900000000000002, "episodes": 1137, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 123823}
{"reward": 0.012000000000000004, "episodes": 1138, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 123932}
{"reward": 0.04100000000000003, "episodes": 1139, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 124041}
{"reward": 0.023000000000000013, "episodes": 1140, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 124150}
{"reward": 0.05400000000000004, "episodes": 1141, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 124259}
{"reward": 0.037000000000000026, "episodes": 1142, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 124368}
{"reward": 0.01900000000000001, "episodes": 1143, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 124477}
{"reward": 0.06200000000000005, "episodes": 1144, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 124586}
{"reward": 0.03800000000000003, "episodes": 1145, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 124695}
{"reward": 0.07100000000000005, "episodes": 1146, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 124804}
{"reward": 0.013000000000000005, "episodes": 1147, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 124913}
{"reward": 0.04000000000000003, "episodes": 1148, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 125022}
{"reward": 0.035000000000000024, "episodes": 1149, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 125131}
{"reward": 0.060000000000000046, "episodes": 1150, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 125240}
{"reward": 0.06700000000000005, "episodes": 1151, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 125349}
{"reward": 0.02900000000000002, "episodes": 1152, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 125458}
{"reward": 0.09100000000000007, "episodes": 1153, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 125567}
{"reward": 0.06700000000000005, "episodes": 1154, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 125676}
{"reward": 0.04100000000000003, "episodes": 1155, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 125785}
{"reward": 0.07000000000000005, "episodes": 1156, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 125894}
{"reward": 0.047000000000000035, "episodes": 1157, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 126003}
{"reward": 0.057000000000000044, "episodes": 1158, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 126112}
{"reward": 0.02900000000000002, "episodes": 1159, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 126221}
{"reward": 0.012000000000000004, "episodes": 1160, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 126330}
{"reward": 0.07300000000000005, "episodes": 1161, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 126439}
{"reward": 0.03300000000000002, "episodes": 1162, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 126548}
{"reward": 0.014000000000000005, "episodes": 1163, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 126657}
{"reward": 0.06100000000000005, "episodes": 1164, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 126766}
{"reward": 0.02900000000000002, "episodes": 1165, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 126875}
{"reward": 0.048000000000000036, "episodes": 1166, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 126984}
{"reward": 0.046000000000000034, "episodes": 1167, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 127093}
{"reward": 0.027000000000000017, "episodes": 1168, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 127202}
{"reward": 0.04500000000000003, "episodes": 1169, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 127311}
{"reward": 0.05000000000000004, "episodes": 1170, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 127420}
{"reward": 0.059000000000000045, "episodes": 1171, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 127529}
{"reward": 0.047000000000000035, "episodes": 1172, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 127638}
{"reward": 0.04900000000000004, "episodes": 1173, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 127747}
{"reward": 0.04400000000000003, "episodes": 1174, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 127856}
{"reward": 0.04500000000000003, "episodes": 1175, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 127965}
{"reward": 0.03400000000000002, "episodes": 1176, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 128074}
{"reward": 0.04900000000000004, "episodes": 1177, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 128183}
{"reward": 0.023000000000000013, "episodes": 1178, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 128292}
{"reward": 0.013000000000000005, "episodes": 1179, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 128401}
{"reward": 0.013000000000000005, "episodes": 1180, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 128510}
{"reward": 0.08200000000000006, "episodes": 1181, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 128619}
{"reward": 0.06100000000000005, "episodes": 1182, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 128728}
{"reward": 0.058000000000000045, "episodes": 1183, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 128837}
{"reward": 0.07300000000000005, "episodes": 1184, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 128946}
{"reward": 0.06300000000000004, "episodes": 1185, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 129055}
{"reward": 0.024000000000000014, "episodes": 1186, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 129164}
{"reward": 0.014000000000000005, "episodes": 1187, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 129273}
{"reward": 0.060000000000000046, "episodes": 1188, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 129382}
{"reward": 0.005, "episodes": 1189, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 129491}
{"reward": 0.07100000000000005, "episodes": 1190, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 129600}
{"reward": 0.04500000000000003, "episodes": 1191, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 129709}
{"reward": 0.05400000000000004, "episodes": 1192, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 129818}
{"reward": 0.02900000000000002, "episodes": 1193, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 129927}
{"reward": 0.037000000000000026, "episodes": 1194, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 130036}
{"reward": 0.08400000000000006, "episodes": 1195, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 130145}
{"reward": 0.036000000000000025, "episodes": 1196, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 130254}
{"reward": 0.03200000000000002, "episodes": 1197, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 130363}
{"reward": 0.03800000000000003, "episodes": 1198, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 130472}
{"reward": 0.04900000000000004, "episodes": 1199, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 130581}
{"reward": 0.06100000000000005, "episodes": 1200, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 130690}
{"reward": 0.08200000000000006, "episodes": 1201, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 130799}
{"reward": 0.08100000000000006, "episodes": 1202, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 130908}
{"reward": 0.025000000000000015, "episodes": 1203, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 131017}
{"reward": 0.05500000000000004, "episodes": 1204, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 131126}
{"reward": 0.03100000000000002, "episodes": 1205, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 131235}
{"reward": 0.06100000000000005, "episodes": 1206, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 131344}
{"reward": 0.07800000000000006, "episodes": 1207, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 131453}
{"reward": 0.03900000000000003, "episodes": 1208, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 131562}
{"reward": 0.02900000000000002, "episodes": 1209, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 131671}
{"reward": 0.03400000000000002, "episodes": 1210, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 131780}
{"reward": 0.06600000000000004, "episodes": 1211, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 131889}
{"reward": 0.024000000000000014, "episodes": 1212, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 131998}
{"reward": 0.058000000000000045, "episodes": 1213, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 132107}
{"reward": 0.03200000000000002, "episodes": 1214, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 132216}
{"reward": 0.05200000000000004, "episodes": 1215, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 132325}
{"reward": 0.06200000000000005, "episodes": 1216, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 132434}
{"reward": 0.05400000000000004, "episodes": 1217, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 132543}
{"reward": 0.08300000000000006, "episodes": 1218, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 132652}
{"reward": 0.06300000000000004, "episodes": 1219, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 132761}
{"reward": 0.03300000000000002, "episodes": 1220, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 132870}
{"reward": 0.08800000000000006, "episodes": 1221, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 132979}
{"reward": 0.060000000000000046, "episodes": 1222, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 133088}
{"reward": 0.07100000000000005, "episodes": 1223, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 133197}
{"reward": 0.025000000000000015, "episodes": 1224, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 133306}
{"reward": 0.024000000000000014, "episodes": 1225, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 133415}
{"reward": 0.04100000000000003, "episodes": 1226, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 133524}
{"reward": 0.05300000000000004, "episodes": 1227, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 133633}
{"reward": 0.06600000000000004, "episodes": 1228, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 133742}
{"reward": 0.047000000000000035, "episodes": 1229, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 133851}
{"reward": 0.026000000000000016, "episodes": 1230, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 133960}
{"reward": 0.05100000000000004, "episodes": 1231, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 134069}
{"reward": 0.04900000000000004, "episodes": 1232, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 134178}
{"reward": 0.05100000000000004, "episodes": 1233, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 134287}
{"reward": 0.03400000000000002, "episodes": 1234, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 134396}
{"reward": 0.05400000000000004, "episodes": 1235, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 134505}
{"reward": 0.02100000000000001, "episodes": 1236, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 134614}
{"reward": 0.09700000000000007, "episodes": 1237, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 134723}
{"reward": 0.08900000000000007, "episodes": 1238, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 134832}
{"reward": 0.07200000000000005, "episodes": 1239, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 134941}
{"reward": 0.036000000000000025, "episodes": 1240, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 135050}
{"reward": 0.06700000000000005, "episodes": 1241, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 135159}
{"reward": 0.03100000000000002, "episodes": 1242, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 135268}
{"reward": 0.04400000000000003, "episodes": 1243, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 135377}
{"reward": 0.035000000000000024, "episodes": 1244, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 135486}
{"reward": 0.027000000000000017, "episodes": 1245, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 135595}
{"reward": 0.046000000000000034, "episodes": 1246, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 135704}
{"reward": 0.06700000000000005, "episodes": 1247, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 135813}
{"reward": 0.05300000000000004, "episodes": 1248, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 135922}
{"reward": 0.03800000000000003, "episodes": 1249, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 136031}
{"reward": 0.04500000000000003, "episodes": 1250, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 136140}
{"reward": 0.06200000000000005, "episodes": 1251, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 136249}
{"reward": 0.07500000000000005, "episodes": 1252, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 136358}
{"reward": 0.09400000000000007, "episodes": 1253, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 136467}
{"reward": 0.06400000000000004, "episodes": 1254, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 136576}
{"reward": 0.028000000000000018, "episodes": 1255, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 136685}
{"reward": 0.06300000000000004, "episodes": 1256, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 136794}
{"reward": 0.04300000000000003, "episodes": 1257, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 136903}
{"reward": 0.05200000000000004, "episodes": 1258, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 137012}
{"reward": 0.06200000000000005, "episodes": 1259, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 137121}
{"reward": 0.057000000000000044, "episodes": 1260, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 137230}
{"reward": 0.037000000000000026, "episodes": 1261, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 137339}
{"reward": 0.05100000000000004, "episodes": 1262, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 137448}
{"reward": 0.046000000000000034, "episodes": 1263, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 137557}
{"reward": 0.04500000000000003, "episodes": 1264, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 137666}
{"reward": 0.03200000000000002, "episodes": 1265, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 137775}
{"reward": 0.03400000000000002, "episodes": 1266, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 137884}
{"reward": 0.04100000000000003, "episodes": 1267, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 137993}
{"reward": 0.024000000000000014, "episodes": 1268, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 138102}
{"reward": 0.02900000000000002, "episodes": 1269, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 138211}
{"reward": 0.07000000000000005, "episodes": 1270, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 138320}
{"reward": 0.04900000000000004, "episodes": 1271, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 138429}
{"reward": 0.02900000000000002, "episodes": 1272, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 138538}
{"reward": 0.03900000000000003, "episodes": 1273, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 138647}
{"reward": 0.03100000000000002, "episodes": 1274, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 138756}
{"reward": 0.057000000000000044, "episodes": 1275, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 138865}
{"reward": 0.05400000000000004, "episodes": 1276, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 138974}
{"reward": 0.035000000000000024, "episodes": 1277, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 139083}
{"reward": 0.04900000000000004, "episodes": 1278, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 139192}
{"reward": 0.07400000000000005, "episodes": 1279, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 139301}
{"reward": 0.037000000000000026, "episodes": 1280, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 139410}
{"reward": 0.03000000000000002, "episodes": 1281, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 139519}
{"reward": 0.059000000000000045, "episodes": 1282, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 139628}
{"reward": 0.06600000000000004, "episodes": 1283, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 139737}
{"reward": 0.027000000000000017, "episodes": 1284, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 139846}
{"reward": 0.036000000000000025, "episodes": 1285, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 139955}
{"reward": 0.03300000000000002, "episodes": 1286, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 140064}
{"reward": 0.004, "episodes": 1287, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 140173}
{"reward": 0.03300000000000002, "episodes": 1288, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 140282}
{"reward": 0.025000000000000015, "episodes": 1289, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 140391}
{"reward": 0.06400000000000004, "episodes": 1290, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 140500}
{"reward": 0.04000000000000003, "episodes": 1291, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 140609}
{"reward": 0.028000000000000018, "episodes": 1292, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 140718}
{"reward": 0.03000000000000002, "episodes": 1293, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 140827}
{"reward": 0.03000000000000002, "episodes": 1294, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 140936}
{"reward": 0.057000000000000044, "episodes": 1295, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 141045}
{"reward": 0.059000000000000045, "episodes": 1296, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 141154}
{"reward": 0.037000000000000026, "episodes": 1297, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 141263}
{"reward": 0.08300000000000006, "episodes": 1298, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 141372}
{"reward": 0.05000000000000004, "episodes": 1299, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 141481}
{"reward": 0.02000000000000001, "episodes": 1300, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 141590}
{"reward": 0.026000000000000016, "episodes": 1301, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 141699}
{"reward": 0.017000000000000008, "episodes": 1302, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 141808}
{"reward": 0.013000000000000005, "episodes": 1303, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 141917}
{"reward": 0.008, "episodes": 1304, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 142026}
{"reward": 0.058000000000000045, "episodes": 1305, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 142135}
{"reward": 0.08000000000000006, "episodes": 1306, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 142244}
{"reward": 0.03800000000000003, "episodes": 1307, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 142353}
{"reward": 0.058000000000000045, "episodes": 1308, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 142462}
{"reward": 0.048000000000000036, "episodes": 1309, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 142571}
{"reward": 0.06500000000000004, "episodes": 1310, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 142680}
{"reward": 0.04300000000000003, "episodes": 1311, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 142789}
{"reward": 0.07700000000000005, "episodes": 1312, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 142898}
{"reward": 0.05000000000000004, "episodes": 1313, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 143007}
{"reward": 0.013000000000000005, "episodes": 1314, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 143116}
{"reward": 0.06500000000000004, "episodes": 1315, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 143225}
{"reward": 0.035000000000000024, "episodes": 1316, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 143334}
{"reward": 0.03900000000000003, "episodes": 1317, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 143443}
{"reward": 0.04400000000000003, "episodes": 1318, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 143552}
{"reward": 0.05600000000000004, "episodes": 1319, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 143661}
{"reward": 0.05600000000000004, "episodes": 1320, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 143770}
{"reward": 0.04900000000000004, "episodes": 1321, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 143879}
{"reward": 0.08000000000000006, "episodes": 1322, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 143988}
{"reward": 0.037000000000000026, "episodes": 1323, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 144097}
{"reward": 0.03800000000000003, "episodes": 1324, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 144206}
{"reward": 0.037000000000000026, "episodes": 1325, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 144315}
{"reward": 0.07600000000000005, "episodes": 1326, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 144424}
{"reward": 0.05200000000000004, "episodes": 1327, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 144533}
{"reward": 0.05100000000000004, "episodes": 1328, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 144642}
{"reward": 0.08000000000000006, "episodes": 1329, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 144751}
{"reward": 0.06500000000000004, "episodes": 1330, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 144860}
{"reward": 0.015000000000000006, "episodes": 1331, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 144969}
{"reward": 0.06600000000000004, "episodes": 1332, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 145078}
{"reward": 0.06400000000000004, "episodes": 1333, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 145187}
{"reward": 0.058000000000000045, "episodes": 1334, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 145296}
{"reward": 0.01900000000000001, "episodes": 1335, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 145405}
{"reward": 0.03800000000000003, "episodes": 1336, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 145514}
{"reward": 0.03300000000000002, "episodes": 1337, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 145623}
{"reward": 0.036000000000000025, "episodes": 1338, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 145732}
{"reward": 0.022000000000000013, "episodes": 1339, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 145841}
{"reward": 0.036000000000000025, "episodes": 1340, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 145950}
{"reward": 0.09600000000000007, "episodes": 1341, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 146059}
{"reward": 0.04300000000000003, "episodes": 1342, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 146168}
{"reward": 0.05000000000000004, "episodes": 1343, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 146277}
{"reward": 0.05100000000000004, "episodes": 1344, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 146386}
{"reward": 0.07100000000000005, "episodes": 1345, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 146495}
{"reward": 0.05400000000000004, "episodes": 1346, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 146604}
{"reward": 0.04400000000000003, "episodes": 1347, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 146713}
{"reward": 0.05500000000000004, "episodes": 1348, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 146822}
{"reward": 0.06300000000000004, "episodes": 1349, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 146931}
{"reward": 0.06600000000000004, "episodes": 1350, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 147040}
{"reward": 0.04200000000000003, "episodes": 1351, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 147149}
{"reward": 0.05500000000000004, "episodes": 1352, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 147258}
{"reward": 0.06300000000000004, "episodes": 1353, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 147367}
{"reward": 0.07800000000000006, "episodes": 1354, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 147476}
{"reward": 0.04400000000000003, "episodes": 1355, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 147585}
{"reward": 0.060000000000000046, "episodes": 1356, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 147694}
{"reward": 0.06800000000000005, "episodes": 1357, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 147803}
{"reward": 0.03400000000000002, "episodes": 1358, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 147912}
{"reward": 0.037000000000000026, "episodes": 1359, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 148021}
{"reward": 0.024000000000000014, "episodes": 1360, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 148130}
{"reward": 0.05000000000000004, "episodes": 1361, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 148239}
{"reward": 0.02000000000000001, "episodes": 1362, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 148348}
{"reward": 0.06900000000000005, "episodes": 1363, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 148457}
{"reward": 0.05300000000000004, "episodes": 1364, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 148566}
{"reward": 0.07500000000000005, "episodes": 1365, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 148675}
{"reward": 0.05600000000000004, "episodes": 1366, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 148784}
{"reward": 0.03000000000000002, "episodes": 1367, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 148893}
{"reward": 0.03400000000000002, "episodes": 1368, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 149002}
{"reward": 0.05000000000000004, "episodes": 1369, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 149111}
{"reward": 0.04300000000000003, "episodes": 1370, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 149220}
{"reward": 0.04300000000000003, "episodes": 1371, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 149329}
{"reward": 0.036000000000000025, "episodes": 1372, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 149438}
{"reward": 0.048000000000000036, "episodes": 1373, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 149547}
{"reward": 0.04000000000000003, "episodes": 1374, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 149656}
{"reward": 0.059000000000000045, "episodes": 1375, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 149765}
{"reward": 0.03900000000000003, "episodes": 1376, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 149874}
{"reward": 0.05000000000000004, "episodes": 1377, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 149983}
{"reward": 0.08500000000000006, "episodes": 1378, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 150092}
{"reward": 0.05000000000000004, "episodes": 1379, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 150201}
{"reward": 0.04200000000000003, "episodes": 1380, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 150310}
{"reward": 0.06200000000000005, "episodes": 1381, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 150419}
{"reward": 0.04400000000000003, "episodes": 1382, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 150528}
{"reward": 0.059000000000000045, "episodes": 1383, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 150637}
{"reward": 0.01800000000000001, "episodes": 1384, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 150746}
{"reward": 0.07200000000000005, "episodes": 1385, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 150855}
{"reward": 0.046000000000000034, "episodes": 1386, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 150964}
{"reward": 0.03100000000000002, "episodes": 1387, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 151073}
{"reward": 0.060000000000000046, "episodes": 1388, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 151182}
{"reward": 0.01900000000000001, "episodes": 1389, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 151291}
{"reward": 0.01900000000000001, "episodes": 1390, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 151400}
{"reward": 0.04100000000000003, "episodes": 1391, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 151509}
{"reward": 0.037000000000000026, "episodes": 1392, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 151618}
{"reward": 0.014000000000000005, "episodes": 1393, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 151727}
{"reward": 0.04200000000000003, "episodes": 1394, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 151836}
{"reward": 0.03900000000000003, "episodes": 1395, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 151945}
{"reward": 0.04100000000000003, "episodes": 1396, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 152054}
{"reward": 0.046000000000000034, "episodes": 1397, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 152163}
{"reward": 0.017000000000000008, "episodes": 1398, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 152272}
{"reward": 0.02100000000000001, "episodes": 1399, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 152381}
{"reward": 0.04100000000000003, "episodes": 1400, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 152490}
{"reward": 0.035000000000000024, "episodes": 1401, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 152599}
{"reward": 0.08000000000000006, "episodes": 1402, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 152708}
{"reward": 0.07200000000000005, "episodes": 1403, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 152817}
{"reward": 0.04100000000000003, "episodes": 1404, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 152926}
{"reward": 0.09200000000000007, "episodes": 1405, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 153035}
{"reward": 0.05100000000000004, "episodes": 1406, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 153144}
{"reward": 0.05500000000000004, "episodes": 1407, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 153253}
{"reward": 0.026000000000000016, "episodes": 1408, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 153362}
{"reward": 0.024000000000000014, "episodes": 1409, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 153471}
{"reward": 0.04300000000000003, "episodes": 1410, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 153580}
{"reward": 0.023000000000000013, "episodes": 1411, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 153689}
{"reward": 0.04200000000000003, "episodes": 1412, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 153798}
{"reward": 0.059000000000000045, "episodes": 1413, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 153907}
{"reward": 0.04400000000000003, "episodes": 1414, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 154016}
{"reward": 0.017000000000000008, "episodes": 1415, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 154125}
{"reward": 0.03100000000000002, "episodes": 1416, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 154234}
{"reward": 0.07200000000000005, "episodes": 1417, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 154343}
{"reward": 0.015000000000000006, "episodes": 1418, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 154452}
{"reward": 0.04300000000000003, "episodes": 1419, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 154561}
{"reward": 0.04500000000000003, "episodes": 1420, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 154670}
{"reward": 0.048000000000000036, "episodes": 1421, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 154779}
{"reward": 0.06800000000000005, "episodes": 1422, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 154888}
{"reward": 0.07100000000000005, "episodes": 1423, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 154997}
{"reward": 0.07500000000000005, "episodes": 1424, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 155106}
{"reward": 0.03900000000000003, "episodes": 1425, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 155215}
{"reward": 0.02900000000000002, "episodes": 1426, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 155324}
{"reward": 0.05400000000000004, "episodes": 1427, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 155433}
{"reward": 0.04500000000000003, "episodes": 1428, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 155542}
{"reward": 0.035000000000000024, "episodes": 1429, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 155651}
{"reward": 0.03000000000000002, "episodes": 1430, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 155760}
{"reward": 0.07300000000000005, "episodes": 1431, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 155869}
{"reward": 0.048000000000000036, "episodes": 1432, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 155978}
{"reward": 0.05600000000000004, "episodes": 1433, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 156087}
{"reward": 0.026000000000000016, "episodes": 1434, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 156196}
{"reward": 0.023000000000000013, "episodes": 1435, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 156305}
{"reward": 0.07500000000000005, "episodes": 1436, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 156414}
{"reward": 0.060000000000000046, "episodes": 1437, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 156523}
{"reward": 0.024000000000000014, "episodes": 1438, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 156632}
{"reward": 0.04400000000000003, "episodes": 1439, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 156741}
{"reward": 0.03900000000000003, "episodes": 1440, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 156850}
{"reward": 0.02100000000000001, "episodes": 1441, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 156959}
{"reward": 0.06900000000000005, "episodes": 1442, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 157068}
{"reward": 0.03800000000000003, "episodes": 1443, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 157177}
{"reward": 0.048000000000000036, "episodes": 1444, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 157286}
{"reward": 0.07400000000000005, "episodes": 1445, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 157395}
{"reward": 0.059000000000000045, "episodes": 1446, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 157504}
{"reward": 0.07200000000000005, "episodes": 1447, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 157613}
{"reward": 0.07000000000000005, "episodes": 1448, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 157722}
{"reward": 0.057000000000000044, "episodes": 1449, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 157831}
{"reward": 0.04500000000000003, "episodes": 1450, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 157940}
{"reward": 0.05200000000000004, "episodes": 1451, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 158049}
{"reward": 0.04900000000000004, "episodes": 1452, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 158158}
{"reward": 0.05400000000000004, "episodes": 1453, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 158267}
{"reward": 0.007, "episodes": 1454, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 158376}
{"reward": 0.08100000000000006, "episodes": 1455, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 158485}
{"reward": 0.05500000000000004, "episodes": 1456, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 158594}
{"reward": 0.036000000000000025, "episodes": 1457, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 158703}
{"reward": 0.036000000000000025, "episodes": 1458, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 158812}
{"reward": 0.06900000000000005, "episodes": 1459, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 158921}
{"reward": 0.03000000000000002, "episodes": 1460, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 159030}
{"reward": 0.058000000000000045, "episodes": 1461, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 159139}
{"reward": 0.03000000000000002, "episodes": 1462, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 159248}
{"reward": 0.036000000000000025, "episodes": 1463, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 159357}
{"reward": 0.03300000000000002, "episodes": 1464, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 159466}
{"reward": 0.036000000000000025, "episodes": 1465, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 159575}
{"reward": 0.06200000000000005, "episodes": 1466, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 159684}
{"reward": 0.047000000000000035, "episodes": 1467, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 159793}
{"reward": 0.05300000000000004, "episodes": 1468, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 159902}
{"reward": 0.015000000000000006, "episodes": 1469, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 160011}
{"reward": 0.060000000000000046, "episodes": 1470, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 160120}
{"reward": 0.046000000000000034, "episodes": 1471, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 160229}
{"reward": 0.07500000000000005, "episodes": 1472, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 160338}
{"reward": 0.07600000000000005, "episodes": 1473, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 160447}
{"reward": 0.08100000000000006, "episodes": 1474, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 160556}
{"reward": 0.07000000000000005, "episodes": 1475, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 160665}
{"reward": 0.057000000000000044, "episodes": 1476, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 160774}
{"reward": 0.058000000000000045, "episodes": 1477, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 160883}
{"reward": 0.06100000000000005, "episodes": 1478, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 160992}
{"reward": 0.012000000000000004, "episodes": 1479, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 161101}
{"reward": 0.06200000000000005, "episodes": 1480, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 161210}
{"reward": 0.025000000000000015, "episodes": 1481, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 161319}
{"reward": 0.035000000000000024, "episodes": 1482, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 161428}
{"reward": 0.07600000000000005, "episodes": 1483, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 161537}
{"reward": 0.05000000000000004, "episodes": 1484, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 161646}
{"reward": 0.08200000000000006, "episodes": 1485, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 161755}
{"reward": 0.08200000000000006, "episodes": 1486, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 161864}
{"reward": 0.07400000000000005, "episodes": 1487, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 161973}
{"reward": 0.05400000000000004, "episodes": 1488, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 162082}
{"reward": 0.059000000000000045, "episodes": 1489, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 162191}
{"reward": 0.05000000000000004, "episodes": 1490, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 162300}
{"reward": 0.03200000000000002, "episodes": 1491, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 162409}
{"reward": 0.06100000000000005, "episodes": 1492, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 162518}
{"reward": 0.0, "episodes": 1493, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 162627}
{"reward": 0.05400000000000004, "episodes": 1494, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 162736}
{"reward": 0.06200000000000005, "episodes": 1495, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 162845}
{"reward": 0.03100000000000002, "episodes": 1496, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 162954}
{"reward": 0.02000000000000001, "episodes": 1497, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 163063}
{"reward": 0.07800000000000006, "episodes": 1498, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 163172}
{"reward": 0.07100000000000005, "episodes": 1499, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 163281}
{"reward": 0.07100000000000005, "episodes": 1500, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 163390}
{"reward": 0.05300000000000004, "episodes": 1501, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 163499}
{"reward": 0.07100000000000005, "episodes": 1502, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 163608}
{"reward": 0.04100000000000003, "episodes": 1503, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 163717}
{"reward": 0.05100000000000004, "episodes": 1504, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 163826}
{"reward": 0.08400000000000006, "episodes": 1505, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 163935}
{"reward": 0.048000000000000036, "episodes": 1506, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 164044}
{"reward": 0.047000000000000035, "episodes": 1507, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 164153}
{"reward": 0.059000000000000045, "episodes": 1508, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 164262}
{"reward": 0.05200000000000004, "episodes": 1509, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 164371}
{"reward": 0.05500000000000004, "episodes": 1510, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 164480}
{"reward": 0.04500000000000003, "episodes": 1511, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 164589}
{"reward": 0.003, "episodes": 1512, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 164698}
{"reward": 0.048000000000000036, "episodes": 1513, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 164807}
{"reward": 0.04200000000000003, "episodes": 1514, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 164916}
{"reward": 0.04500000000000003, "episodes": 1515, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 165025}
{"reward": 0.05400000000000004, "episodes": 1516, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 165134}
{"reward": 0.07000000000000005, "episodes": 1517, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 165243}
{"reward": 0.048000000000000036, "episodes": 1518, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 165352}
{"reward": 0.05600000000000004, "episodes": 1519, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 165461}
{"reward": 0.059000000000000045, "episodes": 1520, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 165570}
{"reward": 0.05100000000000004, "episodes": 1521, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 165679}
{"reward": 0.04900000000000004, "episodes": 1522, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 165788}
{"reward": 0.027000000000000017, "episodes": 1523, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 165897}
{"reward": 0.02900000000000002, "episodes": 1524, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 166006}
{"reward": 0.036000000000000025, "episodes": 1525, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 166115}
{"reward": 0.04100000000000003, "episodes": 1526, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 166224}
{"reward": 0.037000000000000026, "episodes": 1527, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 166333}
{"reward": 0.04900000000000004, "episodes": 1528, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 166442}
{"reward": 0.058000000000000045, "episodes": 1529, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 166551}
{"reward": 0.058000000000000045, "episodes": 1530, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 166660}
{"reward": 0.04400000000000003, "episodes": 1531, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 166769}
{"reward": 0.03100000000000002, "episodes": 1532, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 166878}
{"reward": 0.037000000000000026, "episodes": 1533, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 166987}
{"reward": 0.07000000000000005, "episodes": 1534, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 167096}
{"reward": 0.024000000000000014, "episodes": 1535, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 167205}
{"reward": 0.06500000000000004, "episodes": 1536, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 167314}
{"reward": 0.03400000000000002, "episodes": 1537, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 167423}
{"reward": 0.07300000000000005, "episodes": 1538, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 167532}
{"reward": 0.05400000000000004, "episodes": 1539, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 167641}
{"reward": 0.05600000000000004, "episodes": 1540, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 167750}
{"reward": 0.04400000000000003, "episodes": 1541, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 167859}
{"reward": 0.04400000000000003, "episodes": 1542, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 167968}
{"reward": 0.028000000000000018, "episodes": 1543, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 168077}
{"reward": 0.04300000000000003, "episodes": 1544, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 168186}
{"reward": 0.04300000000000003, "episodes": 1545, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 168295}
{"reward": 0.07400000000000005, "episodes": 1546, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 168404}
{"reward": 0.04300000000000003, "episodes": 1547, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 168513}
{"reward": 0.03800000000000003, "episodes": 1548, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 168622}
{"reward": 0.07700000000000005, "episodes": 1549, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 168731}
{"reward": 0.036000000000000025, "episodes": 1550, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 168840}
{"reward": 0.09000000000000007, "episodes": 1551, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 168949}
{"reward": 0.09800000000000007, "episodes": 1552, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 169058}
{"reward": 0.060000000000000046, "episodes": 1553, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 169167}
{"reward": 0.059000000000000045, "episodes": 1554, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 169276}
{"reward": 0.07400000000000005, "episodes": 1555, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 169385}
{"reward": 0.05400000000000004, "episodes": 1556, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 169494}
{"reward": 0.046000000000000034, "episodes": 1557, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 169603}
{"reward": 0.048000000000000036, "episodes": 1558, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 169712}
{"reward": 0.07100000000000005, "episodes": 1559, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 169821}
{"reward": 0.060000000000000046, "episodes": 1560, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 169930}
{"reward": 0.026000000000000016, "episodes": 1561, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 170039}
{"reward": 0.025000000000000015, "episodes": 1562, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 170148}
{"reward": 0.04100000000000003, "episodes": 1563, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 170257}
{"reward": 0.06700000000000005, "episodes": 1564, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 170366}
{"reward": 0.04300000000000003, "episodes": 1565, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 170475}
{"reward": 0.060000000000000046, "episodes": 1566, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 170584}
{"reward": 0.05200000000000004, "episodes": 1567, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 170693}
{"reward": 0.06600000000000004, "episodes": 1568, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 170802}
{"reward": 0.017000000000000008, "episodes": 1569, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 170911}
{"reward": 0.05200000000000004, "episodes": 1570, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 171020}
{"reward": 0.037000000000000026, "episodes": 1571, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 171129}
{"reward": 0.04900000000000004, "episodes": 1572, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 171238}
{"reward": 0.013000000000000005, "episodes": 1573, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 171347}
{"reward": 0.05200000000000004, "episodes": 1574, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 171456}
{"reward": 0.025000000000000015, "episodes": 1575, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 171565}
{"reward": 0.037000000000000026, "episodes": 1576, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 171674}
{"reward": 0.04300000000000003, "episodes": 1577, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 171783}
{"reward": 0.03400000000000002, "episodes": 1578, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 171892}
{"reward": 0.027000000000000017, "episodes": 1579, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 172001}
{"reward": 0.047000000000000035, "episodes": 1580, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 172110}
{"reward": 0.05300000000000004, "episodes": 1581, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 172219}
{"reward": 0.03000000000000002, "episodes": 1582, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 172328}
{"reward": 0.03200000000000002, "episodes": 1583, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 172437}
{"reward": 0.05400000000000004, "episodes": 1584, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 172546}
{"reward": 0.06500000000000004, "episodes": 1585, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 172655}
{"reward": 0.09500000000000007, "episodes": 1586, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 172764}
{"reward": 0.08800000000000006, "episodes": 1587, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 172873}
{"reward": 0.06100000000000005, "episodes": 1588, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 172982}
{"reward": 0.03300000000000002, "episodes": 1589, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 173091}
{"reward": 0.026000000000000016, "episodes": 1590, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 173200}
{"reward": 0.07300000000000005, "episodes": 1591, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 173309}
{"reward": 0.08400000000000006, "episodes": 1592, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 173418}
{"reward": 0.03900000000000003, "episodes": 1593, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 173527}
{"reward": 0.08200000000000006, "episodes": 1594, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 173636}
{"reward": 0.016000000000000007, "episodes": 1595, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 173745}
{"reward": 0.03000000000000002, "episodes": 1596, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 173854}
{"reward": 0.05500000000000004, "episodes": 1597, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 173963}
{"reward": 0.04500000000000003, "episodes": 1598, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 174072}
{"reward": 0.059000000000000045, "episodes": 1599, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 174181}
{"reward": 0.05600000000000004, "episodes": 1600, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 174290}
{"reward": 0.06100000000000005, "episodes": 1601, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 174399}
{"reward": 0.04100000000000003, "episodes": 1602, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 174508}
{"reward": 0.03300000000000002, "episodes": 1603, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 174617}
{"reward": 0.03400000000000002, "episodes": 1604, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 174726}
{"reward": 0.028000000000000018, "episodes": 1605, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 174835}
{"reward": 0.023000000000000013, "episodes": 1606, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 174944}
{"reward": 0.027000000000000017, "episodes": 1607, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 175053}
{"reward": 0.01800000000000001, "episodes": 1608, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 175162}
{"reward": 0.035000000000000024, "episodes": 1609, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 175271}
{"reward": 0.036000000000000025, "episodes": 1610, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 175380}
{"reward": 0.04300000000000003, "episodes": 1611, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 175489}
{"reward": 0.059000000000000045, "episodes": 1612, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 175598}
{"reward": 0.025000000000000015, "episodes": 1613, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 175707}
{"reward": 0.04500000000000003, "episodes": 1614, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 175816}
{"reward": 0.05000000000000004, "episodes": 1615, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 175925}
{"reward": 0.057000000000000044, "episodes": 1616, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 176034}
{"reward": 0.06200000000000005, "episodes": 1617, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 176143}
{"reward": 0.09600000000000007, "episodes": 1618, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 176252}
{"reward": 0.06600000000000004, "episodes": 1619, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 176361}
{"reward": 0.023000000000000013, "episodes": 1620, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 176470}
{"reward": 0.036000000000000025, "episodes": 1621, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 176579}
{"reward": 0.09000000000000007, "episodes": 1622, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 176688}
{"reward": 0.06300000000000004, "episodes": 1623, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 176797}
{"reward": 0.04000000000000003, "episodes": 1624, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 176906}
{"reward": 0.04100000000000003, "episodes": 1625, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 177015}
{"reward": 0.06200000000000005, "episodes": 1626, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 177124}
{"reward": 0.04200000000000003, "episodes": 1627, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 177233}
{"reward": 0.057000000000000044, "episodes": 1628, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 177342}
{"reward": 0.06200000000000005, "episodes": 1629, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 177451}
{"reward": 0.036000000000000025, "episodes": 1630, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 177560}
{"reward": 0.057000000000000044, "episodes": 1631, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 177669}
{"reward": 0.05300000000000004, "episodes": 1632, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 177778}
{"reward": 0.04500000000000003, "episodes": 1633, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 177887}
{"reward": 0.03400000000000002, "episodes": 1634, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 177996}
{"reward": 0.057000000000000044, "episodes": 1635, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 178105}
{"reward": 0.05400000000000004, "episodes": 1636, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 178214}
{"reward": 0.03400000000000002, "episodes": 1637, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 178323}
{"reward": 0.05400000000000004, "episodes": 1638, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 178432}
{"reward": 0.022000000000000013, "episodes": 1639, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 178541}
{"reward": 0.07600000000000005, "episodes": 1640, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 178650}
{"reward": 0.05400000000000004, "episodes": 1641, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 178759}
{"reward": 0.036000000000000025, "episodes": 1642, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 178868}
{"reward": 0.05000000000000004, "episodes": 1643, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 178977}
{"reward": 0.059000000000000045, "episodes": 1644, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 179086}
{"reward": 0.028000000000000018, "episodes": 1645, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 179195}
{"reward": 0.05600000000000004, "episodes": 1646, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 179304}
{"reward": 0.05200000000000004, "episodes": 1647, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 179413}
{"reward": 0.06600000000000004, "episodes": 1648, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 179522}
{"reward": 0.03000000000000002, "episodes": 1649, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 179631}
{"reward": 0.03300000000000002, "episodes": 1650, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 179740}
{"reward": 0.058000000000000045, "episodes": 1651, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 179849}
{"reward": 0.059000000000000045, "episodes": 1652, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 179958}
{"reward": 0.06100000000000005, "episodes": 1653, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 180067}
{"reward": 0.07500000000000005, "episodes": 1654, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 180176}
{"reward": 0.01900000000000001, "episodes": 1655, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 180285}
{"reward": 0.057000000000000044, "episodes": 1656, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 180394}
{"reward": 0.03400000000000002, "episodes": 1657, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 180503}
{"reward": 0.010000000000000002, "episodes": 1658, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 180612}
{"reward": 0.07000000000000005, "episodes": 1659, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 180721}
{"reward": 0.02900000000000002, "episodes": 1660, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 180830}
{"reward": 0.04900000000000004, "episodes": 1661, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 180939}
{"reward": 0.046000000000000034, "episodes": 1662, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 181048}
{"reward": 0.037000000000000026, "episodes": 1663, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 181157}
{"reward": 0.047000000000000035, "episodes": 1664, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 181266}
{"reward": 0.05400000000000004, "episodes": 1665, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 181375}
{"reward": 0.05400000000000004, "episodes": 1666, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 181484}
{"reward": 0.03800000000000003, "episodes": 1667, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 181593}
{"reward": 0.026000000000000016, "episodes": 1668, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 181702}
{"reward": 0.035000000000000024, "episodes": 1669, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 181811}
{"reward": 0.037000000000000026, "episodes": 1670, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 181920}
{"reward": 0.05500000000000004, "episodes": 1671, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 182029}
{"reward": 0.02900000000000002, "episodes": 1672, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 182138}
{"reward": 0.047000000000000035, "episodes": 1673, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 182247}
{"reward": 0.03300000000000002, "episodes": 1674, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 182356}
{"reward": 0.06100000000000005, "episodes": 1675, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 182465}
{"reward": 0.07800000000000006, "episodes": 1676, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 182574}
{"reward": 0.10200000000000008, "episodes": 1677, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 182683}
{"reward": 0.05300000000000004, "episodes": 1678, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 182792}
{"reward": 0.07500000000000005, "episodes": 1679, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 182901}
{"reward": 0.07500000000000005, "episodes": 1680, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 183010}
{"reward": 0.07100000000000005, "episodes": 1681, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 183119}
{"reward": 0.02900000000000002, "episodes": 1682, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 183228}
{"reward": 0.05300000000000004, "episodes": 1683, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 183337}
{"reward": 0.09100000000000007, "episodes": 1684, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 183446}
{"reward": 0.08900000000000007, "episodes": 1685, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 183555}
{"reward": 0.04400000000000003, "episodes": 1686, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 183664}
{"reward": 0.04300000000000003, "episodes": 1687, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 183773}
{"reward": 0.036000000000000025, "episodes": 1688, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 183882}
{"reward": 0.09200000000000007, "episodes": 1689, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 183991}
{"reward": 0.07200000000000005, "episodes": 1690, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 184100}
{"reward": 0.06900000000000005, "episodes": 1691, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 184209}
{"reward": 0.05600000000000004, "episodes": 1692, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 184318}
{"reward": 0.012000000000000004, "episodes": 1693, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 184427}
{"reward": 0.024000000000000014, "episodes": 1694, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 184536}
{"reward": 0.08100000000000006, "episodes": 1695, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 184645}
{"reward": 0.08300000000000006, "episodes": 1696, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 184754}
{"reward": 0.06100000000000005, "episodes": 1697, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 184863}
{"reward": 0.05000000000000004, "episodes": 1698, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 184972}
{"reward": 0.03200000000000002, "episodes": 1699, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 185081}
{"reward": 0.037000000000000026, "episodes": 1700, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 185190}
{"reward": 0.024000000000000014, "episodes": 1701, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 185299}
{"reward": 0.036000000000000025, "episodes": 1702, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 185408}
{"reward": 0.07700000000000005, "episodes": 1703, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 185517}
{"reward": 0.06700000000000005, "episodes": 1704, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 185626}
{"reward": 0.05200000000000004, "episodes": 1705, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 185735}
{"reward": 0.03200000000000002, "episodes": 1706, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 185844}
{"reward": 0.05100000000000004, "episodes": 1707, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 185953}
{"reward": 0.05400000000000004, "episodes": 1708, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 186062}
{"reward": 0.057000000000000044, "episodes": 1709, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 186171}
{"reward": 0.05400000000000004, "episodes": 1710, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 186280}
{"reward": 0.01800000000000001, "episodes": 1711, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 186389}
{"reward": 0.03800000000000003, "episodes": 1712, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 186498}
{"reward": 0.02100000000000001, "episodes": 1713, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 186607}
{"reward": 0.005, "episodes": 1714, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 186716}
{"reward": 0.04200000000000003, "episodes": 1715, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 186825}
{"reward": 0.03000000000000002, "episodes": 1716, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 186934}
{"reward": 0.04200000000000003, "episodes": 1717, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 187043}
{"reward": 0.04100000000000003, "episodes": 1718, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 187152}
{"reward": 0.05400000000000004, "episodes": 1719, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 187261}
{"reward": 0.04300000000000003, "episodes": 1720, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 187370}
{"reward": 0.04100000000000003, "episodes": 1721, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 187479}
{"reward": 0.059000000000000045, "episodes": 1722, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 187588}
{"reward": 0.05000000000000004, "episodes": 1723, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 187697}
{"reward": 0.028000000000000018, "episodes": 1724, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 187806}
{"reward": 0.03400000000000002, "episodes": 1725, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 187915}
{"reward": 0.057000000000000044, "episodes": 1726, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 188024}
{"reward": 0.06500000000000004, "episodes": 1727, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 188133}
{"reward": 0.05500000000000004, "episodes": 1728, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 188242}
{"reward": 0.05100000000000004, "episodes": 1729, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 188351}
{"reward": 0.05000000000000004, "episodes": 1730, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 188460}
{"reward": 0.028000000000000018, "episodes": 1731, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 188569}
{"reward": 0.015000000000000006, "episodes": 1732, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 188678}
{"reward": 0.03300000000000002, "episodes": 1733, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 188787}
{"reward": 0.08500000000000006, "episodes": 1734, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 188896}
{"reward": 0.02900000000000002, "episodes": 1735, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 189005}
{"reward": 0.07200000000000005, "episodes": 1736, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 189114}
{"reward": 0.017000000000000008, "episodes": 1737, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 189223}
{"reward": 0.04500000000000003, "episodes": 1738, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 189332}
{"reward": 0.07800000000000006, "episodes": 1739, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 189441}
{"reward": 0.07100000000000005, "episodes": 1740, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 189550}
{"reward": 0.04200000000000003, "episodes": 1741, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 189659}
{"reward": 0.03200000000000002, "episodes": 1742, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 189768}
{"reward": 0.060000000000000046, "episodes": 1743, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 189877}
{"reward": 0.04200000000000003, "episodes": 1744, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 189986}
{"reward": 0.04400000000000003, "episodes": 1745, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 190095}
{"reward": 0.03300000000000002, "episodes": 1746, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 190204}
{"reward": 0.03800000000000003, "episodes": 1747, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 190313}
{"reward": 0.058000000000000045, "episodes": 1748, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 190422}
{"reward": 0.028000000000000018, "episodes": 1749, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 190531}
{"reward": 0.023000000000000013, "episodes": 1750, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 190640}
{"reward": 0.03000000000000002, "episodes": 1751, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 190749}
{"reward": 0.02900000000000002, "episodes": 1752, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 190858}
{"reward": 0.04000000000000003, "episodes": 1753, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 190967}
{"reward": 0.07900000000000006, "episodes": 1754, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 191076}
{"reward": 0.058000000000000045, "episodes": 1755, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 191185}
{"reward": 0.07300000000000005, "episodes": 1756, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 191294}
{"reward": 0.07400000000000005, "episodes": 1757, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 191403}
{"reward": 0.060000000000000046, "episodes": 1758, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 191512}
{"reward": 0.057000000000000044, "episodes": 1759, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 191621}
{"reward": 0.07700000000000005, "episodes": 1760, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 191730}
{"reward": 0.04100000000000003, "episodes": 1761, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 191839}
{"reward": 0.04900000000000004, "episodes": 1762, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 191948}
{"reward": 0.05600000000000004, "episodes": 1763, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 192057}
{"reward": 0.09600000000000007, "episodes": 1764, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 192166}
{"reward": 0.07700000000000005, "episodes": 1765, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 192275}
{"reward": 0.09500000000000007, "episodes": 1766, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 192384}
{"reward": 0.06700000000000005, "episodes": 1767, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 192493}
{"reward": 0.027000000000000017, "episodes": 1768, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 192602}
{"reward": 0.02000000000000001, "episodes": 1769, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 192711}
{"reward": 0.09500000000000007, "episodes": 1770, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 192820}
{"reward": 0.048000000000000036, "episodes": 1771, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 192929}
{"reward": 0.05500000000000004, "episodes": 1772, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 193038}
{"reward": 0.028000000000000018, "episodes": 1773, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 193147}
{"reward": 0.03000000000000002, "episodes": 1774, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 193256}
{"reward": 0.06300000000000004, "episodes": 1775, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 193365}
{"reward": 0.03200000000000002, "episodes": 1776, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 193474}
{"reward": 0.06100000000000005, "episodes": 1777, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 193583}
{"reward": 0.07600000000000005, "episodes": 1778, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 193692}
{"reward": 0.06100000000000005, "episodes": 1779, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 193801}
{"reward": 0.07000000000000005, "episodes": 1780, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 193910}
{"reward": 0.06200000000000005, "episodes": 1781, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 194019}
{"reward": 0.03200000000000002, "episodes": 1782, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 194128}
{"reward": 0.06500000000000004, "episodes": 1783, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 194237}
{"reward": 0.047000000000000035, "episodes": 1784, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 194346}
{"reward": 0.06300000000000004, "episodes": 1785, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 194455}
{"reward": 0.05300000000000004, "episodes": 1786, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 194564}
{"reward": 0.06200000000000005, "episodes": 1787, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 194673}
{"reward": 0.04900000000000004, "episodes": 1788, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 194782}
{"reward": 0.04500000000000003, "episodes": 1789, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 194891}
{"reward": 0.07900000000000006, "episodes": 1790, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 195000}
{"reward": 0.06200000000000005, "episodes": 1791, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 195109}
{"reward": 0.04400000000000003, "episodes": 1792, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 195218}
{"reward": 0.059000000000000045, "episodes": 1793, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 195327}
{"reward": 0.06100000000000005, "episodes": 1794, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 195436}
{"reward": 0.07600000000000005, "episodes": 1795, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 195545}
{"reward": 0.046000000000000034, "episodes": 1796, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 195654}
{"reward": 0.03200000000000002, "episodes": 1797, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 195763}
{"reward": 0.03800000000000003, "episodes": 1798, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 195872}
{"reward": 0.037000000000000026, "episodes": 1799, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 195981}
{"reward": 0.04100000000000003, "episodes": 1800, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 196090}
{"reward": 0.06300000000000004, "episodes": 1801, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 196199}
{"reward": 0.05000000000000004, "episodes": 1802, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 196308}
{"reward": 0.046000000000000034, "episodes": 1803, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 196417}
{"reward": 0.04200000000000003, "episodes": 1804, "mean 100 episode reward": 0.0, "head": 9, "% time spent exploring": 9, "steps": 196526}
{"reward": 0.02000000000000001, "episodes": 1805, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 196635}
{"reward": 0.05500000000000004, "episodes": 1806, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 196744}
{"reward": 0.04200000000000003, "episodes": 1807, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 196853}
{"reward": 0.013000000000000005, "episodes": 1808, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 196962}
{"reward": 0.035000000000000024, "episodes": 1809, "mean 100 episode reward": 0.0, "head": 0, "% time spent exploring": 9, "steps": 197071}
{"reward": 0.057000000000000044, "episodes": 1810, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 197180}
{"reward": 0.06300000000000004, "episodes": 1811, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 197289}
{"reward": 0.04100000000000003, "episodes": 1812, "mean 100 episode reward": 0.0, "head": 2, "% time spent exploring": 9, "steps": 197398}
{"reward": 0.05600000000000004, "episodes": 1813, "mean 100 episode reward": 0.0, "head": 3, "% time spent exploring": 9, "steps": 197507}
{"reward": 0.05400000000000004, "episodes": 1814, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 197616}
{"reward": 0.03200000000000002, "episodes": 1815, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 197725}
{"reward": 0.01900000000000001, "episodes": 1816, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 197834}
{"reward": 0.023000000000000013, "episodes": 1817, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 197943}
{"reward": 0.036000000000000025, "episodes": 1818, "mean 100 episode reward": 0.0, "head": 1, "% time spent exploring": 9, "steps": 198052}
{"reward": 0.058000000000000045, "episodes": 1819, "mean 100 episode reward": 0.0, "head": 6, "% time spent exploring": 9, "steps": 198161}
{"reward": 0.06700000000000005, "episodes": 1820, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 198270}
{"reward": 0.08200000000000006, "episodes": 1821, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 198379}
{"reward": 0.06100000000000005, "episodes": 1822, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 198488}
{"reward": 0.05200000000000004, "episodes": 1823, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 198597}
{"reward": 0.08200000000000006, "episodes": 1824, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 198706}
{"reward": 0.07100000000000005, "episodes": 1825, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 198815}
{"reward": 0.07200000000000005, "episodes": 1826, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 198924}
{"reward": 0.059000000000000045, "episodes": 1827, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 199033}
{"reward": 0.04400000000000003, "episodes": 1828, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 199142}
{"reward": 0.009000000000000001, "episodes": 1829, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 199251}
{"reward": 0.03800000000000003, "episodes": 1830, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 199360}
{"reward": 0.05400000000000004, "episodes": 1831, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 199469}
{"reward": 0.04900000000000004, "episodes": 1832, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 199578}
{"reward": 0.048000000000000036, "episodes": 1833, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 199687}
{"reward": 0.03800000000000003, "episodes": 1834, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 199796}
{"reward": 0.06500000000000004, "episodes": 1835, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 199905}
{"reward": 0.06500000000000004, "episodes": 1836, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 200014}
{"reward": 0.037000000000000026, "episodes": 1837, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 200123}
{"reward": 0.02900000000000002, "episodes": 1838, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 200232}
{"reward": 0.03100000000000002, "episodes": 1839, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 200341}
{"reward": 0.03100000000000002, "episodes": 1840, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 200450}
{"reward": 0.02000000000000001, "episodes": 1841, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 200559}
{"reward": 0.03300000000000002, "episodes": 1842, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 200668}
{"reward": 0.04000000000000003, "episodes": 1843, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 200777}
{"reward": 0.027000000000000017, "episodes": 1844, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 200886}
{"reward": 0.058000000000000045, "episodes": 1845, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 200995}
{"reward": 0.03300000000000002, "episodes": 1846, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 201104}
{"reward": 0.05500000000000004, "episodes": 1847, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 201213}
{"reward": 0.04900000000000004, "episodes": 1848, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 201322}
{"reward": 0.07300000000000005, "episodes": 1849, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 201431}
{"reward": 0.08100000000000006, "episodes": 1850, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 201540}
{"reward": 0.03400000000000002, "episodes": 1851, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 201649}
{"reward": 0.08100000000000006, "episodes": 1852, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 201758}
{"reward": 0.04300000000000003, "episodes": 1853, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 201867}
{"reward": 0.06600000000000004, "episodes": 1854, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 201976}
{"reward": 0.04400000000000003, "episodes": 1855, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 202085}
{"reward": 0.05000000000000004, "episodes": 1856, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 202194}
{"reward": 0.06600000000000004, "episodes": 1857, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 202303}
{"reward": 0.02100000000000001, "episodes": 1858, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 202412}
{"reward": 0.035000000000000024, "episodes": 1859, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 202521}
{"reward": 0.07500000000000005, "episodes": 1860, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 202630}
{"reward": 0.07600000000000005, "episodes": 1861, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 202739}
{"reward": 0.014000000000000005, "episodes": 1862, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 202848}
{"reward": 0.05600000000000004, "episodes": 1863, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 202957}
{"reward": 0.05500000000000004, "episodes": 1864, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 203066}
{"reward": 0.07900000000000006, "episodes": 1865, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 203175}
{"reward": 0.05400000000000004, "episodes": 1866, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 203284}
{"reward": 0.03400000000000002, "episodes": 1867, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 203393}
{"reward": 0.05000000000000004, "episodes": 1868, "mean 100 episode reward": 0.0, "head": 4, "% time spent exploring": 9, "steps": 203502}
{"reward": 0.05300000000000004, "episodes": 1869, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 203611}
{"reward": 0.06400000000000004, "episodes": 1870, "mean 100 episode reward": 0.0, "head": 5, "% time spent exploring": 9, "steps": 203720}
{"reward": 0.04100000000000003, "episodes": 1871, "mean 100 episode reward": 0.0, "head": 7, "% time spent exploring": 9, "steps": 203829}
{"reward": 0.06400000000000004, "episodes": 1872, "mean 100 episode reward": 0.0, "head": 8, "% time spent exploring": 9, "steps": 203938}
{"reward": 0.06600000000000004, "episodes": 1873, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 204047}
{"reward": 0.09000000000000007, "episodes": 1874, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 204156}
{"reward": 0.06300000000000004, "episodes": 1875, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 204265}
{"reward": 0.08800000000000006, "episodes": 1876, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 204374}
{"reward": 0.04300000000000003, "episodes": 1877, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 204483}
{"reward": 0.08100000000000006, "episodes": 1878, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 204592}
{"reward": 0.048000000000000036, "episodes": 1879, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 204701}
{"reward": 0.05100000000000004, "episodes": 1880, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 204810}
{"reward": 0.02900000000000002, "episodes": 1881, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 204919}
{"reward": 0.05000000000000004, "episodes": 1882, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 205028}
{"reward": 0.048000000000000036, "episodes": 1883, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 205137}
{"reward": 0.06400000000000004, "episodes": 1884, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 205246}
{"reward": 0.05100000000000004, "episodes": 1885, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 205355}
{"reward": 0.046000000000000034, "episodes": 1886, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 205464}
{"reward": 0.04500000000000003, "episodes": 1887, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 205573}
{"reward": 0.07300000000000005, "episodes": 1888, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 205682}
{"reward": 0.06900000000000005, "episodes": 1889, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 205791}
{"reward": 0.059000000000000045, "episodes": 1890, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 205900}
{"reward": 0.08300000000000006, "episodes": 1891, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 206009}
{"reward": 0.06500000000000004, "episodes": 1892, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 206118}
{"reward": 0.04900000000000004, "episodes": 1893, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 206227}
{"reward": 0.05600000000000004, "episodes": 1894, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 206336}
{"reward": 0.05100000000000004, "episodes": 1895, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 206445}
{"reward": 0.035000000000000024, "episodes": 1896, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 206554}
{"reward": 0.023000000000000013, "episodes": 1897, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 206663}
{"reward": 0.06400000000000004, "episodes": 1898, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 206772}
{"reward": 0.05600000000000004, "episodes": 1899, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 206881}
{"reward": 0.04400000000000003, "episodes": 1900, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 206990}
{"reward": 0.07600000000000005, "episodes": 1901, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 207099}
{"reward": 0.07400000000000005, "episodes": 1902, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 207208}
{"reward": 0.035000000000000024, "episodes": 1903, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 207317}
{"reward": 0.007, "episodes": 1904, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 207426}
{"reward": 0.04000000000000003, "episodes": 1905, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 207535}
{"reward": 0.06200000000000005, "episodes": 1906, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 207644}
{"reward": 0.05600000000000004, "episodes": 1907, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 207753}
{"reward": 0.05200000000000004, "episodes": 1908, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 207862}
{"reward": 0.05600000000000004, "episodes": 1909, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 207971}
{"reward": 0.05100000000000004, "episodes": 1910, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 208080}
{"reward": 0.04000000000000003, "episodes": 1911, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 208189}
{"reward": 0.06800000000000005, "episodes": 1912, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 208298}
{"reward": 0.04500000000000003, "episodes": 1913, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 208407}
{"reward": 0.05100000000000004, "episodes": 1914, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 208516}
{"reward": 0.035000000000000024, "episodes": 1915, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 208625}
{"reward": 0.02000000000000001, "episodes": 1916, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 208734}
{"reward": 0.037000000000000026, "episodes": 1917, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 208843}
{"reward": 0.04400000000000003, "episodes": 1918, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 208952}
{"reward": 0.10100000000000008, "episodes": 1919, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 209061}
{"reward": 0.05200000000000004, "episodes": 1920, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 209170}
{"reward": 0.037000000000000026, "episodes": 1921, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 209279}
{"reward": 0.05100000000000004, "episodes": 1922, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 209388}
{"reward": 0.03100000000000002, "episodes": 1923, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 209497}
{"reward": 0.06300000000000004, "episodes": 1924, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 209606}
{"reward": 0.05600000000000004, "episodes": 1925, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 209715}
{"reward": 0.04300000000000003, "episodes": 1926, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 209824}
{"reward": 0.07500000000000005, "episodes": 1927, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 209933}
{"reward": 0.08600000000000006, "episodes": 1928, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 210042}
{"reward": 0.04400000000000003, "episodes": 1929, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 210151}
{"reward": 0.059000000000000045, "episodes": 1930, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 210260}
{"reward": 0.07000000000000005, "episodes": 1931, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 210369}
{"reward": 0.023000000000000013, "episodes": 1932, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 210478}
{"reward": 0.03200000000000002, "episodes": 1933, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 210587}
{"reward": 0.04200000000000003, "episodes": 1934, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 210696}
{"reward": 0.06500000000000004, "episodes": 1935, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 210805}
{"reward": 0.07400000000000005, "episodes": 1936, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 210914}
{"reward": 0.05100000000000004, "episodes": 1937, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 211023}
{"reward": 0.06300000000000004, "episodes": 1938, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 211132}
{"reward": 0.03900000000000003, "episodes": 1939, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 211241}
{"reward": 0.03800000000000003, "episodes": 1940, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 211350}
{"reward": 0.05100000000000004, "episodes": 1941, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 211459}
{"reward": 0.04500000000000003, "episodes": 1942, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 211568}
{"reward": 0.07200000000000005, "episodes": 1943, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 211677}
{"reward": 0.07300000000000005, "episodes": 1944, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 211786}
{"reward": 0.059000000000000045, "episodes": 1945, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 211895}
{"reward": 0.04900000000000004, "episodes": 1946, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 212004}
{"reward": 0.07000000000000005, "episodes": 1947, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 212113}
{"reward": 0.03800000000000003, "episodes": 1948, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 212222}
{"reward": 0.03800000000000003, "episodes": 1949, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 212331}
{"reward": 0.04100000000000003, "episodes": 1950, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 212440}
{"reward": 0.05500000000000004, "episodes": 1951, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 212549}
{"reward": 0.04200000000000003, "episodes": 1952, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 212658}
{"reward": 0.07900000000000006, "episodes": 1953, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 212767}
{"reward": 0.06300000000000004, "episodes": 1954, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 212876}
{"reward": 0.03000000000000002, "episodes": 1955, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 212985}
{"reward": 0.008, "episodes": 1956, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 213094}
{"reward": 0.07500000000000005, "episodes": 1957, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 213203}
{"reward": 0.036000000000000025, "episodes": 1958, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 213312}
{"reward": 0.03900000000000003, "episodes": 1959, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 213421}
{"reward": 0.03900000000000003, "episodes": 1960, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 213530}
{"reward": 0.09800000000000007, "episodes": 1961, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 213639}
{"reward": 0.04900000000000004, "episodes": 1962, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 213748}
{"reward": 0.05300000000000004, "episodes": 1963, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 213857}
{"reward": 0.07100000000000005, "episodes": 1964, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 213966}
{"reward": 0.04200000000000003, "episodes": 1965, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 214075}
{"reward": 0.04400000000000003, "episodes": 1966, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 214184}
{"reward": 0.07700000000000005, "episodes": 1967, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 214293}
{"reward": 0.02100000000000001, "episodes": 1968, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 214402}
{"reward": 0.06300000000000004, "episodes": 1969, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 214511}
{"reward": 0.04300000000000003, "episodes": 1970, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 214620}
{"reward": 0.05400000000000004, "episodes": 1971, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 214729}
{"reward": 0.07800000000000006, "episodes": 1972, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 214838}
{"reward": 0.06300000000000004, "episodes": 1973, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 214947}
{"reward": 0.03100000000000002, "episodes": 1974, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 215056}
{"reward": 0.03100000000000002, "episodes": 1975, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 215165}
{"reward": 0.01900000000000001, "episodes": 1976, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 215274}
{"reward": 0.013000000000000005, "episodes": 1977, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 215383}
{"reward": 0.08900000000000007, "episodes": 1978, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 215492}
{"reward": 0.028000000000000018, "episodes": 1979, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 215601}
{"reward": 0.058000000000000045, "episodes": 1980, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 215710}
{"reward": 0.06500000000000004, "episodes": 1981, "mean 100 episode reward": 0.1, "head": 8, "% time spent exploring": 9, "steps": 215819}
{"reward": 0.03900000000000003, "episodes": 1982, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 215928}
{"reward": 0.08100000000000006, "episodes": 1983, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 216037}
{"reward": 0.009000000000000001, "episodes": 1984, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 216146}
{"reward": 0.03100000000000002, "episodes": 1985, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 216255}
{"reward": 0.01800000000000001, "episodes": 1986, "mean 100 episode reward": 0.1, "head": 9, "% time spent exploring": 9, "steps": 216364}
{"reward": 0.057000000000000044, "episodes": 1987, "mean 100 episode reward": 0.1, "head": 1, "% time spent exploring": 9, "steps": 216473}
{"reward": 0.059000000000000045, "episodes": 1988, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 216582}
{"reward": 0.08800000000000006, "episodes": 1989, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 216691}
{"reward": 0.060000000000000046, "episodes": 1990, "mean 100 episode reward": 0.1, "head": 5, "% time spent exploring": 9, "steps": 216800}
{"reward": 0.05200000000000004, "episodes": 1991, "mean 100 episode reward": 0.1, "head": 2, "% time spent exploring": 9, "steps": 216909}
{"reward": 0.04300000000000003, "episodes": 1992, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 217018}
{"reward": 0.03000000000000002, "episodes": 1993, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 217127}
{"reward": 0.08800000000000006, "episodes": 1994, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 217236}
{"reward": 0.058000000000000045, "episodes": 1995, "mean 100 episode reward": 0.1, "head": 3, "% time spent exploring": 9, "steps": 217345}
{"reward": 0.036000000000000025, "episodes": 1996, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 217454}
{"reward": 0.05100000000000004, "episodes": 1997, "mean 100 episode reward": 0.1, "head": 7, "% time spent exploring": 9, "steps": 217563}
{"reward": 0.05200000000000004, "episodes": 1998, "mean 100 episode reward": 0.1, "head": 0, "% time spent exploring": 9, "steps": 217672}
{"reward": 0.04000000000000003, "episodes": 1999, "mean 100 episode reward": 0.1, "head": 6, "% time spent exploring": 9, "steps": 217781}
{"reward": 0.057000000000000044, "episodes": 2000, "mean 100 episode reward": 0.1, "head": 4, "% time spent exploring": 9, "steps": 217890}
