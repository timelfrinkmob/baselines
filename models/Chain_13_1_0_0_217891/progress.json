{"reward": 0.028000000000000018, "% time spent exploring": 99, "episodes": 2, "head": 2, "mean 100 episode reward": 0.0, "steps": 108}
{"reward": 0.026000000000000016, "% time spent exploring": 99, "episodes": 3, "head": 0, "mean 100 episode reward": 0.0, "steps": 217}
{"reward": 0.017000000000000008, "% time spent exploring": 98, "episodes": 4, "head": 0, "mean 100 episode reward": 0.0, "steps": 326}
{"reward": 0.023000000000000013, "% time spent exploring": 98, "episodes": 5, "head": 6, "mean 100 episode reward": 0.0, "steps": 435}
{"reward": 0.02000000000000001, "% time spent exploring": 97, "episodes": 6, "head": 2, "mean 100 episode reward": 0.0, "steps": 544}
{"reward": 0.02100000000000001, "% time spent exploring": 97, "episodes": 7, "head": 4, "mean 100 episode reward": 0.0, "steps": 653}
{"reward": 0.016000000000000007, "% time spent exploring": 96, "episodes": 8, "head": 9, "mean 100 episode reward": 0.0, "steps": 762}
{"reward": 0.04100000000000003, "% time spent exploring": 96, "episodes": 9, "head": 3, "mean 100 episode reward": 0.0, "steps": 871}
{"reward": 0.02100000000000001, "% time spent exploring": 95, "episodes": 10, "head": 4, "mean 100 episode reward": 0.0, "steps": 980}
{"reward": 0.006, "% time spent exploring": 95, "episodes": 11, "head": 2, "mean 100 episode reward": 0.0, "steps": 1089}
{"reward": 0.037000000000000026, "% time spent exploring": 95, "episodes": 12, "head": 6, "mean 100 episode reward": 0.0, "steps": 1198}
{"reward": 0.017000000000000008, "% time spent exploring": 94, "episodes": 13, "head": 5, "mean 100 episode reward": 0.0, "steps": 1307}
{"reward": 0.004, "% time spent exploring": 94, "episodes": 14, "head": 9, "mean 100 episode reward": 0.0, "steps": 1416}
{"reward": 0.017000000000000008, "% time spent exploring": 93, "episodes": 15, "head": 4, "mean 100 episode reward": 0.0, "steps": 1525}
{"reward": 0.014000000000000005, "% time spent exploring": 93, "episodes": 16, "head": 2, "mean 100 episode reward": 0.0, "steps": 1634}
{"reward": 0.025000000000000015, "% time spent exploring": 92, "episodes": 17, "head": 0, "mean 100 episode reward": 0.0, "steps": 1743}
{"reward": 0.007, "% time spent exploring": 92, "episodes": 18, "head": 3, "mean 100 episode reward": 0.0, "steps": 1852}
{"reward": 0.006, "% time spent exploring": 91, "episodes": 19, "head": 5, "mean 100 episode reward": 0.0, "steps": 1961}
{"reward": 0.012000000000000004, "% time spent exploring": 91, "episodes": 20, "head": 3, "mean 100 episode reward": 0.0, "steps": 2070}
{"reward": 0.009000000000000001, "% time spent exploring": 90, "episodes": 21, "head": 6, "mean 100 episode reward": 0.0, "steps": 2179}
{"reward": 0.01800000000000001, "% time spent exploring": 90, "episodes": 22, "head": 5, "mean 100 episode reward": 0.0, "steps": 2288}
{"reward": 0.007, "% time spent exploring": 90, "episodes": 23, "head": 1, "mean 100 episode reward": 0.0, "steps": 2397}
{"reward": 0.009000000000000001, "% time spent exploring": 89, "episodes": 24, "head": 2, "mean 100 episode reward": 0.0, "steps": 2506}
{"reward": 0.011000000000000003, "% time spent exploring": 89, "episodes": 25, "head": 8, "mean 100 episode reward": 0.0, "steps": 2615}
{"reward": 0.03300000000000002, "% time spent exploring": 88, "episodes": 26, "head": 8, "mean 100 episode reward": 0.0, "steps": 2724}
{"reward": 0.03000000000000002, "% time spent exploring": 88, "episodes": 27, "head": 6, "mean 100 episode reward": 0.0, "steps": 2833}
{"reward": 0.011000000000000003, "% time spent exploring": 87, "episodes": 28, "head": 2, "mean 100 episode reward": 0.0, "steps": 2942}
{"reward": 0.0, "% time spent exploring": 87, "episodes": 29, "head": 4, "mean 100 episode reward": 0.0, "steps": 3051}
{"reward": 0.046000000000000034, "% time spent exploring": 86, "episodes": 30, "head": 5, "mean 100 episode reward": 0.0, "steps": 3160}
{"reward": 0.013000000000000005, "% time spent exploring": 86, "episodes": 31, "head": 7, "mean 100 episode reward": 0.0, "steps": 3269}
{"reward": 0.008, "% time spent exploring": 86, "episodes": 32, "head": 3, "mean 100 episode reward": 0.0, "steps": 3378}
{"reward": 0.005, "% time spent exploring": 85, "episodes": 33, "head": 5, "mean 100 episode reward": 0.0, "steps": 3487}
{"reward": 0.012000000000000004, "% time spent exploring": 85, "episodes": 34, "head": 8, "mean 100 episode reward": 0.0, "steps": 3596}
{"reward": 0.003, "% time spent exploring": 84, "episodes": 35, "head": 3, "mean 100 episode reward": 0.0, "steps": 3705}
{"reward": 0.007, "% time spent exploring": 84, "episodes": 36, "head": 8, "mean 100 episode reward": 0.0, "steps": 3814}
{"reward": 0.01900000000000001, "% time spent exploring": 83, "episodes": 37, "head": 5, "mean 100 episode reward": 0.0, "steps": 3923}
{"reward": 0.024000000000000014, "% time spent exploring": 83, "episodes": 38, "head": 1, "mean 100 episode reward": 0.0, "steps": 4032}
{"reward": 0.0, "% time spent exploring": 82, "episodes": 39, "head": 8, "mean 100 episode reward": 0.0, "steps": 4141}
{"reward": 0.009000000000000001, "% time spent exploring": 82, "episodes": 40, "head": 1, "mean 100 episode reward": 0.0, "steps": 4250}
{"reward": 0.009000000000000001, "% time spent exploring": 81, "episodes": 41, "head": 7, "mean 100 episode reward": 0.0, "steps": 4359}
{"reward": 0.004, "% time spent exploring": 81, "episodes": 42, "head": 7, "mean 100 episode reward": 0.0, "steps": 4468}
{"reward": 0.028000000000000018, "% time spent exploring": 81, "episodes": 43, "head": 5, "mean 100 episode reward": 0.0, "steps": 4577}
{"reward": 0.05600000000000004, "% time spent exploring": 80, "episodes": 44, "head": 6, "mean 100 episode reward": 0.0, "steps": 4686}
{"reward": 0.04300000000000003, "% time spent exploring": 80, "episodes": 45, "head": 3, "mean 100 episode reward": 0.0, "steps": 4795}
{"reward": 0.009000000000000001, "% time spent exploring": 79, "episodes": 46, "head": 3, "mean 100 episode reward": 0.0, "steps": 4904}
{"reward": 0.03300000000000002, "% time spent exploring": 79, "episodes": 47, "head": 6, "mean 100 episode reward": 0.0, "steps": 5013}
{"reward": 0.059000000000000045, "% time spent exploring": 78, "episodes": 48, "head": 6, "mean 100 episode reward": 0.0, "steps": 5122}
{"reward": 0.048000000000000036, "% time spent exploring": 78, "episodes": 49, "head": 3, "mean 100 episode reward": 0.0, "steps": 5231}
{"reward": 0.0, "% time spent exploring": 77, "episodes": 50, "head": 0, "mean 100 episode reward": 0.0, "steps": 5340}
{"reward": 0.005, "% time spent exploring": 77, "episodes": 51, "head": 7, "mean 100 episode reward": 0.0, "steps": 5449}
{"reward": 0.01900000000000001, "% time spent exploring": 77, "episodes": 52, "head": 8, "mean 100 episode reward": 0.0, "steps": 5558}
{"reward": 0.036000000000000025, "% time spent exploring": 76, "episodes": 53, "head": 6, "mean 100 episode reward": 0.0, "steps": 5667}
{"reward": 0.0, "% time spent exploring": 76, "episodes": 54, "head": 4, "mean 100 episode reward": 0.0, "steps": 5776}
{"reward": 0.001, "% time spent exploring": 75, "episodes": 55, "head": 3, "mean 100 episode reward": 0.0, "steps": 5885}
{"reward": 0.011000000000000003, "% time spent exploring": 75, "episodes": 56, "head": 5, "mean 100 episode reward": 0.0, "steps": 5994}
{"reward": 0.002, "% time spent exploring": 74, "episodes": 57, "head": 0, "mean 100 episode reward": 0.0, "steps": 6103}
{"reward": 0.001, "% time spent exploring": 74, "episodes": 58, "head": 5, "mean 100 episode reward": 0.0, "steps": 6212}
{"reward": 0.005, "% time spent exploring": 73, "episodes": 59, "head": 9, "mean 100 episode reward": 0.0, "steps": 6321}
{"reward": 0.02000000000000001, "% time spent exploring": 73, "episodes": 60, "head": 9, "mean 100 episode reward": 0.0, "steps": 6430}
{"reward": 0.001, "% time spent exploring": 72, "episodes": 61, "head": 4, "mean 100 episode reward": 0.0, "steps": 6539}
{"reward": 0.06200000000000005, "% time spent exploring": 72, "episodes": 62, "head": 3, "mean 100 episode reward": 0.0, "steps": 6648}
{"reward": 0.010000000000000002, "% time spent exploring": 72, "episodes": 63, "head": 2, "mean 100 episode reward": 0.0, "steps": 6757}
{"reward": 0.006, "% time spent exploring": 71, "episodes": 64, "head": 1, "mean 100 episode reward": 0.0, "steps": 6866}
{"reward": 0.008, "% time spent exploring": 71, "episodes": 65, "head": 8, "mean 100 episode reward": 0.0, "steps": 6975}
{"reward": 0.023000000000000013, "% time spent exploring": 70, "episodes": 66, "head": 5, "mean 100 episode reward": 0.0, "steps": 7084}
{"reward": 0.03400000000000002, "% time spent exploring": 70, "episodes": 67, "head": 5, "mean 100 episode reward": 0.0, "steps": 7193}
{"reward": 0.0, "% time spent exploring": 69, "episodes": 68, "head": 9, "mean 100 episode reward": 0.0, "steps": 7302}
{"reward": 0.027000000000000017, "% time spent exploring": 69, "episodes": 69, "head": 1, "mean 100 episode reward": 0.0, "steps": 7411}
{"reward": 0.014000000000000005, "% time spent exploring": 68, "episodes": 70, "head": 1, "mean 100 episode reward": 0.0, "steps": 7520}
{"reward": 0.01800000000000001, "% time spent exploring": 68, "episodes": 71, "head": 0, "mean 100 episode reward": 0.0, "steps": 7629}
{"reward": 0.04000000000000003, "% time spent exploring": 68, "episodes": 72, "head": 7, "mean 100 episode reward": 0.0, "steps": 7738}
{"reward": 0.022000000000000013, "% time spent exploring": 67, "episodes": 73, "head": 4, "mean 100 episode reward": 0.0, "steps": 7847}
{"reward": 0.04500000000000003, "% time spent exploring": 67, "episodes": 74, "head": 5, "mean 100 episode reward": 0.0, "steps": 7956}
{"reward": 0.012000000000000004, "% time spent exploring": 66, "episodes": 75, "head": 9, "mean 100 episode reward": 0.0, "steps": 8065}
{"reward": 0.010000000000000002, "% time spent exploring": 66, "episodes": 76, "head": 4, "mean 100 episode reward": 0.0, "steps": 8174}
{"reward": 0.010000000000000002, "% time spent exploring": 65, "episodes": 77, "head": 3, "mean 100 episode reward": 0.0, "steps": 8283}
{"reward": 0.006, "% time spent exploring": 65, "episodes": 78, "head": 6, "mean 100 episode reward": 0.0, "steps": 8392}
{"reward": 0.023000000000000013, "% time spent exploring": 64, "episodes": 79, "head": 1, "mean 100 episode reward": 0.0, "steps": 8501}
{"reward": 0.010000000000000002, "% time spent exploring": 64, "episodes": 80, "head": 3, "mean 100 episode reward": 0.0, "steps": 8610}
{"reward": 0.03300000000000002, "% time spent exploring": 63, "episodes": 81, "head": 9, "mean 100 episode reward": 0.0, "steps": 8719}
{"reward": 0.005, "% time spent exploring": 63, "episodes": 82, "head": 2, "mean 100 episode reward": 0.0, "steps": 8828}
{"reward": 0.04000000000000003, "% time spent exploring": 63, "episodes": 83, "head": 1, "mean 100 episode reward": 0.0, "steps": 8937}
{"reward": 0.01800000000000001, "% time spent exploring": 62, "episodes": 84, "head": 7, "mean 100 episode reward": 0.0, "steps": 9046}
{"reward": 0.0, "% time spent exploring": 62, "episodes": 85, "head": 3, "mean 100 episode reward": 0.0, "steps": 9155}
{"reward": 0.023000000000000013, "% time spent exploring": 61, "episodes": 86, "head": 4, "mean 100 episode reward": 0.0, "steps": 9264}
{"reward": 0.024000000000000014, "% time spent exploring": 61, "episodes": 87, "head": 0, "mean 100 episode reward": 0.0, "steps": 9373}
{"reward": 0.022000000000000013, "% time spent exploring": 60, "episodes": 88, "head": 4, "mean 100 episode reward": 0.0, "steps": 9482}
{"reward": 0.015000000000000006, "% time spent exploring": 60, "episodes": 89, "head": 4, "mean 100 episode reward": 0.0, "steps": 9591}
{"reward": 0.003, "% time spent exploring": 59, "episodes": 90, "head": 6, "mean 100 episode reward": 0.0, "steps": 9700}
{"reward": 0.05100000000000004, "% time spent exploring": 59, "episodes": 91, "head": 8, "mean 100 episode reward": 0.0, "steps": 9809}
{"reward": 0.0, "% time spent exploring": 59, "episodes": 92, "head": 3, "mean 100 episode reward": 0.0, "steps": 9918}
{"reward": 0.0, "% time spent exploring": 58, "episodes": 93, "head": 3, "mean 100 episode reward": 0.0, "steps": 10027}
{"reward": 0.03300000000000002, "% time spent exploring": 58, "episodes": 94, "head": 9, "mean 100 episode reward": 0.0, "steps": 10136}
{"reward": 0.01900000000000001, "% time spent exploring": 57, "episodes": 95, "head": 0, "mean 100 episode reward": 0.0, "steps": 10245}
{"reward": 0.017000000000000008, "% time spent exploring": 57, "episodes": 96, "head": 4, "mean 100 episode reward": 0.0, "steps": 10354}
{"reward": 0.008, "% time spent exploring": 56, "episodes": 97, "head": 9, "mean 100 episode reward": 0.0, "steps": 10463}
{"reward": 0.022000000000000013, "% time spent exploring": 56, "episodes": 98, "head": 9, "mean 100 episode reward": 0.0, "steps": 10572}
{"reward": 0.02000000000000001, "% time spent exploring": 55, "episodes": 99, "head": 2, "mean 100 episode reward": 0.0, "steps": 10681}
{"reward": 0.014000000000000005, "% time spent exploring": 55, "episodes": 100, "head": 0, "mean 100 episode reward": 0.0, "steps": 10790}
{"reward": 0.037000000000000026, "% time spent exploring": 54, "episodes": 101, "head": 2, "mean 100 episode reward": 0.0, "steps": 10899}
{"reward": 0.014000000000000005, "% time spent exploring": 54, "episodes": 102, "head": 2, "mean 100 episode reward": 0.0, "steps": 11008}
{"reward": 0.037000000000000026, "% time spent exploring": 54, "episodes": 103, "head": 9, "mean 100 episode reward": 0.0, "steps": 11117}
{"reward": 0.0, "% time spent exploring": 53, "episodes": 104, "head": 7, "mean 100 episode reward": 0.0, "steps": 11226}
{"reward": 0.004, "% time spent exploring": 53, "episodes": 105, "head": 8, "mean 100 episode reward": 0.0, "steps": 11335}
{"reward": 0.0, "% time spent exploring": 52, "episodes": 106, "head": 6, "mean 100 episode reward": 0.0, "steps": 11444}
{"reward": 0.05400000000000004, "% time spent exploring": 52, "episodes": 107, "head": 1, "mean 100 episode reward": 0.0, "steps": 11553}
{"reward": 0.04100000000000003, "% time spent exploring": 51, "episodes": 108, "head": 7, "mean 100 episode reward": 0.0, "steps": 11662}
{"reward": 0.024000000000000014, "% time spent exploring": 51, "episodes": 109, "head": 9, "mean 100 episode reward": 0.0, "steps": 11771}
{"reward": 0.04400000000000003, "% time spent exploring": 50, "episodes": 110, "head": 8, "mean 100 episode reward": 0.0, "steps": 11880}
{"reward": 0.06600000000000004, "% time spent exploring": 50, "episodes": 111, "head": 8, "mean 100 episode reward": 0.0, "steps": 11989}
{"reward": 0.05000000000000004, "% time spent exploring": 50, "episodes": 112, "head": 9, "mean 100 episode reward": 0.0, "steps": 12098}
{"reward": 0.07300000000000005, "% time spent exploring": 49, "episodes": 113, "head": 0, "mean 100 episode reward": 0.0, "steps": 12207}
{"reward": 0.002, "% time spent exploring": 49, "episodes": 114, "head": 3, "mean 100 episode reward": 0.0, "steps": 12316}
{"reward": 0.017000000000000008, "% time spent exploring": 48, "episodes": 115, "head": 4, "mean 100 episode reward": 0.0, "steps": 12425}
{"reward": 0.07300000000000005, "% time spent exploring": 48, "episodes": 116, "head": 7, "mean 100 episode reward": 0.0, "steps": 12534}
{"reward": 0.03800000000000003, "% time spent exploring": 47, "episodes": 117, "head": 8, "mean 100 episode reward": 0.0, "steps": 12643}
{"reward": 0.057000000000000044, "% time spent exploring": 47, "episodes": 118, "head": 1, "mean 100 episode reward": 0.0, "steps": 12752}
{"reward": 0.0, "% time spent exploring": 46, "episodes": 119, "head": 6, "mean 100 episode reward": 0.0, "steps": 12861}
{"reward": 0.008, "% time spent exploring": 46, "episodes": 120, "head": 8, "mean 100 episode reward": 0.0, "steps": 12970}
{"reward": 0.07000000000000005, "% time spent exploring": 45, "episodes": 121, "head": 4, "mean 100 episode reward": 0.0, "steps": 13079}
{"reward": 0.05400000000000004, "% time spent exploring": 45, "episodes": 122, "head": 1, "mean 100 episode reward": 0.0, "steps": 13188}
{"reward": 0.06100000000000005, "% time spent exploring": 45, "episodes": 123, "head": 0, "mean 100 episode reward": 0.0, "steps": 13297}
{"reward": 0.048000000000000036, "% time spent exploring": 44, "episodes": 124, "head": 0, "mean 100 episode reward": 0.0, "steps": 13406}
{"reward": 0.08600000000000006, "% time spent exploring": 44, "episodes": 125, "head": 7, "mean 100 episode reward": 0.0, "steps": 13515}
{"reward": 0.07400000000000005, "% time spent exploring": 43, "episodes": 126, "head": 7, "mean 100 episode reward": 0.0, "steps": 13624}
{"reward": 0.07100000000000005, "% time spent exploring": 43, "episodes": 127, "head": 9, "mean 100 episode reward": 0.0, "steps": 13733}
{"reward": 0.0, "% time spent exploring": 42, "episodes": 128, "head": 6, "mean 100 episode reward": 0.0, "steps": 13842}
{"reward": 0.06900000000000005, "% time spent exploring": 42, "episodes": 129, "head": 1, "mean 100 episode reward": 0.0, "steps": 13951}
{"reward": 0.06100000000000005, "% time spent exploring": 41, "episodes": 130, "head": 2, "mean 100 episode reward": 0.0, "steps": 14060}
{"reward": 0.048000000000000036, "% time spent exploring": 41, "episodes": 131, "head": 8, "mean 100 episode reward": 0.0, "steps": 14169}
{"reward": 0.001, "% time spent exploring": 41, "episodes": 132, "head": 6, "mean 100 episode reward": 0.0, "steps": 14278}
{"reward": 0.002, "% time spent exploring": 40, "episodes": 133, "head": 6, "mean 100 episode reward": 0.0, "steps": 14387}
{"reward": 0.0, "% time spent exploring": 40, "episodes": 134, "head": 5, "mean 100 episode reward": 0.0, "steps": 14496}
{"reward": 0.03000000000000002, "% time spent exploring": 39, "episodes": 135, "head": 2, "mean 100 episode reward": 0.0, "steps": 14605}
{"reward": 0.07300000000000005, "% time spent exploring": 39, "episodes": 136, "head": 1, "mean 100 episode reward": 0.0, "steps": 14714}
{"reward": 0.003, "% time spent exploring": 38, "episodes": 137, "head": 5, "mean 100 episode reward": 0.0, "steps": 14823}
{"reward": 0.0, "% time spent exploring": 38, "episodes": 138, "head": 6, "mean 100 episode reward": 0.0, "steps": 14932}
{"reward": 0.0, "% time spent exploring": 37, "episodes": 139, "head": 8, "mean 100 episode reward": 0.0, "steps": 15041}
{"reward": 0.06400000000000004, "% time spent exploring": 37, "episodes": 140, "head": 4, "mean 100 episode reward": 0.0, "steps": 15150}
{"reward": 0.0, "% time spent exploring": 36, "episodes": 141, "head": 5, "mean 100 episode reward": 0.0, "steps": 15259}
{"reward": 0.0, "% time spent exploring": 36, "episodes": 142, "head": 6, "mean 100 episode reward": 0.0, "steps": 15368}
{"reward": 0.0, "% time spent exploring": 36, "episodes": 143, "head": 6, "mean 100 episode reward": 0.0, "steps": 15477}
{"reward": 0.02000000000000001, "% time spent exploring": 35, "episodes": 144, "head": 8, "mean 100 episode reward": 0.0, "steps": 15586}
{"reward": 0.06500000000000004, "% time spent exploring": 35, "episodes": 145, "head": 1, "mean 100 episode reward": 0.0, "steps": 15695}
{"reward": 0.005, "% time spent exploring": 34, "episodes": 146, "head": 3, "mean 100 episode reward": 0.0, "steps": 15804}
{"reward": 0.06500000000000004, "% time spent exploring": 34, "episodes": 147, "head": 0, "mean 100 episode reward": 0.0, "steps": 15913}
{"reward": 0.09400000000000007, "% time spent exploring": 33, "episodes": 148, "head": 8, "mean 100 episode reward": 0.0, "steps": 16022}
{"reward": 0.02100000000000001, "% time spent exploring": 33, "episodes": 149, "head": 2, "mean 100 episode reward": 0.0, "steps": 16131}
{"reward": 0.05000000000000004, "% time spent exploring": 32, "episodes": 150, "head": 3, "mean 100 episode reward": 0.0, "steps": 16240}
{"reward": 0.025000000000000015, "% time spent exploring": 32, "episodes": 151, "head": 3, "mean 100 episode reward": 0.0, "steps": 16349}
{"reward": 0.05000000000000004, "% time spent exploring": 32, "episodes": 152, "head": 9, "mean 100 episode reward": 0.0, "steps": 16458}
{"reward": 0.04500000000000003, "% time spent exploring": 31, "episodes": 153, "head": 0, "mean 100 episode reward": 0.0, "steps": 16567}
{"reward": 0.04200000000000003, "% time spent exploring": 31, "episodes": 154, "head": 1, "mean 100 episode reward": 0.0, "steps": 16676}
{"reward": 0.09500000000000007, "% time spent exploring": 30, "episodes": 155, "head": 8, "mean 100 episode reward": 0.0, "steps": 16785}
{"reward": 0.03800000000000003, "% time spent exploring": 30, "episodes": 156, "head": 0, "mean 100 episode reward": 0.0, "steps": 16894}
{"reward": 0.0, "% time spent exploring": 29, "episodes": 157, "head": 5, "mean 100 episode reward": 0.0, "steps": 17003}
{"reward": 0.01900000000000001, "% time spent exploring": 29, "episodes": 158, "head": 0, "mean 100 episode reward": 0.0, "steps": 17112}
{"reward": 0.0, "% time spent exploring": 28, "episodes": 159, "head": 5, "mean 100 episode reward": 0.0, "steps": 17221}
{"reward": 0.026000000000000016, "% time spent exploring": 28, "episodes": 160, "head": 4, "mean 100 episode reward": 0.0, "steps": 17330}
{"reward": 0.08800000000000006, "% time spent exploring": 27, "episodes": 161, "head": 8, "mean 100 episode reward": 0.0, "steps": 17439}
{"reward": 0.04500000000000003, "% time spent exploring": 27, "episodes": 162, "head": 0, "mean 100 episode reward": 0.0, "steps": 17548}
{"reward": 0.001, "% time spent exploring": 27, "episodes": 163, "head": 6, "mean 100 episode reward": 0.0, "steps": 17657}
{"reward": 0.06200000000000005, "% time spent exploring": 26, "episodes": 164, "head": 1, "mean 100 episode reward": 0.0, "steps": 17766}
{"reward": 0.04200000000000003, "% time spent exploring": 26, "episodes": 165, "head": 9, "mean 100 episode reward": 0.0, "steps": 17875}
{"reward": 0.03400000000000002, "% time spent exploring": 25, "episodes": 166, "head": 4, "mean 100 episode reward": 0.0, "steps": 17984}
{"reward": 0.04500000000000003, "% time spent exploring": 25, "episodes": 167, "head": 1, "mean 100 episode reward": 0.0, "steps": 18093}
{"reward": 0.036000000000000025, "% time spent exploring": 24, "episodes": 168, "head": 7, "mean 100 episode reward": 0.0, "steps": 18202}
{"reward": 0.02900000000000002, "% time spent exploring": 24, "episodes": 169, "head": 1, "mean 100 episode reward": 0.0, "steps": 18311}
{"reward": 0.10200000000000008, "% time spent exploring": 23, "episodes": 170, "head": 8, "mean 100 episode reward": 0.0, "steps": 18420}
{"reward": 0.07600000000000005, "% time spent exploring": 23, "episodes": 171, "head": 9, "mean 100 episode reward": 0.0, "steps": 18529}
{"reward": 0.07900000000000006, "% time spent exploring": 23, "episodes": 172, "head": 8, "mean 100 episode reward": 0.0, "steps": 18638}
{"reward": 0.07000000000000005, "% time spent exploring": 22, "episodes": 173, "head": 8, "mean 100 episode reward": 0.0, "steps": 18747}
{"reward": 0.06500000000000004, "% time spent exploring": 22, "episodes": 174, "head": 1, "mean 100 episode reward": 0.0, "steps": 18856}
{"reward": 0.04200000000000003, "% time spent exploring": 21, "episodes": 175, "head": 6, "mean 100 episode reward": 0.0, "steps": 18965}
{"reward": 0.07400000000000005, "% time spent exploring": 21, "episodes": 176, "head": 8, "mean 100 episode reward": 0.0, "steps": 19074}
{"reward": 0.04400000000000003, "% time spent exploring": 20, "episodes": 177, "head": 6, "mean 100 episode reward": 0.0, "steps": 19183}
{"reward": 0.03400000000000002, "% time spent exploring": 20, "episodes": 178, "head": 6, "mean 100 episode reward": 0.0, "steps": 19292}
{"reward": 0.08000000000000006, "% time spent exploring": 19, "episodes": 179, "head": 8, "mean 100 episode reward": 0.0, "steps": 19401}
{"reward": 0.04100000000000003, "% time spent exploring": 19, "episodes": 180, "head": 6, "mean 100 episode reward": 0.0, "steps": 19510}
{"reward": 0.02900000000000002, "% time spent exploring": 18, "episodes": 181, "head": 8, "mean 100 episode reward": 0.0, "steps": 19619}
{"reward": 0.046000000000000034, "% time spent exploring": 18, "episodes": 182, "head": 0, "mean 100 episode reward": 0.0, "steps": 19728}
{"reward": 0.036000000000000025, "% time spent exploring": 18, "episodes": 183, "head": 2, "mean 100 episode reward": 0.0, "steps": 19837}
{"reward": 0.046000000000000034, "% time spent exploring": 17, "episodes": 184, "head": 8, "mean 100 episode reward": 0.0, "steps": 19946}
{"reward": 0.04300000000000003, "% time spent exploring": 17, "episodes": 185, "head": 7, "mean 100 episode reward": 0.0, "steps": 20055}
{"reward": 0.0, "% time spent exploring": 16, "episodes": 186, "head": 5, "mean 100 episode reward": 0.0, "steps": 20164}
{"reward": 0.09600000000000007, "% time spent exploring": 16, "episodes": 187, "head": 4, "mean 100 episode reward": 0.0, "steps": 20273}
{"reward": 0.0, "% time spent exploring": 15, "episodes": 188, "head": 5, "mean 100 episode reward": 0.0, "steps": 20382}
{"reward": 0.06200000000000005, "% time spent exploring": 15, "episodes": 189, "head": 2, "mean 100 episode reward": 0.0, "steps": 20491}
{"reward": 0.059000000000000045, "% time spent exploring": 14, "episodes": 190, "head": 1, "mean 100 episode reward": 0.0, "steps": 20600}
{"reward": 0.06300000000000004, "% time spent exploring": 14, "episodes": 191, "head": 1, "mean 100 episode reward": 0.0, "steps": 20709}
{"reward": 0.09600000000000007, "% time spent exploring": 14, "episodes": 192, "head": 2, "mean 100 episode reward": 0.0, "steps": 20818}
{"reward": 0.01900000000000001, "% time spent exploring": 13, "episodes": 193, "head": 9, "mean 100 episode reward": 0.0, "steps": 20927}
{"reward": 0.022000000000000013, "% time spent exploring": 13, "episodes": 194, "head": 6, "mean 100 episode reward": 0.0, "steps": 21036}
{"reward": 0.004, "% time spent exploring": 12, "episodes": 195, "head": 5, "mean 100 episode reward": 0.0, "steps": 21145}
{"reward": 0.07700000000000005, "% time spent exploring": 12, "episodes": 196, "head": 4, "mean 100 episode reward": 0.0, "steps": 21254}
{"reward": 0.05400000000000004, "% time spent exploring": 11, "episodes": 197, "head": 6, "mean 100 episode reward": 0.0, "steps": 21363}
{"reward": 0.06300000000000004, "% time spent exploring": 11, "episodes": 198, "head": 4, "mean 100 episode reward": 0.0, "steps": 21472}
{"reward": 0.07100000000000005, "% time spent exploring": 10, "episodes": 199, "head": 8, "mean 100 episode reward": 0.0, "steps": 21581}
{"reward": 0.037000000000000026, "% time spent exploring": 10, "episodes": 200, "head": 0, "mean 100 episode reward": 0.0, "steps": 21690}
{"reward": 0.014000000000000005, "% time spent exploring": 9, "episodes": 201, "head": 4, "mean 100 episode reward": 0.0, "steps": 21799}
{"reward": 0.06600000000000004, "% time spent exploring": 9, "episodes": 202, "head": 7, "mean 100 episode reward": 0.0, "steps": 21908}
{"reward": 0.048000000000000036, "% time spent exploring": 9, "episodes": 203, "head": 7, "mean 100 episode reward": 0.0, "steps": 22017}
{"reward": 0.05000000000000004, "% time spent exploring": 9, "episodes": 204, "head": 0, "mean 100 episode reward": 0.0, "steps": 22126}
{"reward": 0.04000000000000003, "% time spent exploring": 9, "episodes": 205, "head": 1, "mean 100 episode reward": 0.0, "steps": 22235}
{"reward": 0.0, "% time spent exploring": 9, "episodes": 206, "head": 2, "mean 100 episode reward": 0.0, "steps": 22344}
{"reward": 0.012000000000000004, "% time spent exploring": 9, "episodes": 207, "head": 4, "mean 100 episode reward": 0.0, "steps": 22453}
{"reward": 0.10600000000000008, "% time spent exploring": 9, "episodes": 208, "head": 1, "mean 100 episode reward": 0.0, "steps": 22562}
{"reward": 0.09400000000000007, "% time spent exploring": 9, "episodes": 209, "head": 6, "mean 100 episode reward": 0.0, "steps": 22671}
{"reward": 0.036000000000000025, "% time spent exploring": 9, "episodes": 210, "head": 1, "mean 100 episode reward": 0.0, "steps": 22780}
{"reward": 0.0, "% time spent exploring": 9, "episodes": 211, "head": 5, "mean 100 episode reward": 0.0, "steps": 22889}
{"reward": 0.09600000000000007, "% time spent exploring": 9, "episodes": 212, "head": 2, "mean 100 episode reward": 0.0, "steps": 22998}
{"reward": 0.06400000000000004, "% time spent exploring": 9, "episodes": 213, "head": 9, "mean 100 episode reward": 0.0, "steps": 23107}
{"reward": 0.06400000000000004, "% time spent exploring": 9, "episodes": 214, "head": 7, "mean 100 episode reward": 0.0, "steps": 23216}
{"reward": 0.035000000000000024, "% time spent exploring": 9, "episodes": 215, "head": 1, "mean 100 episode reward": 0.0, "steps": 23325}
{"reward": 0.07400000000000005, "% time spent exploring": 9, "episodes": 216, "head": 7, "mean 100 episode reward": 0.0, "steps": 23434}
{"reward": 0.08400000000000006, "% time spent exploring": 9, "episodes": 217, "head": 0, "mean 100 episode reward": 0.0, "steps": 23543}
{"reward": 0.06200000000000005, "% time spent exploring": 9, "episodes": 218, "head": 2, "mean 100 episode reward": 0.0, "steps": 23652}
{"reward": 0.06400000000000004, "% time spent exploring": 9, "episodes": 219, "head": 6, "mean 100 episode reward": 0.0, "steps": 23761}
{"reward": 0.05200000000000004, "% time spent exploring": 9, "episodes": 220, "head": 9, "mean 100 episode reward": 0.0, "steps": 23870}
{"reward": 0.016000000000000007, "% time spent exploring": 9, "episodes": 221, "head": 4, "mean 100 episode reward": 0.0, "steps": 23979}
{"reward": 0.05100000000000004, "% time spent exploring": 9, "episodes": 222, "head": 5, "mean 100 episode reward": 0.0, "steps": 24088}
{"reward": 0.009000000000000001, "% time spent exploring": 9, "episodes": 223, "head": 0, "mean 100 episode reward": 0.0, "steps": 24197}
{"reward": 0.06600000000000004, "% time spent exploring": 9, "episodes": 224, "head": 6, "mean 100 episode reward": 0.0, "steps": 24306}
{"reward": 0.026000000000000016, "% time spent exploring": 9, "episodes": 225, "head": 4, "mean 100 episode reward": 0.0, "steps": 24415}
{"reward": 0.10500000000000008, "% time spent exploring": 9, "episodes": 226, "head": 8, "mean 100 episode reward": 0.0, "steps": 24524}
{"reward": 0.02100000000000001, "% time spent exploring": 9, "episodes": 227, "head": 4, "mean 100 episode reward": 0.0, "steps": 24633}
{"reward": 0.03300000000000002, "% time spent exploring": 9, "episodes": 228, "head": 6, "mean 100 episode reward": 0.0, "steps": 24742}
{"reward": 0.06400000000000004, "% time spent exploring": 9, "episodes": 229, "head": 7, "mean 100 episode reward": 0.0, "steps": 24851}
{"reward": 0.06900000000000005, "% time spent exploring": 9, "episodes": 230, "head": 6, "mean 100 episode reward": 0.0, "steps": 24960}
{"reward": 0.06500000000000004, "% time spent exploring": 9, "episodes": 231, "head": 9, "mean 100 episode reward": 0.0, "steps": 25069}
{"reward": 0.08200000000000006, "% time spent exploring": 9, "episodes": 232, "head": 0, "mean 100 episode reward": 0.0, "steps": 25178}
{"reward": 0.07500000000000005, "% time spent exploring": 9, "episodes": 233, "head": 9, "mean 100 episode reward": 0.0, "steps": 25287}
{"reward": 0.06400000000000004, "% time spent exploring": 9, "episodes": 234, "head": 6, "mean 100 episode reward": 0.0, "steps": 25396}
{"reward": 0.07900000000000006, "% time spent exploring": 9, "episodes": 235, "head": 4, "mean 100 episode reward": 0.0, "steps": 25505}
{"reward": 0.04000000000000003, "% time spent exploring": 9, "episodes": 236, "head": 7, "mean 100 episode reward": 0.0, "steps": 25614}
{"reward": 0.10000000000000007, "% time spent exploring": 9, "episodes": 237, "head": 8, "mean 100 episode reward": 0.0, "steps": 25723}
{"reward": 0.010000000000000002, "% time spent exploring": 9, "episodes": 238, "head": 4, "mean 100 episode reward": 0.0, "steps": 25832}
{"reward": 0.01800000000000001, "% time spent exploring": 9, "episodes": 239, "head": 6, "mean 100 episode reward": 0.0, "steps": 25941}
{"reward": 0.06900000000000005, "% time spent exploring": 9, "episodes": 240, "head": 7, "mean 100 episode reward": 0.0, "steps": 26050}
{"reward": 0.10100000000000008, "% time spent exploring": 9, "episodes": 241, "head": 7, "mean 100 episode reward": 0.0, "steps": 26159}
{"reward": 0.09200000000000007, "% time spent exploring": 9, "episodes": 242, "head": 5, "mean 100 episode reward": 0.0, "steps": 26268}
{"reward": 0.07600000000000005, "% time spent exploring": 9, "episodes": 243, "head": 6, "mean 100 episode reward": 0.1, "steps": 26377}
{"reward": 0.10200000000000008, "% time spent exploring": 9, "episodes": 244, "head": 1, "mean 100 episode reward": 0.1, "steps": 26486}
{"reward": 0.08000000000000006, "% time spent exploring": 9, "episodes": 245, "head": 4, "mean 100 episode reward": 0.1, "steps": 26595}
{"reward": 0.060000000000000046, "% time spent exploring": 9, "episodes": 246, "head": 9, "mean 100 episode reward": 0.1, "steps": 26704}
{"reward": 0.07700000000000005, "% time spent exploring": 9, "episodes": 247, "head": 4, "mean 100 episode reward": 0.1, "steps": 26813}
{"reward": 0.08400000000000006, "% time spent exploring": 9, "episodes": 248, "head": 9, "mean 100 episode reward": 0.1, "steps": 26922}
{"reward": 0.10600000000000008, "% time spent exploring": 9, "episodes": 249, "head": 5, "mean 100 episode reward": 0.1, "steps": 27031}
{"reward": 0.10000000000000007, "% time spent exploring": 9, "episodes": 250, "head": 7, "mean 100 episode reward": 0.1, "steps": 27140}
{"reward": 0.10200000000000008, "% time spent exploring": 9, "episodes": 251, "head": 5, "mean 100 episode reward": 0.1, "steps": 27249}
{"reward": 0.07100000000000005, "% time spent exploring": 9, "episodes": 252, "head": 4, "mean 100 episode reward": 0.1, "steps": 27358}
{"reward": 0.06600000000000004, "% time spent exploring": 9, "episodes": 253, "head": 0, "mean 100 episode reward": 0.1, "steps": 27467}
{"reward": 0.08000000000000006, "% time spent exploring": 9, "episodes": 254, "head": 7, "mean 100 episode reward": 0.1, "steps": 27576}
{"reward": 0.10200000000000008, "% time spent exploring": 9, "episodes": 255, "head": 3, "mean 100 episode reward": 0.1, "steps": 27685}
{"reward": 0.10100000000000008, "% time spent exploring": 9, "episodes": 256, "head": 8, "mean 100 episode reward": 0.1, "steps": 27794}
{"reward": 0.06700000000000005, "% time spent exploring": 9, "episodes": 257, "head": 7, "mean 100 episode reward": 0.1, "steps": 27903}
{"reward": 0.08700000000000006, "% time spent exploring": 9, "episodes": 258, "head": 0, "mean 100 episode reward": 0.1, "steps": 28012}
{"reward": 0.03900000000000003, "% time spent exploring": 9, "episodes": 259, "head": 3, "mean 100 episode reward": 0.1, "steps": 28121}
{"reward": 0.05100000000000004, "% time spent exploring": 9, "episodes": 260, "head": 3, "mean 100 episode reward": 0.1, "steps": 28230}
{"reward": 0.08000000000000006, "% time spent exploring": 9, "episodes": 261, "head": 4, "mean 100 episode reward": 0.1, "steps": 28339}
{"reward": 0.057000000000000044, "% time spent exploring": 9, "episodes": 262, "head": 1, "mean 100 episode reward": 0.1, "steps": 28448}
{"reward": 0.07300000000000005, "% time spent exploring": 9, "episodes": 263, "head": 9, "mean 100 episode reward": 0.1, "steps": 28557}
{"reward": 0.08700000000000006, "% time spent exploring": 9, "episodes": 264, "head": 3, "mean 100 episode reward": 0.1, "steps": 28666}
{"reward": 0.08200000000000006, "% time spent exploring": 9, "episodes": 265, "head": 2, "mean 100 episode reward": 0.1, "steps": 28775}
{"reward": 0.09200000000000007, "% time spent exploring": 9, "episodes": 266, "head": 0, "mean 100 episode reward": 0.1, "steps": 28884}
{"reward": 0.08200000000000006, "% time spent exploring": 9, "episodes": 267, "head": 8, "mean 100 episode reward": 0.1, "steps": 28993}
{"reward": 0.08200000000000006, "% time spent exploring": 9, "episodes": 268, "head": 5, "mean 100 episode reward": 0.1, "steps": 29102}
{"reward": 0.09500000000000007, "% time spent exploring": 9, "episodes": 269, "head": 3, "mean 100 episode reward": 0.1, "steps": 29211}
{"reward": 0.06900000000000005, "% time spent exploring": 9, "episodes": 270, "head": 9, "mean 100 episode reward": 0.1, "steps": 29320}
{"reward": 0.07200000000000005, "% time spent exploring": 9, "episodes": 271, "head": 9, "mean 100 episode reward": 0.1, "steps": 29429}
{"reward": 0.057000000000000044, "% time spent exploring": 9, "episodes": 272, "head": 4, "mean 100 episode reward": 0.1, "steps": 29538}
{"reward": 0.06800000000000005, "% time spent exploring": 9, "episodes": 273, "head": 6, "mean 100 episode reward": 0.1, "steps": 29647}
{"reward": 0.09200000000000007, "% time spent exploring": 9, "episodes": 274, "head": 3, "mean 100 episode reward": 0.1, "steps": 29756}
{"reward": 0.09600000000000007, "% time spent exploring": 9, "episodes": 275, "head": 8, "mean 100 episode reward": 0.1, "steps": 29865}
{"reward": 0.048000000000000036, "% time spent exploring": 9, "episodes": 276, "head": 4, "mean 100 episode reward": 0.1, "steps": 29974}
{"reward": 0.05500000000000004, "% time spent exploring": 9, "episodes": 277, "head": 3, "mean 100 episode reward": 0.1, "steps": 30083}
{"reward": 0.05200000000000004, "% time spent exploring": 9, "episodes": 278, "head": 8, "mean 100 episode reward": 0.1, "steps": 30192}
{"reward": 0.035000000000000024, "% time spent exploring": 9, "episodes": 279, "head": 7, "mean 100 episode reward": 0.1, "steps": 30301}
{"reward": 0.06300000000000004, "% time spent exploring": 9, "episodes": 280, "head": 6, "mean 100 episode reward": 0.1, "steps": 30410}
{"reward": 0.05300000000000004, "% time spent exploring": 9, "episodes": 281, "head": 2, "mean 100 episode reward": 0.1, "steps": 30519}
{"reward": 0.025000000000000015, "% time spent exploring": 9, "episodes": 282, "head": 7, "mean 100 episode reward": 0.1, "steps": 30628}
{"reward": 0.09200000000000007, "% time spent exploring": 9, "episodes": 283, "head": 5, "mean 100 episode reward": 0.1, "steps": 30737}
{"reward": 0.003, "% time spent exploring": 9, "episodes": 284, "head": 6, "mean 100 episode reward": 0.1, "steps": 30846}
{"reward": 0.09300000000000007, "% time spent exploring": 9, "episodes": 285, "head": 5, "mean 100 episode reward": 0.1, "steps": 30955}
{"reward": 0.06500000000000004, "% time spent exploring": 9, "episodes": 286, "head": 2, "mean 100 episode reward": 0.1, "steps": 31064}
{"reward": 0.07200000000000005, "% time spent exploring": 9, "episodes": 287, "head": 1, "mean 100 episode reward": 0.1, "steps": 31173}
{"reward": 0.07700000000000005, "% time spent exploring": 9, "episodes": 288, "head": 3, "mean 100 episode reward": 0.1, "steps": 31282}
{"reward": 0.036000000000000025, "% time spent exploring": 9, "episodes": 289, "head": 4, "mean 100 episode reward": 0.1, "steps": 31391}
{"reward": 0.06800000000000005, "% time spent exploring": 9, "episodes": 290, "head": 9, "mean 100 episode reward": 0.1, "steps": 31500}
{"reward": 0.047000000000000035, "% time spent exploring": 9, "episodes": 291, "head": 4, "mean 100 episode reward": 0.1, "steps": 31609}
{"reward": 0.06700000000000005, "% time spent exploring": 9, "episodes": 292, "head": 0, "mean 100 episode reward": 0.1, "steps": 31718}
{"reward": 0.03100000000000002, "% time spent exploring": 9, "episodes": 293, "head": 4, "mean 100 episode reward": 0.1, "steps": 31827}
{"reward": 0.05500000000000004, "% time spent exploring": 9, "episodes": 294, "head": 9, "mean 100 episode reward": 0.1, "steps": 31936}
{"reward": 0.04500000000000003, "% time spent exploring": 9, "episodes": 295, "head": 7, "mean 100 episode reward": 0.1, "steps": 32045}
{"reward": 0.04200000000000003, "% time spent exploring": 9, "episodes": 296, "head": 9, "mean 100 episode reward": 0.1, "steps": 32154}
{"reward": 0.04400000000000003, "% time spent exploring": 9, "episodes": 297, "head": 0, "mean 100 episode reward": 0.1, "steps": 32263}
{"reward": 0.07700000000000005, "% time spent exploring": 9, "episodes": 298, "head": 1, "mean 100 episode reward": 0.1, "steps": 32372}
{"reward": 0.07800000000000006, "% time spent exploring": 9, "episodes": 299, "head": 6, "mean 100 episode reward": 0.1, "steps": 32481}
{"reward": 0.09500000000000007, "% time spent exploring": 9, "episodes": 300, "head": 8, "mean 100 episode reward": 0.1, "steps": 32590}
{"reward": 0.037000000000000026, "% time spent exploring": 9, "episodes": 301, "head": 9, "mean 100 episode reward": 0.1, "steps": 32699}
{"reward": 0.059000000000000045, "% time spent exploring": 9, "episodes": 302, "head": 9, "mean 100 episode reward": 0.1, "steps": 32808}
{"reward": 0.10600000000000008, "% time spent exploring": 9, "episodes": 303, "head": 8, "mean 100 episode reward": 0.1, "steps": 32917}
{"reward": 0.05000000000000004, "% time spent exploring": 9, "episodes": 304, "head": 0, "mean 100 episode reward": 0.1, "steps": 33026}
{"reward": 0.05400000000000004, "% time spent exploring": 9, "episodes": 305, "head": 6, "mean 100 episode reward": 0.1, "steps": 33135}
{"reward": 0.03400000000000002, "% time spent exploring": 9, "episodes": 306, "head": 4, "mean 100 episode reward": 0.1, "steps": 33244}
{"reward": 0.09000000000000007, "% time spent exploring": 9, "episodes": 307, "head": 8, "mean 100 episode reward": 0.1, "steps": 33353}
{"reward": 0.036000000000000025, "% time spent exploring": 9, "episodes": 308, "head": 3, "mean 100 episode reward": 0.1, "steps": 33462}
{"reward": 0.003, "% time spent exploring": 9, "episodes": 309, "head": 4, "mean 100 episode reward": 0.1, "steps": 33571}
{"reward": 0.03900000000000003, "% time spent exploring": 9, "episodes": 310, "head": 9, "mean 100 episode reward": 0.1, "steps": 33680}
{"reward": 0.06300000000000004, "% time spent exploring": 9, "episodes": 311, "head": 6, "mean 100 episode reward": 0.1, "steps": 33789}
{"reward": 0.10000000000000007, "% time spent exploring": 9, "episodes": 312, "head": 3, "mean 100 episode reward": 0.1, "steps": 33898}
