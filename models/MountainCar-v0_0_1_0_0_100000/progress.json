{"steps": 199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 2, "% time spent exploring": 98}
{"steps": 399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 3, "% time spent exploring": 96}
{"steps": 599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 4, "% time spent exploring": 94}
{"steps": 799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 5, "% time spent exploring": 92}
{"steps": 999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 6, "% time spent exploring": 91}
{"steps": 1199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 7, "% time spent exploring": 89}
{"steps": 1399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 8, "% time spent exploring": 87}
{"steps": 1599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 9, "% time spent exploring": 85}
{"steps": 1799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 10, "% time spent exploring": 83}
{"steps": 1999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 11, "% time spent exploring": 82}
{"steps": 2199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 12, "% time spent exploring": 80}
{"steps": 2399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 13, "% time spent exploring": 78}
{"steps": 2599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 14, "% time spent exploring": 76}
{"steps": 2799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 15, "% time spent exploring": 74}
{"steps": 2999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 16, "% time spent exploring": 73}
{"steps": 3199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 17, "% time spent exploring": 71}
{"steps": 3399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 18, "% time spent exploring": 69}
{"steps": 3599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 19, "% time spent exploring": 67}
{"steps": 3799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 20, "% time spent exploring": 65}
{"steps": 3999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 21, "% time spent exploring": 64}
{"steps": 4199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 22, "% time spent exploring": 62}
{"steps": 4399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 23, "% time spent exploring": 60}
{"steps": 4599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 24, "% time spent exploring": 58}
{"steps": 4799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 25, "% time spent exploring": 56}
{"steps": 4999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 26, "% time spent exploring": 55}
{"steps": 5199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 27, "% time spent exploring": 53}
{"steps": 5399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 28, "% time spent exploring": 51}
{"steps": 5599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 29, "% time spent exploring": 49}
{"steps": 5799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 30, "% time spent exploring": 47}
{"steps": 5999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 31, "% time spent exploring": 46}
{"steps": 6199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 32, "% time spent exploring": 44}
{"steps": 6399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 33, "% time spent exploring": 42}
{"steps": 6599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 34, "% time spent exploring": 40}
{"steps": 6799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 35, "% time spent exploring": 38}
{"steps": 6999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 36, "% time spent exploring": 37}
{"steps": 7199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 37, "% time spent exploring": 35}
{"steps": 7399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 38, "% time spent exploring": 33}
{"steps": 7599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 39, "% time spent exploring": 31}
{"steps": 7799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 40, "% time spent exploring": 29}
{"steps": 7999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 41, "% time spent exploring": 28}
{"steps": 8199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 42, "% time spent exploring": 26}
{"steps": 8399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 43, "% time spent exploring": 24}
{"steps": 8599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 44, "% time spent exploring": 22}
{"steps": 8799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 45, "% time spent exploring": 20}
{"steps": 8999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 46, "% time spent exploring": 19}
{"steps": 9199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 47, "% time spent exploring": 17}
{"steps": 9399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 48, "% time spent exploring": 15}
{"steps": 9599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 49, "% time spent exploring": 13}
{"steps": 9799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 50, "% time spent exploring": 11}
{"steps": 9999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 51, "% time spent exploring": 10}
{"steps": 10199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 52, "% time spent exploring": 9}
{"steps": 10399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 53, "% time spent exploring": 9}
{"steps": 10599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 54, "% time spent exploring": 9}
{"steps": 10799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 55, "% time spent exploring": 9}
{"steps": 10999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 56, "% time spent exploring": 9}
{"steps": 11199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 57, "% time spent exploring": 9}
{"steps": 11399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 58, "% time spent exploring": 9}
{"steps": 11599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 59, "% time spent exploring": 9}
{"steps": 11799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 60, "% time spent exploring": 9}
{"steps": 11999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 61, "% time spent exploring": 9}
{"steps": 12199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 62, "% time spent exploring": 9}
{"steps": 12399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 63, "% time spent exploring": 9}
{"steps": 12599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 64, "% time spent exploring": 9}
{"steps": 12799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 65, "% time spent exploring": 9}
{"steps": 12999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 66, "% time spent exploring": 9}
{"steps": 13199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 67, "% time spent exploring": 9}
{"steps": 13399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 68, "% time spent exploring": 9}
{"steps": 13599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 69, "% time spent exploring": 9}
{"steps": 13799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 70, "% time spent exploring": 9}
{"steps": 13999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 71, "% time spent exploring": 9}
{"steps": 14199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 72, "% time spent exploring": 9}
{"steps": 14399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 73, "% time spent exploring": 9}
{"steps": 14599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 74, "% time spent exploring": 9}
{"steps": 14799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 75, "% time spent exploring": 9}
{"steps": 14999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 76, "% time spent exploring": 9}
{"steps": 15199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 77, "% time spent exploring": 9}
{"steps": 15399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 78, "% time spent exploring": 9}
{"steps": 15599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 79, "% time spent exploring": 9}
{"steps": 15799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 80, "% time spent exploring": 9}
{"steps": 15999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 81, "% time spent exploring": 9}
{"steps": 16199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 82, "% time spent exploring": 9}
{"steps": 16399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 83, "% time spent exploring": 9}
{"steps": 16599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 84, "% time spent exploring": 9}
{"steps": 16799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 85, "% time spent exploring": 9}
{"steps": 16999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 86, "% time spent exploring": 9}
{"steps": 17199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 87, "% time spent exploring": 9}
{"steps": 17399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 88, "% time spent exploring": 9}
{"steps": 17599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 89, "% time spent exploring": 9}
{"steps": 17799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 90, "% time spent exploring": 9}
{"steps": 17999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 91, "% time spent exploring": 9}
{"steps": 18199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 92, "% time spent exploring": 9}
{"steps": 18399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 93, "% time spent exploring": 9}
{"steps": 18599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 94, "% time spent exploring": 9}
{"steps": 18799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 95, "% time spent exploring": 9}
{"steps": 18999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 96, "% time spent exploring": 9}
{"steps": 19199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 97, "% time spent exploring": 9}
{"steps": 19399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 98, "% time spent exploring": 9}
{"steps": 19599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 99, "% time spent exploring": 9}
{"steps": 19799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 100, "% time spent exploring": 9}
{"steps": 19999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 101, "% time spent exploring": 9}
{"steps": 20199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 102, "% time spent exploring": 9}
{"steps": 20399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 103, "% time spent exploring": 9}
{"steps": 20599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 104, "% time spent exploring": 9}
{"steps": 20799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 105, "% time spent exploring": 9}
{"steps": 20999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 106, "% time spent exploring": 9}
{"steps": 21199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 107, "% time spent exploring": 9}
{"steps": 21399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 108, "% time spent exploring": 9}
{"steps": 21599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 109, "% time spent exploring": 9}
{"steps": 21799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 110, "% time spent exploring": 9}
{"steps": 21999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 7, "episodes": 111, "% time spent exploring": 9}
{"steps": 22199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 112, "% time spent exploring": 9}
{"steps": 22399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 113, "% time spent exploring": 9}
{"steps": 22599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 114, "% time spent exploring": 9}
{"steps": 22799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 115, "% time spent exploring": 9}
{"steps": 22999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 116, "% time spent exploring": 9}
{"steps": 23199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 117, "% time spent exploring": 9}
{"steps": 23399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 118, "% time spent exploring": 9}
{"steps": 23599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 119, "% time spent exploring": 9}
{"steps": 23799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 120, "% time spent exploring": 9}
{"steps": 23999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 121, "% time spent exploring": 9}
{"steps": 24199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 122, "% time spent exploring": 9}
{"steps": 24399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 1, "episodes": 123, "% time spent exploring": 9}
{"steps": 24599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 124, "% time spent exploring": 9}
{"steps": 24799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 125, "% time spent exploring": 9}
{"steps": 24999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 126, "% time spent exploring": 9}
{"steps": 25199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 127, "% time spent exploring": 9}
{"steps": 25399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 128, "% time spent exploring": 9}
{"steps": 25599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 129, "% time spent exploring": 9}
{"steps": 25799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 130, "% time spent exploring": 9}
{"steps": 25999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 131, "% time spent exploring": 9}
{"steps": 26199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 132, "% time spent exploring": 9}
{"steps": 26399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 133, "% time spent exploring": 9}
{"steps": 26599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 134, "% time spent exploring": 9}
{"steps": 26799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 135, "% time spent exploring": 9}
{"steps": 26999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 136, "% time spent exploring": 9}
{"steps": 27199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 137, "% time spent exploring": 9}
{"steps": 27399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 138, "% time spent exploring": 9}
{"steps": 27599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 139, "% time spent exploring": 9}
{"steps": 27799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 140, "% time spent exploring": 9}
{"steps": 27999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 141, "% time spent exploring": 9}
{"steps": 28199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 142, "% time spent exploring": 9}
{"steps": 28399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 143, "% time spent exploring": 9}
{"steps": 28599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 144, "% time spent exploring": 9}
{"steps": 28799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 145, "% time spent exploring": 9}
{"steps": 28999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 146, "% time spent exploring": 9}
{"steps": 29199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 2, "episodes": 147, "% time spent exploring": 9}
{"steps": 29399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 148, "% time spent exploring": 9}
{"steps": 29599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 149, "% time spent exploring": 9}
{"steps": 29799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 150, "% time spent exploring": 9}
{"steps": 29999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 151, "% time spent exploring": 9}
{"steps": 30199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 4, "episodes": 152, "% time spent exploring": 9}
{"steps": 30399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 3, "episodes": 153, "% time spent exploring": 9}
{"steps": 30599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 6, "episodes": 154, "% time spent exploring": 9}
{"steps": 30799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 155, "% time spent exploring": 9}
{"steps": 30999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 156, "% time spent exploring": 9}
{"steps": 31199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 157, "% time spent exploring": 9}
{"steps": 31399, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 8, "episodes": 158, "% time spent exploring": 9}
{"steps": 31599, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 5, "episodes": 159, "% time spent exploring": 9}
{"steps": 31799, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 160, "% time spent exploring": 9}
{"steps": 31999, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 0, "episodes": 161, "% time spent exploring": 9}
{"steps": 32199, "mean 100 episode reward": -200.0, "reward": -200.0, "head": 9, "episodes": 162, "% time spent exploring": 9}
{"steps": 32397, "mean 100 episode reward": -200.0, "reward": -198.0, "head": 6, "episodes": 163, "% time spent exploring": 9}
{"steps": 32583, "mean 100 episode reward": -199.8, "reward": -186.0, "head": 5, "episodes": 164, "% time spent exploring": 9}
{"steps": 32783, "mean 100 episode reward": -199.8, "reward": -200.0, "head": 3, "episodes": 165, "% time spent exploring": 9}
{"steps": 32983, "mean 100 episode reward": -199.8, "reward": -200.0, "head": 1, "episodes": 166, "% time spent exploring": 9}
{"steps": 33183, "mean 100 episode reward": -199.8, "reward": -200.0, "head": 8, "episodes": 167, "% time spent exploring": 9}
{"steps": 33383, "mean 100 episode reward": -199.8, "reward": -200.0, "head": 0, "episodes": 168, "% time spent exploring": 9}
{"steps": 33583, "mean 100 episode reward": -199.8, "reward": -200.0, "head": 4, "episodes": 169, "% time spent exploring": 9}
{"steps": 33771, "mean 100 episode reward": -199.7, "reward": -188.0, "head": 9, "episodes": 170, "% time spent exploring": 9}
{"steps": 33971, "mean 100 episode reward": -199.7, "reward": -200.0, "head": 6, "episodes": 171, "% time spent exploring": 9}
{"steps": 34171, "mean 100 episode reward": -199.7, "reward": -200.0, "head": 5, "episodes": 172, "% time spent exploring": 9}
{"steps": 34371, "mean 100 episode reward": -199.7, "reward": -200.0, "head": 7, "episodes": 173, "% time spent exploring": 9}
{"steps": 34571, "mean 100 episode reward": -199.7, "reward": -200.0, "head": 8, "episodes": 174, "% time spent exploring": 9}
{"steps": 34771, "mean 100 episode reward": -199.7, "reward": -200.0, "head": 8, "episodes": 175, "% time spent exploring": 9}
{"steps": 34936, "mean 100 episode reward": -199.4, "reward": -165.0, "head": 9, "episodes": 176, "% time spent exploring": 9}
{"steps": 35136, "mean 100 episode reward": -199.4, "reward": -200.0, "head": 2, "episodes": 177, "% time spent exploring": 9}
{"steps": 35336, "mean 100 episode reward": -199.4, "reward": -200.0, "head": 8, "episodes": 178, "% time spent exploring": 9}
{"steps": 35510, "mean 100 episode reward": -199.1, "reward": -174.0, "head": 6, "episodes": 179, "% time spent exploring": 9}
{"steps": 35710, "mean 100 episode reward": -199.1, "reward": -200.0, "head": 6, "episodes": 180, "% time spent exploring": 9}
{"steps": 35910, "mean 100 episode reward": -199.1, "reward": -200.0, "head": 9, "episodes": 181, "% time spent exploring": 9}
{"steps": 36070, "mean 100 episode reward": -198.7, "reward": -160.0, "head": 1, "episodes": 182, "% time spent exploring": 9}
{"steps": 36270, "mean 100 episode reward": -198.7, "reward": -200.0, "head": 6, "episodes": 183, "% time spent exploring": 9}
{"steps": 36470, "mean 100 episode reward": -198.7, "reward": -200.0, "head": 8, "episodes": 184, "% time spent exploring": 9}
{"steps": 36669, "mean 100 episode reward": -198.7, "reward": -199.0, "head": 8, "episodes": 185, "% time spent exploring": 9}
{"steps": 36858, "mean 100 episode reward": -198.6, "reward": -189.0, "head": 3, "episodes": 186, "% time spent exploring": 9}
{"steps": 37058, "mean 100 episode reward": -198.6, "reward": -200.0, "head": 2, "episodes": 187, "% time spent exploring": 9}
{"steps": 37258, "mean 100 episode reward": -198.6, "reward": -200.0, "head": 3, "episodes": 188, "% time spent exploring": 9}
{"steps": 37393, "mean 100 episode reward": -197.9, "reward": -135.0, "head": 6, "episodes": 189, "% time spent exploring": 9}
{"steps": 37559, "mean 100 episode reward": -197.6, "reward": -166.0, "head": 3, "episodes": 190, "% time spent exploring": 9}
{"steps": 37759, "mean 100 episode reward": -197.6, "reward": -200.0, "head": 6, "episodes": 191, "% time spent exploring": 9}
{"steps": 37919, "mean 100 episode reward": -197.2, "reward": -160.0, "head": 5, "episodes": 192, "% time spent exploring": 9}
{"steps": 38119, "mean 100 episode reward": -197.2, "reward": -200.0, "head": 7, "episodes": 193, "% time spent exploring": 9}
{"steps": 38319, "mean 100 episode reward": -197.2, "reward": -200.0, "head": 0, "episodes": 194, "% time spent exploring": 9}
{"steps": 38516, "mean 100 episode reward": -197.2, "reward": -197.0, "head": 8, "episodes": 195, "% time spent exploring": 9}
{"steps": 38716, "mean 100 episode reward": -197.2, "reward": -200.0, "head": 4, "episodes": 196, "% time spent exploring": 9}
{"steps": 38859, "mean 100 episode reward": -196.6, "reward": -143.0, "head": 6, "episodes": 197, "% time spent exploring": 9}
{"steps": 39003, "mean 100 episode reward": -196.0, "reward": -144.0, "head": 5, "episodes": 198, "% time spent exploring": 9}
{"steps": 39198, "mean 100 episode reward": -196.0, "reward": -195.0, "head": 8, "episodes": 199, "% time spent exploring": 9}
{"steps": 39364, "mean 100 episode reward": -195.6, "reward": -166.0, "head": 2, "episodes": 200, "% time spent exploring": 9}
{"steps": 39519, "mean 100 episode reward": -195.2, "reward": -155.0, "head": 3, "episodes": 201, "% time spent exploring": 9}
{"steps": 39682, "mean 100 episode reward": -194.8, "reward": -163.0, "head": 9, "episodes": 202, "% time spent exploring": 9}
{"steps": 39834, "mean 100 episode reward": -194.4, "reward": -152.0, "head": 7, "episodes": 203, "% time spent exploring": 9}
{"steps": 39994, "mean 100 episode reward": -194.0, "reward": -160.0, "head": 5, "episodes": 204, "% time spent exploring": 9}
{"steps": 40194, "mean 100 episode reward": -194.0, "reward": -200.0, "head": 3, "episodes": 205, "% time spent exploring": 9}
{"steps": 40394, "mean 100 episode reward": -194.0, "reward": -200.0, "head": 4, "episodes": 206, "% time spent exploring": 9}
{"steps": 40575, "mean 100 episode reward": -193.8, "reward": -181.0, "head": 5, "episodes": 207, "% time spent exploring": 9}
{"steps": 40733, "mean 100 episode reward": -193.3, "reward": -158.0, "head": 3, "episodes": 208, "% time spent exploring": 9}
{"steps": 40933, "mean 100 episode reward": -193.3, "reward": -200.0, "head": 3, "episodes": 209, "% time spent exploring": 9}
{"steps": 41121, "mean 100 episode reward": -193.2, "reward": -188.0, "head": 7, "episodes": 210, "% time spent exploring": 9}
{"steps": 41271, "mean 100 episode reward": -192.7, "reward": -150.0, "head": 9, "episodes": 211, "% time spent exploring": 9}
{"steps": 41419, "mean 100 episode reward": -192.2, "reward": -148.0, "head": 9, "episodes": 212, "% time spent exploring": 9}
{"steps": 41565, "mean 100 episode reward": -191.7, "reward": -146.0, "head": 9, "episodes": 213, "% time spent exploring": 9}
{"steps": 41729, "mean 100 episode reward": -191.3, "reward": -164.0, "head": 7, "episodes": 214, "% time spent exploring": 9}
{"steps": 41887, "mean 100 episode reward": -190.9, "reward": -158.0, "head": 3, "episodes": 215, "% time spent exploring": 9}
{"steps": 42087, "mean 100 episode reward": -190.9, "reward": -200.0, "head": 2, "episodes": 216, "% time spent exploring": 9}
{"steps": 42257, "mean 100 episode reward": -190.6, "reward": -170.0, "head": 3, "episodes": 217, "% time spent exploring": 9}
{"steps": 42457, "mean 100 episode reward": -190.6, "reward": -200.0, "head": 9, "episodes": 218, "% time spent exploring": 9}
{"steps": 42617, "mean 100 episode reward": -190.2, "reward": -160.0, "head": 7, "episodes": 219, "% time spent exploring": 9}
{"steps": 42778, "mean 100 episode reward": -189.8, "reward": -161.0, "head": 7, "episodes": 220, "% time spent exploring": 9}
{"steps": 42976, "mean 100 episode reward": -189.8, "reward": -198.0, "head": 5, "episodes": 221, "% time spent exploring": 9}
{"steps": 43176, "mean 100 episode reward": -189.8, "reward": -200.0, "head": 1, "episodes": 222, "% time spent exploring": 9}
{"steps": 43376, "mean 100 episode reward": -189.8, "reward": -200.0, "head": 2, "episodes": 223, "% time spent exploring": 9}
{"steps": 43535, "mean 100 episode reward": -189.4, "reward": -159.0, "head": 2, "episodes": 224, "% time spent exploring": 9}
{"steps": 43701, "mean 100 episode reward": -189.0, "reward": -166.0, "head": 8, "episodes": 225, "% time spent exploring": 9}
{"steps": 43856, "mean 100 episode reward": -188.6, "reward": -155.0, "head": 1, "episodes": 226, "% time spent exploring": 9}
{"steps": 44011, "mean 100 episode reward": -188.1, "reward": -155.0, "head": 5, "episodes": 227, "% time spent exploring": 9}
{"steps": 44171, "mean 100 episode reward": -187.7, "reward": -160.0, "head": 8, "episodes": 228, "% time spent exploring": 9}
{"steps": 44371, "mean 100 episode reward": -187.7, "reward": -200.0, "head": 4, "episodes": 229, "% time spent exploring": 9}
{"steps": 44551, "mean 100 episode reward": -187.5, "reward": -180.0, "head": 0, "episodes": 230, "% time spent exploring": 9}
{"steps": 44719, "mean 100 episode reward": -187.2, "reward": -168.0, "head": 2, "episodes": 231, "% time spent exploring": 9}
{"steps": 44919, "mean 100 episode reward": -187.2, "reward": -200.0, "head": 5, "episodes": 232, "% time spent exploring": 9}
{"steps": 45108, "mean 100 episode reward": -187.1, "reward": -189.0, "head": 5, "episodes": 233, "% time spent exploring": 9}
{"steps": 45247, "mean 100 episode reward": -186.5, "reward": -139.0, "head": 0, "episodes": 234, "% time spent exploring": 9}
{"steps": 45442, "mean 100 episode reward": -186.4, "reward": -195.0, "head": 8, "episodes": 235, "% time spent exploring": 9}
{"steps": 45600, "mean 100 episode reward": -186.0, "reward": -158.0, "head": 1, "episodes": 236, "% time spent exploring": 9}
{"steps": 45800, "mean 100 episode reward": -186.0, "reward": -200.0, "head": 1, "episodes": 237, "% time spent exploring": 9}
{"steps": 45952, "mean 100 episode reward": -185.5, "reward": -152.0, "head": 0, "episodes": 238, "% time spent exploring": 9}
{"steps": 46095, "mean 100 episode reward": -185.0, "reward": -143.0, "head": 3, "episodes": 239, "% time spent exploring": 9}
{"steps": 46295, "mean 100 episode reward": -185.0, "reward": -200.0, "head": 8, "episodes": 240, "% time spent exploring": 9}
{"steps": 46448, "mean 100 episode reward": -184.5, "reward": -153.0, "head": 8, "episodes": 241, "% time spent exploring": 9}
{"steps": 46648, "mean 100 episode reward": -184.5, "reward": -200.0, "head": 4, "episodes": 242, "% time spent exploring": 9}
{"steps": 46848, "mean 100 episode reward": -184.5, "reward": -200.0, "head": 4, "episodes": 243, "% time spent exploring": 9}
{"steps": 47013, "mean 100 episode reward": -184.1, "reward": -165.0, "head": 0, "episodes": 244, "% time spent exploring": 9}
{"steps": 47213, "mean 100 episode reward": -184.1, "reward": -200.0, "head": 9, "episodes": 245, "% time spent exploring": 9}
{"steps": 47392, "mean 100 episode reward": -183.9, "reward": -179.0, "head": 3, "episodes": 246, "% time spent exploring": 9}
{"steps": 47592, "mean 100 episode reward": -183.9, "reward": -200.0, "head": 7, "episodes": 247, "% time spent exploring": 9}
{"steps": 47735, "mean 100 episode reward": -183.4, "reward": -143.0, "head": 3, "episodes": 248, "% time spent exploring": 9}
{"steps": 47935, "mean 100 episode reward": -183.4, "reward": -200.0, "head": 2, "episodes": 249, "% time spent exploring": 9}
{"steps": 48095, "mean 100 episode reward": -183.0, "reward": -160.0, "head": 1, "episodes": 250, "% time spent exploring": 9}
{"steps": 48295, "mean 100 episode reward": -183.0, "reward": -200.0, "head": 1, "episodes": 251, "% time spent exploring": 9}
{"steps": 48428, "mean 100 episode reward": -182.3, "reward": -133.0, "head": 2, "episodes": 252, "% time spent exploring": 9}
{"steps": 48628, "mean 100 episode reward": -182.3, "reward": -200.0, "head": 1, "episodes": 253, "% time spent exploring": 9}
{"steps": 48767, "mean 100 episode reward": -181.7, "reward": -139.0, "head": 4, "episodes": 254, "% time spent exploring": 9}
{"steps": 48967, "mean 100 episode reward": -181.7, "reward": -200.0, "head": 2, "episodes": 255, "% time spent exploring": 9}
{"steps": 49167, "mean 100 episode reward": -181.7, "reward": -200.0, "head": 5, "episodes": 256, "% time spent exploring": 9}
{"steps": 49330, "mean 100 episode reward": -181.3, "reward": -163.0, "head": 5, "episodes": 257, "% time spent exploring": 9}
{"steps": 49530, "mean 100 episode reward": -181.3, "reward": -200.0, "head": 5, "episodes": 258, "% time spent exploring": 9}
{"steps": 49675, "mean 100 episode reward": -180.8, "reward": -145.0, "head": 2, "episodes": 259, "% time spent exploring": 9}
{"steps": 49861, "mean 100 episode reward": -180.6, "reward": -186.0, "head": 5, "episodes": 260, "% time spent exploring": 9}
{"steps": 50044, "mean 100 episode reward": -180.4, "reward": -183.0, "head": 7, "episodes": 261, "% time spent exploring": 9}
{"steps": 50244, "mean 100 episode reward": -180.4, "reward": -200.0, "head": 7, "episodes": 262, "% time spent exploring": 9}
{"steps": 50368, "mean 100 episode reward": -179.7, "reward": -124.0, "head": 6, "episodes": 263, "% time spent exploring": 9}
{"steps": 50524, "mean 100 episode reward": -179.4, "reward": -156.0, "head": 1, "episodes": 264, "% time spent exploring": 9}
{"steps": 50683, "mean 100 episode reward": -179.0, "reward": -159.0, "head": 6, "episodes": 265, "% time spent exploring": 9}
{"steps": 50841, "mean 100 episode reward": -178.6, "reward": -158.0, "head": 7, "episodes": 266, "% time spent exploring": 9}
{"steps": 51041, "mean 100 episode reward": -178.6, "reward": -200.0, "head": 2, "episodes": 267, "% time spent exploring": 9}
{"steps": 51241, "mean 100 episode reward": -178.6, "reward": -200.0, "head": 3, "episodes": 268, "% time spent exploring": 9}
{"steps": 51385, "mean 100 episode reward": -178.0, "reward": -144.0, "head": 1, "episodes": 269, "% time spent exploring": 9}
{"steps": 51538, "mean 100 episode reward": -177.7, "reward": -153.0, "head": 9, "episodes": 270, "% time spent exploring": 9}
{"steps": 51738, "mean 100 episode reward": -177.7, "reward": -200.0, "head": 5, "episodes": 271, "% time spent exploring": 9}
{"steps": 51878, "mean 100 episode reward": -177.1, "reward": -140.0, "head": 9, "episodes": 272, "% time spent exploring": 9}
{"steps": 52047, "mean 100 episode reward": -176.8, "reward": -169.0, "head": 9, "episodes": 273, "% time spent exploring": 9}
{"steps": 52247, "mean 100 episode reward": -176.8, "reward": -200.0, "head": 2, "episodes": 274, "% time spent exploring": 9}
{"steps": 52430, "mean 100 episode reward": -176.6, "reward": -183.0, "head": 0, "episodes": 275, "% time spent exploring": 9}
{"steps": 52584, "mean 100 episode reward": -176.5, "reward": -154.0, "head": 9, "episodes": 276, "% time spent exploring": 9}
{"steps": 52780, "mean 100 episode reward": -176.4, "reward": -196.0, "head": 1, "episodes": 277, "% time spent exploring": 9}
{"steps": 52972, "mean 100 episode reward": -176.4, "reward": -192.0, "head": 9, "episodes": 278, "% time spent exploring": 9}
{"steps": 53124, "mean 100 episode reward": -176.1, "reward": -152.0, "head": 0, "episodes": 279, "% time spent exploring": 9}
{"steps": 53275, "mean 100 episode reward": -175.6, "reward": -151.0, "head": 6, "episodes": 280, "% time spent exploring": 9}
{"steps": 53438, "mean 100 episode reward": -175.3, "reward": -163.0, "head": 0, "episodes": 281, "% time spent exploring": 9}
{"steps": 53638, "mean 100 episode reward": -175.7, "reward": -200.0, "head": 4, "episodes": 282, "% time spent exploring": 9}
{"steps": 53788, "mean 100 episode reward": -175.2, "reward": -150.0, "head": 8, "episodes": 283, "% time spent exploring": 9}
{"steps": 53988, "mean 100 episode reward": -175.2, "reward": -200.0, "head": 4, "episodes": 284, "% time spent exploring": 9}
{"steps": 54188, "mean 100 episode reward": -175.2, "reward": -200.0, "head": 3, "episodes": 285, "% time spent exploring": 9}
{"steps": 54343, "mean 100 episode reward": -174.8, "reward": -155.0, "head": 3, "episodes": 286, "% time spent exploring": 9}
{"steps": 54531, "mean 100 episode reward": -174.7, "reward": -188.0, "head": 8, "episodes": 287, "% time spent exploring": 9}
{"steps": 54731, "mean 100 episode reward": -174.7, "reward": -200.0, "head": 8, "episodes": 288, "% time spent exploring": 9}
{"steps": 54931, "mean 100 episode reward": -175.4, "reward": -200.0, "head": 7, "episodes": 289, "% time spent exploring": 9}
{"steps": 55083, "mean 100 episode reward": -175.2, "reward": -152.0, "head": 0, "episodes": 290, "% time spent exploring": 9}
{"steps": 55273, "mean 100 episode reward": -175.1, "reward": -190.0, "head": 3, "episodes": 291, "% time spent exploring": 9}
{"steps": 55430, "mean 100 episode reward": -175.1, "reward": -157.0, "head": 8, "episodes": 292, "% time spent exploring": 9}
{"steps": 55575, "mean 100 episode reward": -174.6, "reward": -145.0, "head": 7, "episodes": 293, "% time spent exploring": 9}
{"steps": 55723, "mean 100 episode reward": -174.0, "reward": -148.0, "head": 7, "episodes": 294, "% time spent exploring": 9}
{"steps": 55923, "mean 100 episode reward": -174.1, "reward": -200.0, "head": 1, "episodes": 295, "% time spent exploring": 9}
{"steps": 56079, "mean 100 episode reward": -173.6, "reward": -156.0, "head": 8, "episodes": 296, "% time spent exploring": 9}
{"steps": 56249, "mean 100 episode reward": -173.9, "reward": -170.0, "head": 4, "episodes": 297, "% time spent exploring": 9}
{"steps": 56393, "mean 100 episode reward": -173.9, "reward": -144.0, "head": 7, "episodes": 298, "% time spent exploring": 9}
{"steps": 56542, "mean 100 episode reward": -173.4, "reward": -149.0, "head": 0, "episodes": 299, "% time spent exploring": 9}
{"steps": 56702, "mean 100 episode reward": -173.4, "reward": -160.0, "head": 4, "episodes": 300, "% time spent exploring": 9}
{"steps": 56847, "mean 100 episode reward": -173.3, "reward": -145.0, "head": 9, "episodes": 301, "% time spent exploring": 9}
{"steps": 57000, "mean 100 episode reward": -173.2, "reward": -153.0, "head": 0, "episodes": 302, "% time spent exploring": 9}
{"steps": 57144, "mean 100 episode reward": -173.1, "reward": -144.0, "head": 6, "episodes": 303, "% time spent exploring": 9}
{"steps": 57344, "mean 100 episode reward": -173.5, "reward": -200.0, "head": 4, "episodes": 304, "% time spent exploring": 9}
{"steps": 57528, "mean 100 episode reward": -173.3, "reward": -184.0, "head": 2, "episodes": 305, "% time spent exploring": 9}
{"steps": 57672, "mean 100 episode reward": -172.8, "reward": -144.0, "head": 4, "episodes": 306, "% time spent exploring": 9}
{"steps": 57845, "mean 100 episode reward": -172.7, "reward": -173.0, "head": 6, "episodes": 307, "% time spent exploring": 9}
{"steps": 58045, "mean 100 episode reward": -173.1, "reward": -200.0, "head": 3, "episodes": 308, "% time spent exploring": 9}
{"steps": 58200, "mean 100 episode reward": -172.7, "reward": -155.0, "head": 3, "episodes": 309, "% time spent exploring": 9}
{"steps": 58400, "mean 100 episode reward": -172.8, "reward": -200.0, "head": 7, "episodes": 310, "% time spent exploring": 9}
{"steps": 58562, "mean 100 episode reward": -172.9, "reward": -162.0, "head": 8, "episodes": 311, "% time spent exploring": 9}
{"steps": 58762, "mean 100 episode reward": -173.4, "reward": -200.0, "head": 5, "episodes": 312, "% time spent exploring": 9}
{"steps": 58936, "mean 100 episode reward": -173.7, "reward": -174.0, "head": 0, "episodes": 313, "% time spent exploring": 9}
{"steps": 59098, "mean 100 episode reward": -173.7, "reward": -162.0, "head": 8, "episodes": 314, "% time spent exploring": 9}
{"steps": 59244, "mean 100 episode reward": -173.6, "reward": -146.0, "head": 5, "episodes": 315, "% time spent exploring": 9}
{"steps": 59405, "mean 100 episode reward": -173.2, "reward": -161.0, "head": 4, "episodes": 316, "% time spent exploring": 9}
{"steps": 59563, "mean 100 episode reward": -173.1, "reward": -158.0, "head": 7, "episodes": 317, "% time spent exploring": 9}
{"steps": 59716, "mean 100 episode reward": -172.6, "reward": -153.0, "head": 4, "episodes": 318, "% time spent exploring": 9}
{"steps": 59873, "mean 100 episode reward": -172.6, "reward": -157.0, "head": 1, "episodes": 319, "% time spent exploring": 9}
{"steps": 60027, "mean 100 episode reward": -172.5, "reward": -154.0, "head": 3, "episodes": 320, "% time spent exploring": 9}
{"steps": 60227, "mean 100 episode reward": -172.5, "reward": -200.0, "head": 3, "episodes": 321, "% time spent exploring": 9}
{"steps": 60427, "mean 100 episode reward": -172.5, "reward": -200.0, "head": 9, "episodes": 322, "% time spent exploring": 9}
{"steps": 60580, "mean 100 episode reward": -172.0, "reward": -153.0, "head": 2, "episodes": 323, "% time spent exploring": 9}
{"steps": 60780, "mean 100 episode reward": -172.4, "reward": -200.0, "head": 5, "episodes": 324, "% time spent exploring": 9}
{"steps": 60942, "mean 100 episode reward": -172.4, "reward": -162.0, "head": 2, "episodes": 325, "% time spent exploring": 9}
{"steps": 61101, "mean 100 episode reward": -172.4, "reward": -159.0, "head": 3, "episodes": 326, "% time spent exploring": 9}
{"steps": 61256, "mean 100 episode reward": -172.4, "reward": -155.0, "head": 5, "episodes": 327, "% time spent exploring": 9}
{"steps": 61410, "mean 100 episode reward": -172.4, "reward": -154.0, "head": 7, "episodes": 328, "% time spent exploring": 9}
{"steps": 61561, "mean 100 episode reward": -171.9, "reward": -151.0, "head": 2, "episodes": 329, "% time spent exploring": 9}
{"steps": 61718, "mean 100 episode reward": -171.7, "reward": -157.0, "head": 7, "episodes": 330, "% time spent exploring": 9}
{"steps": 61881, "mean 100 episode reward": -171.6, "reward": -163.0, "head": 1, "episodes": 331, "% time spent exploring": 9}
{"steps": 62027, "mean 100 episode reward": -171.1, "reward": -146.0, "head": 6, "episodes": 332, "% time spent exploring": 9}
{"steps": 62186, "mean 100 episode reward": -170.8, "reward": -159.0, "head": 5, "episodes": 333, "% time spent exploring": 9}
{"steps": 62386, "mean 100 episode reward": -171.4, "reward": -200.0, "head": 0, "episodes": 334, "% time spent exploring": 9}
{"steps": 62476, "mean 100 episode reward": -170.3, "reward": -90.0, "head": 0, "episodes": 335, "% time spent exploring": 9}
{"steps": 62676, "mean 100 episode reward": -170.8, "reward": -200.0, "head": 3, "episodes": 336, "% time spent exploring": 9}
{"steps": 62840, "mean 100 episode reward": -170.4, "reward": -164.0, "head": 1, "episodes": 337, "% time spent exploring": 9}
{"steps": 63040, "mean 100 episode reward": -170.9, "reward": -200.0, "head": 9, "episodes": 338, "% time spent exploring": 9}
{"steps": 63144, "mean 100 episode reward": -170.5, "reward": -104.0, "head": 9, "episodes": 339, "% time spent exploring": 9}
{"steps": 63298, "mean 100 episode reward": -170.0, "reward": -154.0, "head": 6, "episodes": 340, "% time spent exploring": 9}
{"steps": 63392, "mean 100 episode reward": -169.4, "reward": -94.0, "head": 6, "episodes": 341, "% time spent exploring": 9}
{"steps": 63491, "mean 100 episode reward": -168.4, "reward": -99.0, "head": 7, "episodes": 342, "% time spent exploring": 9}
{"steps": 63691, "mean 100 episode reward": -168.4, "reward": -200.0, "head": 8, "episodes": 343, "% time spent exploring": 9}
{"steps": 63891, "mean 100 episode reward": -168.8, "reward": -200.0, "head": 8, "episodes": 344, "% time spent exploring": 9}
{"steps": 64045, "mean 100 episode reward": -168.3, "reward": -154.0, "head": 7, "episodes": 345, "% time spent exploring": 9}
{"steps": 64213, "mean 100 episode reward": -168.2, "reward": -168.0, "head": 0, "episodes": 346, "% time spent exploring": 9}
{"steps": 64413, "mean 100 episode reward": -168.2, "reward": -200.0, "head": 8, "episodes": 347, "% time spent exploring": 9}
{"steps": 64613, "mean 100 episode reward": -168.8, "reward": -200.0, "head": 6, "episodes": 348, "% time spent exploring": 9}
{"steps": 64760, "mean 100 episode reward": -168.2, "reward": -147.0, "head": 8, "episodes": 349, "% time spent exploring": 9}
{"steps": 64909, "mean 100 episode reward": -168.1, "reward": -149.0, "head": 9, "episodes": 350, "% time spent exploring": 9}
{"steps": 65060, "mean 100 episode reward": -167.6, "reward": -151.0, "head": 8, "episodes": 351, "% time spent exploring": 9}
{"steps": 65260, "mean 100 episode reward": -168.3, "reward": -200.0, "head": 3, "episodes": 352, "% time spent exploring": 9}
{"steps": 65409, "mean 100 episode reward": -167.8, "reward": -149.0, "head": 6, "episodes": 353, "% time spent exploring": 9}
{"steps": 65563, "mean 100 episode reward": -168.0, "reward": -154.0, "head": 1, "episodes": 354, "% time spent exploring": 9}
{"steps": 65723, "mean 100 episode reward": -167.6, "reward": -160.0, "head": 7, "episodes": 355, "% time spent exploring": 9}
{"steps": 65814, "mean 100 episode reward": -166.5, "reward": -91.0, "head": 4, "episodes": 356, "% time spent exploring": 9}
{"steps": 66014, "mean 100 episode reward": -166.8, "reward": -200.0, "head": 9, "episodes": 357, "% time spent exploring": 9}
{"steps": 66203, "mean 100 episode reward": -166.7, "reward": -189.0, "head": 2, "episodes": 358, "% time spent exploring": 9}
{"steps": 66370, "mean 100 episode reward": -167.0, "reward": -167.0, "head": 0, "episodes": 359, "% time spent exploring": 9}
{"steps": 66540, "mean 100 episode reward": -166.8, "reward": -170.0, "head": 8, "episodes": 360, "% time spent exploring": 9}
{"steps": 66693, "mean 100 episode reward": -166.5, "reward": -153.0, "head": 2, "episodes": 361, "% time spent exploring": 9}
{"steps": 66862, "mean 100 episode reward": -166.2, "reward": -169.0, "head": 7, "episodes": 362, "% time spent exploring": 9}
{"steps": 67019, "mean 100 episode reward": -166.5, "reward": -157.0, "head": 8, "episodes": 363, "% time spent exploring": 9}
{"steps": 67219, "mean 100 episode reward": -167.0, "reward": -200.0, "head": 4, "episodes": 364, "% time spent exploring": 9}
{"steps": 67378, "mean 100 episode reward": -167.0, "reward": -159.0, "head": 4, "episodes": 365, "% time spent exploring": 9}
{"steps": 67535, "mean 100 episode reward": -166.9, "reward": -157.0, "head": 1, "episodes": 366, "% time spent exploring": 9}
{"steps": 67686, "mean 100 episode reward": -166.4, "reward": -151.0, "head": 7, "episodes": 367, "% time spent exploring": 9}
{"steps": 67886, "mean 100 episode reward": -166.4, "reward": -200.0, "head": 6, "episodes": 368, "% time spent exploring": 9}
{"steps": 68052, "mean 100 episode reward": -166.7, "reward": -166.0, "head": 9, "episodes": 369, "% time spent exploring": 9}
{"steps": 68143, "mean 100 episode reward": -166.0, "reward": -91.0, "head": 4, "episodes": 370, "% time spent exploring": 9}
{"steps": 68293, "mean 100 episode reward": -165.6, "reward": -150.0, "head": 1, "episodes": 371, "% time spent exploring": 9}
{"steps": 68465, "mean 100 episode reward": -165.9, "reward": -172.0, "head": 5, "episodes": 372, "% time spent exploring": 9}
{"steps": 68618, "mean 100 episode reward": -165.7, "reward": -153.0, "head": 9, "episodes": 373, "% time spent exploring": 9}
{"steps": 68818, "mean 100 episode reward": -165.7, "reward": -200.0, "head": 7, "episodes": 374, "% time spent exploring": 9}
{"steps": 68982, "mean 100 episode reward": -165.5, "reward": -164.0, "head": 1, "episodes": 375, "% time spent exploring": 9}
{"steps": 69172, "mean 100 episode reward": -165.9, "reward": -190.0, "head": 3, "episodes": 376, "% time spent exploring": 9}
{"steps": 69372, "mean 100 episode reward": -165.9, "reward": -200.0, "head": 5, "episodes": 377, "% time spent exploring": 9}
{"steps": 69572, "mean 100 episode reward": -166.0, "reward": -200.0, "head": 7, "episodes": 378, "% time spent exploring": 9}
{"steps": 69727, "mean 100 episode reward": -166.0, "reward": -155.0, "head": 3, "episodes": 379, "% time spent exploring": 9}
{"steps": 69927, "mean 100 episode reward": -166.5, "reward": -200.0, "head": 6, "episodes": 380, "% time spent exploring": 9}
{"steps": 70127, "mean 100 episode reward": -166.9, "reward": -200.0, "head": 6, "episodes": 381, "% time spent exploring": 9}
{"steps": 70327, "mean 100 episode reward": -166.9, "reward": -200.0, "head": 7, "episodes": 382, "% time spent exploring": 9}
{"steps": 70527, "mean 100 episode reward": -167.4, "reward": -200.0, "head": 9, "episodes": 383, "% time spent exploring": 9}
{"steps": 70686, "mean 100 episode reward": -167.0, "reward": -159.0, "head": 1, "episodes": 384, "% time spent exploring": 9}
{"steps": 70858, "mean 100 episode reward": -166.7, "reward": -172.0, "head": 9, "episodes": 385, "% time spent exploring": 9}
{"steps": 71016, "mean 100 episode reward": -166.7, "reward": -158.0, "head": 6, "episodes": 386, "% time spent exploring": 9}
{"steps": 71180, "mean 100 episode reward": -166.5, "reward": -164.0, "head": 0, "episodes": 387, "% time spent exploring": 9}
{"steps": 71380, "mean 100 episode reward": -166.5, "reward": -200.0, "head": 3, "episodes": 388, "% time spent exploring": 9}
{"steps": 71545, "mean 100 episode reward": -166.1, "reward": -165.0, "head": 8, "episodes": 389, "% time spent exploring": 9}
{"steps": 71701, "mean 100 episode reward": -166.2, "reward": -156.0, "head": 4, "episodes": 390, "% time spent exploring": 9}
{"steps": 71901, "mean 100 episode reward": -166.3, "reward": -200.0, "head": 1, "episodes": 391, "% time spent exploring": 9}
{"steps": 72071, "mean 100 episode reward": -166.4, "reward": -170.0, "head": 4, "episodes": 392, "% time spent exploring": 9}
{"steps": 72239, "mean 100 episode reward": -166.6, "reward": -168.0, "head": 5, "episodes": 393, "% time spent exploring": 9}
{"steps": 72334, "mean 100 episode reward": -166.1, "reward": -95.0, "head": 0, "episodes": 394, "% time spent exploring": 9}
{"steps": 72534, "mean 100 episode reward": -166.1, "reward": -200.0, "head": 3, "episodes": 395, "% time spent exploring": 9}
{"steps": 72716, "mean 100 episode reward": -166.4, "reward": -182.0, "head": 1, "episodes": 396, "% time spent exploring": 9}
{"steps": 72894, "mean 100 episode reward": -166.4, "reward": -178.0, "head": 4, "episodes": 397, "% time spent exploring": 9}
{"steps": 73055, "mean 100 episode reward": -166.6, "reward": -161.0, "head": 4, "episodes": 398, "% time spent exploring": 9}
{"steps": 73255, "mean 100 episode reward": -167.1, "reward": -200.0, "head": 4, "episodes": 399, "% time spent exploring": 9}
{"steps": 73455, "mean 100 episode reward": -167.5, "reward": -200.0, "head": 0, "episodes": 400, "% time spent exploring": 9}
{"steps": 73655, "mean 100 episode reward": -168.1, "reward": -200.0, "head": 0, "episodes": 401, "% time spent exploring": 9}
{"steps": 73817, "mean 100 episode reward": -168.2, "reward": -162.0, "head": 8, "episodes": 402, "% time spent exploring": 9}
{"steps": 74015, "mean 100 episode reward": -168.7, "reward": -198.0, "head": 4, "episodes": 403, "% time spent exploring": 9}
{"steps": 74200, "mean 100 episode reward": -168.6, "reward": -185.0, "head": 6, "episodes": 404, "% time spent exploring": 9}
{"steps": 74381, "mean 100 episode reward": -168.5, "reward": -181.0, "head": 9, "episodes": 405, "% time spent exploring": 9}
{"steps": 74556, "mean 100 episode reward": -168.8, "reward": -175.0, "head": 3, "episodes": 406, "% time spent exploring": 9}
{"steps": 74756, "mean 100 episode reward": -169.1, "reward": -200.0, "head": 3, "episodes": 407, "% time spent exploring": 9}
{"steps": 74934, "mean 100 episode reward": -168.9, "reward": -178.0, "head": 2, "episodes": 408, "% time spent exploring": 9}
{"steps": 75093, "mean 100 episode reward": -168.9, "reward": -159.0, "head": 1, "episodes": 409, "% time spent exploring": 9}
{"steps": 75255, "mean 100 episode reward": -168.6, "reward": -162.0, "head": 2, "episodes": 410, "% time spent exploring": 9}
{"steps": 75366, "mean 100 episode reward": -168.0, "reward": -111.0, "head": 1, "episodes": 411, "% time spent exploring": 9}
{"steps": 75530, "mean 100 episode reward": -167.7, "reward": -164.0, "head": 3, "episodes": 412, "% time spent exploring": 9}
{"steps": 75705, "mean 100 episode reward": -167.7, "reward": -175.0, "head": 4, "episodes": 413, "% time spent exploring": 9}
{"steps": 75848, "mean 100 episode reward": -167.5, "reward": -143.0, "head": 1, "episodes": 414, "% time spent exploring": 9}
{"steps": 76048, "mean 100 episode reward": -168.0, "reward": -200.0, "head": 1, "episodes": 415, "% time spent exploring": 9}
{"steps": 76207, "mean 100 episode reward": -168.0, "reward": -159.0, "head": 0, "episodes": 416, "% time spent exploring": 9}
{"steps": 76360, "mean 100 episode reward": -168.0, "reward": -153.0, "head": 7, "episodes": 417, "% time spent exploring": 9}
{"steps": 76560, "mean 100 episode reward": -168.4, "reward": -200.0, "head": 8, "episodes": 418, "% time spent exploring": 9}
{"steps": 76659, "mean 100 episode reward": -167.9, "reward": -99.0, "head": 4, "episodes": 419, "% time spent exploring": 9}
{"steps": 76815, "mean 100 episode reward": -167.9, "reward": -156.0, "head": 3, "episodes": 420, "% time spent exploring": 9}
{"steps": 76902, "mean 100 episode reward": -166.8, "reward": -87.0, "head": 5, "episodes": 421, "% time spent exploring": 9}
{"steps": 77102, "mean 100 episode reward": -166.8, "reward": -200.0, "head": 6, "episodes": 422, "% time spent exploring": 9}
{"steps": 77248, "mean 100 episode reward": -166.7, "reward": -146.0, "head": 3, "episodes": 423, "% time spent exploring": 9}
{"steps": 77406, "mean 100 episode reward": -166.3, "reward": -158.0, "head": 2, "episodes": 424, "% time spent exploring": 9}
{"steps": 77605, "mean 100 episode reward": -166.6, "reward": -199.0, "head": 9, "episodes": 425, "% time spent exploring": 9}
{"steps": 77767, "mean 100 episode reward": -166.7, "reward": -162.0, "head": 8, "episodes": 426, "% time spent exploring": 9}
{"steps": 77967, "mean 100 episode reward": -167.1, "reward": -200.0, "head": 1, "episodes": 427, "% time spent exploring": 9}
{"steps": 78167, "mean 100 episode reward": -167.6, "reward": -200.0, "head": 4, "episodes": 428, "% time spent exploring": 9}
{"steps": 78367, "mean 100 episode reward": -168.1, "reward": -200.0, "head": 0, "episodes": 429, "% time spent exploring": 9}
{"steps": 78524, "mean 100 episode reward": -168.1, "reward": -157.0, "head": 8, "episodes": 430, "% time spent exploring": 9}
{"steps": 78716, "mean 100 episode reward": -168.4, "reward": -192.0, "head": 3, "episodes": 431, "% time spent exploring": 9}
{"steps": 78860, "mean 100 episode reward": -168.3, "reward": -144.0, "head": 9, "episodes": 432, "% time spent exploring": 9}
{"steps": 79010, "mean 100 episode reward": -168.2, "reward": -150.0, "head": 5, "episodes": 433, "% time spent exploring": 9}
{"steps": 79161, "mean 100 episode reward": -167.8, "reward": -151.0, "head": 5, "episodes": 434, "% time spent exploring": 9}
{"steps": 79260, "mean 100 episode reward": -167.8, "reward": -99.0, "head": 1, "episodes": 435, "% time spent exploring": 9}
{"steps": 79425, "mean 100 episode reward": -167.5, "reward": -165.0, "head": 7, "episodes": 436, "% time spent exploring": 9}
{"steps": 79625, "mean 100 episode reward": -167.8, "reward": -200.0, "head": 8, "episodes": 437, "% time spent exploring": 9}
{"steps": 79722, "mean 100 episode reward": -166.8, "reward": -97.0, "head": 6, "episodes": 438, "% time spent exploring": 9}
{"steps": 79872, "mean 100 episode reward": -167.3, "reward": -150.0, "head": 4, "episodes": 439, "% time spent exploring": 9}
{"steps": 80026, "mean 100 episode reward": -167.3, "reward": -154.0, "head": 7, "episodes": 440, "% time spent exploring": 9}
{"steps": 80181, "mean 100 episode reward": -167.9, "reward": -155.0, "head": 3, "episodes": 441, "% time spent exploring": 9}
{"steps": 80334, "mean 100 episode reward": -168.4, "reward": -153.0, "head": 5, "episodes": 442, "% time spent exploring": 9}
{"steps": 80480, "mean 100 episode reward": -167.9, "reward": -146.0, "head": 3, "episodes": 443, "% time spent exploring": 9}
{"steps": 80657, "mean 100 episode reward": -167.7, "reward": -177.0, "head": 6, "episodes": 444, "% time spent exploring": 9}
{"steps": 80857, "mean 100 episode reward": -168.1, "reward": -200.0, "head": 4, "episodes": 445, "% time spent exploring": 9}
{"steps": 81057, "mean 100 episode reward": -168.4, "reward": -200.0, "head": 7, "episodes": 446, "% time spent exploring": 9}
{"steps": 81221, "mean 100 episode reward": -168.1, "reward": -164.0, "head": 3, "episodes": 447, "% time spent exploring": 9}
{"steps": 81375, "mean 100 episode reward": -167.6, "reward": -154.0, "head": 0, "episodes": 448, "% time spent exploring": 9}
{"steps": 81531, "mean 100 episode reward": -167.7, "reward": -156.0, "head": 5, "episodes": 449, "% time spent exploring": 9}
{"steps": 81640, "mean 100 episode reward": -167.3, "reward": -109.0, "head": 9, "episodes": 450, "% time spent exploring": 9}
{"steps": 81797, "mean 100 episode reward": -167.4, "reward": -157.0, "head": 3, "episodes": 451, "% time spent exploring": 9}
{"steps": 81938, "mean 100 episode reward": -166.8, "reward": -141.0, "head": 7, "episodes": 452, "% time spent exploring": 9}
{"steps": 82093, "mean 100 episode reward": -166.8, "reward": -155.0, "head": 5, "episodes": 453, "% time spent exploring": 9}
{"steps": 82196, "mean 100 episode reward": -166.3, "reward": -103.0, "head": 5, "episodes": 454, "% time spent exploring": 9}
{"steps": 82345, "mean 100 episode reward": -166.2, "reward": -149.0, "head": 8, "episodes": 455, "% time spent exploring": 9}
{"steps": 82537, "mean 100 episode reward": -167.2, "reward": -192.0, "head": 0, "episodes": 456, "% time spent exploring": 9}
{"steps": 82681, "mean 100 episode reward": -166.7, "reward": -144.0, "head": 8, "episodes": 457, "% time spent exploring": 9}
{"steps": 82765, "mean 100 episode reward": -165.6, "reward": -84.0, "head": 3, "episodes": 458, "% time spent exploring": 9}
{"steps": 82910, "mean 100 episode reward": -165.4, "reward": -145.0, "head": 6, "episodes": 459, "% time spent exploring": 9}
{"steps": 83078, "mean 100 episode reward": -165.4, "reward": -168.0, "head": 9, "episodes": 460, "% time spent exploring": 9}
{"steps": 83218, "mean 100 episode reward": -165.2, "reward": -140.0, "head": 3, "episodes": 461, "% time spent exploring": 9}
{"steps": 83313, "mean 100 episode reward": -164.5, "reward": -95.0, "head": 2, "episodes": 462, "% time spent exploring": 9}
{"steps": 83404, "mean 100 episode reward": -163.8, "reward": -91.0, "head": 7, "episodes": 463, "% time spent exploring": 9}
{"steps": 83584, "mean 100 episode reward": -163.6, "reward": -180.0, "head": 0, "episodes": 464, "% time spent exploring": 9}
{"steps": 83731, "mean 100 episode reward": -163.5, "reward": -147.0, "head": 3, "episodes": 465, "% time spent exploring": 9}
{"steps": 83883, "mean 100 episode reward": -163.5, "reward": -152.0, "head": 0, "episodes": 466, "% time spent exploring": 9}
{"steps": 84080, "mean 100 episode reward": -163.9, "reward": -197.0, "head": 3, "episodes": 467, "% time spent exploring": 9}
{"steps": 84232, "mean 100 episode reward": -163.5, "reward": -152.0, "head": 6, "episodes": 468, "% time spent exploring": 9}
{"steps": 84379, "mean 100 episode reward": -163.3, "reward": -147.0, "head": 1, "episodes": 469, "% time spent exploring": 9}
{"steps": 84547, "mean 100 episode reward": -164.0, "reward": -168.0, "head": 9, "episodes": 470, "% time spent exploring": 9}
{"steps": 84709, "mean 100 episode reward": -164.2, "reward": -162.0, "head": 2, "episodes": 471, "% time spent exploring": 9}
{"steps": 84866, "mean 100 episode reward": -164.0, "reward": -157.0, "head": 9, "episodes": 472, "% time spent exploring": 9}
{"steps": 84953, "mean 100 episode reward": -163.4, "reward": -87.0, "head": 4, "episodes": 473, "% time spent exploring": 9}
{"steps": 85153, "mean 100 episode reward": -163.4, "reward": -200.0, "head": 9, "episodes": 474, "% time spent exploring": 9}
{"steps": 85348, "mean 100 episode reward": -163.7, "reward": -195.0, "head": 1, "episodes": 475, "% time spent exploring": 9}
{"steps": 85492, "mean 100 episode reward": -163.2, "reward": -144.0, "head": 3, "episodes": 476, "% time spent exploring": 9}
{"steps": 85645, "mean 100 episode reward": -162.7, "reward": -153.0, "head": 2, "episodes": 477, "% time spent exploring": 9}
{"steps": 85792, "mean 100 episode reward": -162.2, "reward": -147.0, "head": 4, "episodes": 478, "% time spent exploring": 9}
{"steps": 85944, "mean 100 episode reward": -162.2, "reward": -152.0, "head": 9, "episodes": 479, "% time spent exploring": 9}
{"steps": 86096, "mean 100 episode reward": -161.7, "reward": -152.0, "head": 7, "episodes": 480, "% time spent exploring": 9}
{"steps": 86253, "mean 100 episode reward": -161.3, "reward": -157.0, "head": 4, "episodes": 481, "% time spent exploring": 9}
{"steps": 86406, "mean 100 episode reward": -160.8, "reward": -153.0, "head": 9, "episodes": 482, "% time spent exploring": 9}
{"steps": 86598, "mean 100 episode reward": -160.7, "reward": -192.0, "head": 4, "episodes": 483, "% time spent exploring": 9}
{"steps": 86740, "mean 100 episode reward": -160.5, "reward": -142.0, "head": 1, "episodes": 484, "% time spent exploring": 9}
{"steps": 86829, "mean 100 episode reward": -159.7, "reward": -89.0, "head": 2, "episodes": 485, "% time spent exploring": 9}
{"steps": 86974, "mean 100 episode reward": -159.6, "reward": -145.0, "head": 7, "episodes": 486, "% time spent exploring": 9}
{"steps": 87118, "mean 100 episode reward": -159.4, "reward": -144.0, "head": 2, "episodes": 487, "% time spent exploring": 9}
{"steps": 87263, "mean 100 episode reward": -158.8, "reward": -145.0, "head": 3, "episodes": 488, "% time spent exploring": 9}
{"steps": 87446, "mean 100 episode reward": -159.0, "reward": -183.0, "head": 9, "episodes": 489, "% time spent exploring": 9}
{"steps": 87543, "mean 100 episode reward": -158.4, "reward": -97.0, "head": 7, "episodes": 490, "% time spent exploring": 9}
{"steps": 87688, "mean 100 episode reward": -157.9, "reward": -145.0, "head": 6, "episodes": 491, "% time spent exploring": 9}
{"steps": 87834, "mean 100 episode reward": -157.6, "reward": -146.0, "head": 6, "episodes": 492, "% time spent exploring": 9}
{"steps": 87924, "mean 100 episode reward": -156.8, "reward": -90.0, "head": 2, "episodes": 493, "% time spent exploring": 9}
{"steps": 88010, "mean 100 episode reward": -156.8, "reward": -86.0, "head": 3, "episodes": 494, "% time spent exploring": 9}
{"steps": 88163, "mean 100 episode reward": -156.3, "reward": -153.0, "head": 6, "episodes": 495, "% time spent exploring": 9}
{"steps": 88256, "mean 100 episode reward": -155.4, "reward": -93.0, "head": 0, "episodes": 496, "% time spent exploring": 9}
{"steps": 88351, "mean 100 episode reward": -154.6, "reward": -95.0, "head": 8, "episodes": 497, "% time spent exploring": 9}
{"steps": 88510, "mean 100 episode reward": -154.6, "reward": -159.0, "head": 0, "episodes": 498, "% time spent exploring": 9}
{"steps": 88685, "mean 100 episode reward": -154.3, "reward": -175.0, "head": 7, "episodes": 499, "% time spent exploring": 9}
{"steps": 88850, "mean 100 episode reward": -154.0, "reward": -165.0, "head": 6, "episodes": 500, "% time spent exploring": 9}
{"steps": 88994, "mean 100 episode reward": -153.4, "reward": -144.0, "head": 5, "episodes": 501, "% time spent exploring": 9}
{"steps": 89141, "mean 100 episode reward": -153.2, "reward": -147.0, "head": 9, "episodes": 502, "% time spent exploring": 9}
{"steps": 89305, "mean 100 episode reward": -152.9, "reward": -164.0, "head": 6, "episodes": 503, "% time spent exploring": 9}
{"steps": 89396, "mean 100 episode reward": -152.0, "reward": -91.0, "head": 5, "episodes": 504, "% time spent exploring": 9}
{"steps": 89542, "mean 100 episode reward": -151.6, "reward": -146.0, "head": 2, "episodes": 505, "% time spent exploring": 9}
{"steps": 89695, "mean 100 episode reward": -151.4, "reward": -153.0, "head": 7, "episodes": 506, "% time spent exploring": 9}
{"steps": 89838, "mean 100 episode reward": -150.8, "reward": -143.0, "head": 1, "episodes": 507, "% time spent exploring": 9}
{"steps": 89931, "mean 100 episode reward": -150.0, "reward": -93.0, "head": 9, "episodes": 508, "% time spent exploring": 9}
{"steps": 90079, "mean 100 episode reward": -149.9, "reward": -148.0, "head": 2, "episodes": 509, "% time spent exploring": 9}
{"steps": 90235, "mean 100 episode reward": -149.8, "reward": -156.0, "head": 2, "episodes": 510, "% time spent exploring": 9}
{"steps": 90379, "mean 100 episode reward": -150.1, "reward": -144.0, "head": 5, "episodes": 511, "% time spent exploring": 9}
{"steps": 90554, "mean 100 episode reward": -150.2, "reward": -175.0, "head": 6, "episodes": 512, "% time spent exploring": 9}
{"steps": 90702, "mean 100 episode reward": -150.0, "reward": -148.0, "head": 4, "episodes": 513, "% time spent exploring": 9}
{"steps": 90852, "mean 100 episode reward": -150.0, "reward": -150.0, "head": 2, "episodes": 514, "% time spent exploring": 9}
{"steps": 91002, "mean 100 episode reward": -149.5, "reward": -150.0, "head": 2, "episodes": 515, "% time spent exploring": 9}
{"steps": 91148, "mean 100 episode reward": -149.4, "reward": -146.0, "head": 1, "episodes": 516, "% time spent exploring": 9}
{"steps": 91297, "mean 100 episode reward": -149.4, "reward": -149.0, "head": 0, "episodes": 517, "% time spent exploring": 9}
{"steps": 91446, "mean 100 episode reward": -148.9, "reward": -149.0, "head": 9, "episodes": 518, "% time spent exploring": 9}
{"steps": 91594, "mean 100 episode reward": -149.4, "reward": -148.0, "head": 0, "episodes": 519, "% time spent exploring": 9}
{"steps": 91788, "mean 100 episode reward": -149.7, "reward": -194.0, "head": 2, "episodes": 520, "% time spent exploring": 9}
{"steps": 91941, "mean 100 episode reward": -150.4, "reward": -153.0, "head": 8, "episodes": 521, "% time spent exploring": 9}
{"steps": 92113, "mean 100 episode reward": -150.1, "reward": -172.0, "head": 3, "episodes": 522, "% time spent exploring": 9}
{"steps": 92253, "mean 100 episode reward": -150.0, "reward": -140.0, "head": 0, "episodes": 523, "% time spent exploring": 9}
{"steps": 92420, "mean 100 episode reward": -150.1, "reward": -167.0, "head": 8, "episodes": 524, "% time spent exploring": 9}
{"steps": 92580, "mean 100 episode reward": -149.8, "reward": -160.0, "head": 8, "episodes": 525, "% time spent exploring": 9}
{"steps": 92728, "mean 100 episode reward": -149.6, "reward": -148.0, "head": 1, "episodes": 526, "% time spent exploring": 9}
{"steps": 92874, "mean 100 episode reward": -149.1, "reward": -146.0, "head": 0, "episodes": 527, "% time spent exploring": 9}
{"steps": 93018, "mean 100 episode reward": -148.5, "reward": -144.0, "head": 5, "episodes": 528, "% time spent exploring": 9}
{"steps": 93161, "mean 100 episode reward": -147.9, "reward": -143.0, "head": 8, "episodes": 529, "% time spent exploring": 9}
{"steps": 93328, "mean 100 episode reward": -148.0, "reward": -167.0, "head": 2, "episodes": 530, "% time spent exploring": 9}
{"steps": 93472, "mean 100 episode reward": -147.6, "reward": -144.0, "head": 3, "episodes": 531, "% time spent exploring": 9}
{"steps": 93643, "mean 100 episode reward": -147.8, "reward": -171.0, "head": 5, "episodes": 532, "% time spent exploring": 9}
{"steps": 93784, "mean 100 episode reward": -147.7, "reward": -141.0, "head": 3, "episodes": 533, "% time spent exploring": 9}
{"steps": 93884, "mean 100 episode reward": -147.2, "reward": -100.0, "head": 8, "episodes": 534, "% time spent exploring": 9}
{"steps": 94037, "mean 100 episode reward": -147.8, "reward": -153.0, "head": 6, "episodes": 535, "% time spent exploring": 9}
{"steps": 94184, "mean 100 episode reward": -147.6, "reward": -147.0, "head": 4, "episodes": 536, "% time spent exploring": 9}
{"steps": 94333, "mean 100 episode reward": -147.1, "reward": -149.0, "head": 6, "episodes": 537, "% time spent exploring": 9}
{"steps": 94476, "mean 100 episode reward": -147.5, "reward": -143.0, "head": 3, "episodes": 538, "% time spent exploring": 9}
{"steps": 94620, "mean 100 episode reward": -147.5, "reward": -144.0, "head": 6, "episodes": 539, "% time spent exploring": 9}
{"steps": 94766, "mean 100 episode reward": -147.4, "reward": -146.0, "head": 2, "episodes": 540, "% time spent exploring": 9}
{"steps": 94859, "mean 100 episode reward": -146.8, "reward": -93.0, "head": 6, "episodes": 541, "% time spent exploring": 9}
{"steps": 95003, "mean 100 episode reward": -146.7, "reward": -144.0, "head": 5, "episodes": 542, "% time spent exploring": 9}
{"steps": 95148, "mean 100 episode reward": -146.7, "reward": -145.0, "head": 5, "episodes": 543, "% time spent exploring": 9}
{"steps": 95299, "mean 100 episode reward": -146.4, "reward": -151.0, "head": 9, "episodes": 544, "% time spent exploring": 9}
{"steps": 95460, "mean 100 episode reward": -146.0, "reward": -161.0, "head": 4, "episodes": 545, "% time spent exploring": 9}
{"steps": 95608, "mean 100 episode reward": -145.5, "reward": -148.0, "head": 6, "episodes": 546, "% time spent exploring": 9}
{"steps": 95761, "mean 100 episode reward": -145.4, "reward": -153.0, "head": 5, "episodes": 547, "% time spent exploring": 9}
{"steps": 95908, "mean 100 episode reward": -145.3, "reward": -147.0, "head": 1, "episodes": 548, "% time spent exploring": 9}
{"steps": 96068, "mean 100 episode reward": -145.4, "reward": -160.0, "head": 3, "episodes": 549, "% time spent exploring": 9}
{"steps": 96222, "mean 100 episode reward": -145.8, "reward": -154.0, "head": 3, "episodes": 550, "% time spent exploring": 9}
{"steps": 96371, "mean 100 episode reward": -145.7, "reward": -149.0, "head": 8, "episodes": 551, "% time spent exploring": 9}
{"steps": 96515, "mean 100 episode reward": -145.8, "reward": -144.0, "head": 9, "episodes": 552, "% time spent exploring": 9}
{"steps": 96679, "mean 100 episode reward": -145.9, "reward": -164.0, "head": 5, "episodes": 553, "% time spent exploring": 9}
{"steps": 96824, "mean 100 episode reward": -146.3, "reward": -145.0, "head": 5, "episodes": 554, "% time spent exploring": 9}
{"steps": 96968, "mean 100 episode reward": -146.2, "reward": -144.0, "head": 6, "episodes": 555, "% time spent exploring": 9}
{"steps": 97114, "mean 100 episode reward": -145.8, "reward": -146.0, "head": 0, "episodes": 556, "% time spent exploring": 9}
{"steps": 97281, "mean 100 episode reward": -146.0, "reward": -167.0, "head": 9, "episodes": 557, "% time spent exploring": 9}
{"steps": 97372, "mean 100 episode reward": -146.1, "reward": -91.0, "head": 7, "episodes": 558, "% time spent exploring": 9}
{"steps": 97521, "mean 100 episode reward": -146.1, "reward": -149.0, "head": 5, "episodes": 559, "% time spent exploring": 9}
{"steps": 97673, "mean 100 episode reward": -146.0, "reward": -152.0, "head": 1, "episodes": 560, "% time spent exploring": 9}
{"steps": 97816, "mean 100 episode reward": -146.0, "reward": -143.0, "head": 5, "episodes": 561, "% time spent exploring": 9}
{"steps": 97961, "mean 100 episode reward": -146.5, "reward": -145.0, "head": 6, "episodes": 562, "% time spent exploring": 9}
{"steps": 98105, "mean 100 episode reward": -147.0, "reward": -144.0, "head": 6, "episodes": 563, "% time spent exploring": 9}
{"steps": 98212, "mean 100 episode reward": -146.3, "reward": -107.0, "head": 8, "episodes": 564, "% time spent exploring": 9}
{"steps": 98354, "mean 100 episode reward": -146.2, "reward": -142.0, "head": 7, "episodes": 565, "% time spent exploring": 9}
{"steps": 98501, "mean 100 episode reward": -146.2, "reward": -147.0, "head": 5, "episodes": 566, "% time spent exploring": 9}
{"steps": 98644, "mean 100 episode reward": -145.6, "reward": -143.0, "head": 3, "episodes": 567, "% time spent exploring": 9}
{"steps": 98789, "mean 100 episode reward": -145.6, "reward": -145.0, "head": 2, "episodes": 568, "% time spent exploring": 9}
{"steps": 98934, "mean 100 episode reward": -145.6, "reward": -145.0, "head": 9, "episodes": 569, "% time spent exploring": 9}
{"steps": 99088, "mean 100 episode reward": -145.4, "reward": -154.0, "head": 9, "episodes": 570, "% time spent exploring": 9}
{"steps": 99193, "mean 100 episode reward": -144.8, "reward": -105.0, "head": 3, "episodes": 571, "% time spent exploring": 9}
{"steps": 99341, "mean 100 episode reward": -144.8, "reward": -148.0, "head": 2, "episodes": 572, "% time spent exploring": 9}
{"steps": 99443, "mean 100 episode reward": -144.9, "reward": -102.0, "head": 5, "episodes": 573, "% time spent exploring": 9}
{"steps": 99594, "mean 100 episode reward": -144.4, "reward": -151.0, "head": 4, "episodes": 574, "% time spent exploring": 9}
{"steps": 99762, "mean 100 episode reward": -144.1, "reward": -168.0, "head": 1, "episodes": 575, "% time spent exploring": 9}
{"steps": 99849, "mean 100 episode reward": -143.6, "reward": -87.0, "head": 5, "episodes": 576, "% time spent exploring": 9}
{"steps": 99998, "mean 100 episode reward": -143.5, "reward": -149.0, "head": 8, "episodes": 577, "% time spent exploring": 9}
